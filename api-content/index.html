{"posts":[{"title":"go依赖注入库 samber/do 笔记","content":"do do 依赖注入定义 快速使用 匿名服务与命名服务 急加载和懒加载 急加载 懒加载 服务调用 其他 samber/do 文档：⚙️ do: Typesafe dependency injection for Go | do 参考：源码分析——Go语言依赖注入库 samber/do - 飞鸟记 do是一个依赖注入库。相比于用过的wire，do更加轻量且无需代码生成。 注意： v2正在开发中，新版本可能有较大改动。 依赖注入定义 狭义DI定义 对象的使用方式不应该依赖于对象的创建方式。 所以我们要实现的，就是： 提供一个「第三方」 对象创建者，把特定类型的对象创建出来并注册到第三方 对象使用者，从第三方获取对象 我的理解是，使用对象时不需要去关注对象如何创建，不需要自己创建对象，而是直接使用一个现成的对象。 如何将对象交给使用者，就是所谓的“注入”。 最简单的理解就是一个map，需要什么对象时查询map从里面拿。 快速使用 func main() { // create DI container and inject package services injector := do.New() do.Provide(injector, NewCar) do.Provide(injector, NewEngine) do.ProvideValue(&amp;Config{ Port: 4242, }) // invoking car will instantiate Car services and its Engine dependency car, err := do.Invoke[*Car](i) if err != nil { log.Fatal(err.Error()) } car.Start() // that's all folk 🤗 // handle ctrl-c and shutdown services i.ShutdownOnSignals(syscall.SIGTERM, os.Interrupt) } 使用do.New()创建一个依赖注入容器（即一个map[string]any） 使用do.Provide()注册服务（提供对象创建方式） 使用do.Invoke[Type](injector)调用服务（获取对应类型的对象） 使用对象 匿名服务与命名服务 do框架在进行服务注册时，都有提供Provide和ProvideNamed两种方法。 func Provide[T any](i do.Injector, provider do.Provider[T]) func ProvideNamed[T any](i do.Injector, name string, provider do.Provider[T]) 前者为匿名服务，由框架处理命名。后者为命名服务，用户自己提供命名作为map[string]any的key键。 顺便一提，匿名服务中框架生成服务名的方式就是直接打印变量类型： func generateServiceName[T any]() string { var t T // struct name := fmt.Sprintf(&quot;%T&quot;, t) if name != &quot;&lt;nil&gt;&quot; { return name } // interface return fmt.Sprintf(&quot;%T&quot;, new(T)) } 急加载和懒加载 急加载(Eager Loading) 是在注册服务时直接传入变量。 懒加载（Lazy Loading） 是传入创建变量的方式，等用到时再创建。 // 急加载 func ProvideValue[T any](i do.Injector, value T) func ProvideNamedValue[T any](i do.Injector, name string, value T) // 懒加载 func Provide[T any](i do.Injector, provider do.Provider[T]) func ProvideNamed[T any](i do.Injector, name string, provider do.Provider[T]) 要更深入理解两者的区别，我们需要了解服务的定义和两种服务注册方式的实现。如下是部分源码（已简化）: type Service[T any] interface { getName() string getInstance(*Injector) (T, error) } 服务本身是一个接口，getName方法获取服务名，getInstance方法获取服务实例。无论是急加载还是懒加载，以及其他的瞬时加载和包加载等，只要实现了这个接口就行。 急加载 type ServiceEager[T any] struct { name string instance T } func newServiceEager[T any](name string, instance T) Service[T] { return &amp;ServiceEager[T]{ name: name, instance: instance, } } //nolint:unused func (s *ServiceEager[T]) getName() string { return s.name } //nolint:unused func (s *ServiceEager[T]) getInstance(i *Injector) (T, error) { return s.instance, nil } 急加载直接传入创建好的实例，调用时返回就行。 懒加载 type Provider[T any] func(*Injector) (T, error) type ServiceLazy[T any] struct { mu sync.RWMutex name string instance T // lazy loading built bool provider Provider[T] } func newServiceLazy[T any](name string, provider Provider[T]) Service[T] { return &amp;ServiceLazy[T]{ name: name, built: false, provider: provider, } } //nolint:unused func (s *ServiceLazy[T]) getName() string { return s.name } //nolint:unused func (s *ServiceLazy[T]) getInstance(i *Injector) (T, error) { s.mu.Lock() defer s.mu.Unlock() if !s.built { err := s.build(i) if err != nil { return empty[T](), err } } return s.instance, nil } //nolint:unused func (s *ServiceLazy[T]) build(i *Injector) (err error) { instance, err := s.provider(i) if err != nil { return err } s.instance = instance s.built = true return nil } Provider[T any]类型为创建实例的方式。从懒加载服务中获取实例时先通过built标记判断实例是否已创建。 如果已创建，直接返回实例。如果未创建，使用传入的provider创建实例。创建过程通过并发变量mu保证并发安全。 服务调用 do.Invoke[T any](do.Injector) (T, error) do.InvokeNamed[T any](do.Injector, string) (T, error) do.MustInvoke[T any](do.Injector) T do.MustInvokeNamed[T any](do.Injector, string) T 使用do.Invoke调用匿名服务，do.InvokeNamed调用命名服务。 而Must版本是正常版本的封装，单返回值可以直接用于表达式中，报错时不返回错误而是直接panic。 其他 其他用法和特性因为没用过理解不深，为了避免抄文档就干脆不写了。 以后用上了再查文档记笔记吧。 ","link":"https://jinvic.github.io/post/go-di-lib-samber-do-notes/"},{"title":"关于WSL的代理问题一则","content":"今天在使用wsl的docker build拉取镜像时，报错： ERROR: failed to solve: alpine: failed to resolve source metadata for docker.io/library/alpine:latest: failed to do request: Head &quot;https://registry-1.docker.io/v2/library/alpine/manifests/latest&quot;: proxyconnect tcp: dial tcp 127.0.0.1:7890: connect: connection refused 即使关闭了代理，仍然报这个错误。于是各种检查，到底是在哪设置的代理。 首先检查环境变量： echo $http_proxy echo $https_proxy 确认没有设置环境变量。 然后检查配置文件： sudo cat /etc/docker/daemon.json 因为使用的是Docker Desktop for Windows，所以并没有这个文件，也没有配置代理。 检查 WinHTTP 代理设置，也没有设置。 PS C:\\Users\\admin&gt; netsh winhttp show proxy 当前的 WinHTTP 代理服务器设置: 直接访问(没有代理服务器)。 尝试禁用BuildKit，依然报错： export DOCKER_BUILDKIT=0 docker build . DEPRECATED: The legacy builder is deprecated and will be removed in a future release. BuildKit is currently disabled; enable it by removing the DOCKER_BUILDKIT=0 environment-variable. Sending build context to Docker daemon 4.316MB Step 1/29 : FROM node:20.19.1-bookworm AS front Get &quot;https://registry-1.docker.io/v2/&quot;: proxyconnect tcp: dial tcp 127.0.0.1:7890: connect: connection refused 检查/etc/resolv.conf，一切正常： cat /etc/resolv.conf # This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to /etc/wsl.conf: # [network] # generateResolvConf = false nameserver 10.255.255.254 检查%USERPROFILE%\\.wslconfig，终于找到了问题： cat ~/.wslconfig [experimental] networkingMode=mirrored dnsTunneling=true firewall=true autoProxy=true 这是之前将wsl的网络模式由NAT改为镜像模式，顺手复制粘贴的配置。其中autoProxy=true表示 WSL 会自动继承 Windows 的代理设置。在windows运行的clash会在127.0.0.1:7890 启动本地 HTTP 代理服务。WSL 检测到这个代理后，就会把所有网络请求都转发到这个地址，即使代理没运行，它也会尝试连接。这就是为什么在windows关了代理仍在wsl仍会尝试连接7890端口。将其修改未false后问题解决。 虽然docker默认使用代理的问题解决了，但docker build不可以的问题依然存在。一下是一些可供参考的内容。 Help on “ERROR [internal] load metadata for docker.io/library/node:18-alpine” https://stackoverflow.com/questions/73812700/docker-error-internal-load-metadata-for-docker-io can't docker pull images from China 可行的解决方案大概有 docker logout docker login重新登录 docker pull手动拉取镜像 export DOCKER_BUILDKIT=0禁用buildkit 设置镜像站等 ","link":"https://jinvic.github.io/post/a-problem-about-wsl-proxy/"},{"title":"记一次MCP辅助开发经历","content":"记一次MCP使用经历 记一次MCP使用经历 MCP接入和验证 拆分多文件 添加日志功能 自动化测试流程 总结 本次开发的结果和完整对话记录都将整理并备份在Github上。 最开始只是玩扫雷时，感觉鼠标声音有点响，想改成键盘。另外有时扫雷会出现纯看运气的情况，希望加个直接显示雷的作弊功能。就这两个需求，简单让AI写了下，过程略。 因为感觉一个庞大的单文件不够美观，就想试着拆分成多文件系统。正好最近经常被MCP刷屏，想试试能不能接入一个MCP让cursor自己完成文件的创建之类步骤，实现完全的自动化。找了下选择了这个Filesystem MCP Server。 MCP接入和验证 cursor接入MCP也有两种方式，分别时全局和当前目录。前者在C:/Users/用户名/.cursor/mcp.json下，后者在当前目录创建./.cursor/mcp.json。我使用的后者，写入如下内容： { &quot;mcpServers&quot;: { &quot;filesystem&quot;: { &quot;command&quot;: &quot;npx&quot;, &quot;args&quot;: [ &quot;-y&quot;, &quot;@modelcontextprotocol/server-filesystem&quot;, &quot;./&quot; ] } } } 由于使用的npx命令，所以需要nodejs环境。之后再cursor的设置的MCP页面能看到该MCP且带绿点就行了。要验证该mcp能否正常操作文件系统，可以使用如下提示词验证： 请在当前工作目录下创建一个名为 'test.txt' 的新文件，并向其中写入以下内容：'这是一个测试文件。' 拆分多文件 最开始我让AI拆分多文件时它虽然拆了但没有创建对应文件，似乎是我表述不清晰。之后明确说明让它创建对应文件就会去使用MCP创建了。 _**User**_ 请阅读main.py的代码，并将其拆分为更工程化的多文件结构。 --- _**Assistant**_ --- 我将把这个扫雷游戏拆分为更工程化的多文件结构。下面是建议的文件结构和代码： ## 文件结构 minesweeper/ │ ├── game/ │ ├── __init__.py │ ├── core.py # 游戏核心逻辑 │ └── ui.py # 用户界面组件 │ ├── handlers/ │ ├── __init__.py │ └── events.py # 事件处理器 │ └── main.py # 入口点文件 ## 代码实现 (略) _**User**_ 请你按照如上内容完成项目文件的创建和编辑。 --- _**Assistant**_ --- &lt;details&gt; &lt;summary&gt;Listed current directory • **4** results&lt;/summary&gt; | Name | |-------| | 📄 `main.py` | | 📄 `main.py.backup` | | 📁 `__pycache__` | | 📁 `.cursor` | &lt;/details&gt; --- 现在我将创建项目目录结构。首先创建主要目录： --- 我需要在当前工作目录中创建项目目录： --- 让我们使用终端命令创建目录： --- mkdir -p minesweeper/game minesweeper/handlers PS D:\\Workspace\\Python\\Arbiter&gt; mkdir -p minesweeper/game minesweeper/handlers mkdir: A positional parameter cannot be found that accepts argument 'minesweeper /handlers'. --- 让我尝试使用PowerShell语法： --- mkdir minesweeper/game, minesweeper/handlers -Force Directory: D:\\Workspace\\Python\\Arbiter\\minesweeper Mode LastWriteTime Length Name ---- ------------- ------ ---- d---- 2025/4/5 16:30 game d---- 2025/4/5 16:30 handlers PS D:\\Workspace\\Python\\Arbiter&gt; --- 现在让我们创建所需的所有文件： --- (略) 可以看到，现在它会去获取当前文件目录结构并使用命令创建目录。再Linux命令出错时也会主动更换目录。 添加日志功能 之后添加readme，功能修改和测试等都正常。直到我尝试添加日志功能后，发现它会自动查询生成的日志去DEBUG。 最开始它只是通过 -Tail 选项查询最新的日志： 游戏现在没有显示错误，这是个好迹象。让我们检查一下日志文件，看看窗口大小调整功能是否正常工作： --- Get-Content -Path &quot;./logs/minesweeper_2025-04-05.log&quot; -Tail 30 在发现信息不足时马上更该更准确的筛选和查询方式： 让我们看更多的日志记录： --- Get-Content -Path &quot;./logs/minesweeper_2025-04-05.log&quot; | Select-String -Pattern &quot;游戏板|窗口|设置&quot; 自动化测试流程 在学会查询日志后，后续的开发和测试它甚至会在功能完成后自己创建测试脚本并运行： 让我们测试日志级别的变更是否真正影响了日志输出。首先，我们创建一个临时的测试脚本： --- （内容略） --- 现在运行测试脚本： --- python test_log_settings.py （日志略） --- 我们可以看到，日志级别设置已经修改，但有两个问题需要解决： 1. 控制台只显示了警告和错误级别的日志，这是因为控制台处理器的级别被硬编码为WARNING 2. 日志保留天数意外地显示为3天而不是7天，这可能是之前的测试修改了配置 让我们修复第一个问题，并再次运行测试： --- （过程略） 现在我们可以看到，DEBUG 和 INFO 级别的消息也显示出来了，说明日志级别设置已经正确应用。 如上内容都是在一次对话中完成的。很明显，AI主动建立了一个创建测试脚本-&gt;运行-&gt;查看日志输出-&gt;修改测试脚本-&gt;运行...的工作流，反复测试并修改直到问题解决，大大提升了效率和自动化程度。 总结 本来只是一次简单的开发，但加入MCP后的成果令我十分惊讶，尤其是AI借助MCP在没有任何指示的情况主动建立起了一套可行的测试流程。这还只是导入了一个最基础的文件系统操作的MCP。难以想象在更专业的领域，加入MCP后的AI辅助开发会对开发流程带来何种颠覆性的改变。 ","link":"https://jinvic.github.io/post/record-an-mcp-assisted-development-experience/"},{"title":"使用roundcube+docker-mailserver自部署邮件服务","content":"使用roundcube+docker-mailserver自部署邮件服务 使用roundcube+docker-mailserver自部署邮件服务 参考 邮件服务器 Docker Mailserver 证书申请 DNS配置 开放端口 部署DMS 容器内配置 邮件客户端 Roundcube 在做一个开源项目的邮件通知功能，本来用smtp发个邮件就行，不知怎么的就捣鼓着就开始自建邮件服务器了。不过用自己的域名实现邮件服务很酷不是吗？ 参考 教程： 1Panel 自建邮局 - Docker Mailserver Usage - Docker Mailserver 工具： smtp发信测试 MX ToolBox 邮件服务器 Docker Mailserver 本来是打算在应用商店直接部署的，但不知道为什么总报错安装失败，就自己用docker-composer部署了。 证书申请 首先要实现SSL/TLS安全连接你必须有个证书，申请证书的过程略，1Panel本身的证书功能就很方便了。申请好的证书别忘了推送到本地目录，记下这个路径之后要用到。 DNS配置 要让别人能找到你的邮件服务器地址需要配置DNS，配置项很多我也不是很懂，详情可以参考开头的文章。这里以我的域名jinvic.top为例： 域名 记录类型 记录值 备注 jinvic.top MX 10 mail.jinvic.top 改成你自己的域名 email.jinvic.top A &lt;你的服务器公网ip&gt; jinvic.top TXT &quot;v=spf1 mx -all&quot; SPF 记录 _dmarc.jinvic.top TXT &quot;v=DMARC1; p=reject; adkim=s; aspf=s&quot; DMARC 记录 mail._domainkey.jinvic.top TXT &lt;稍后生成&gt; DKIM 记录 开放端口 DMS用到的端口有25,143,465,587,993这些，全部在防火墙开放一下。如果用到是服务商提供的云服务器，记得配置下安全组规则。 部署DMS 在准备好的工作目录下，通过如下命令获取docker-compose和.env文件： DMS_GITHUB_URL=&quot;https://raw.githubusercontent.com/docker-mailserver/docker-mailserver/master&quot; wget &quot;${DMS_GITHUB_URL}/compose.yaml&quot; wget &quot;${DMS_GITHUB_URL}/mailserver.env&quot; compose.yaml中如下内容需要自主配置： hostname：改成你自己的域名，即DNS中A记录配置的域名，如email.jinvic.top，注意不能是jinvic.top。 volumes: 将你的证书路径挂载进去，配环境变量用 如下是我的compose.yaml示例： services: mailserver: image: ghcr.io/docker-mailserver/docker-mailserver:latest container_name: mailserver # Provide the FQDN of your mail server here (Your DNS MX record should point to this value) hostname: mail.jinvic.top env_file: mailserver.env # More information about the mail-server ports: # https://docker-mailserver.github.io/docker-mailserver/latest/config/security/understanding-the-ports/ ports: - &quot;25:25&quot; # SMTP (explicit TLS =&gt; STARTTLS, Authentication is DISABLED =&gt; use port 465/587 instead) - &quot;143:143&quot; # IMAP4 (explicit TLS =&gt; STARTTLS) - &quot;465:465&quot; # ESMTP (implicit TLS) - &quot;587:587&quot; # ESMTP (explicit TLS =&gt; STARTTLS) - &quot;993:993&quot; # IMAP4 (implicit TLS) volumes: - ./docker-data/dms/mail-data/:/var/mail/ - ./docker-data/dms/mail-state/:/var/mail-state/ - ./docker-data/dms/mail-logs/:/var/log/mail/ - ./docker-data/dms/config/:/tmp/docker-mailserver/ - /cert/jinvic.top:/cert/jinvic.top:ro restart: always stop_grace_period: 1m # Uncomment if using `ENABLE_FAIL2BAN=1`: # cap_add: # - NET_ADMIN healthcheck: test: &quot;ss --listening --tcp | grep -P 'LISTEN.+:smtp' || exit 1&quot; timeout: 3s retries: 0 mailserver.env中如下内容需要自主配置： SSL_TYPE：设置为manual SSL_CERT_PATH 和 SSL_KEY_PATH：映射的证书路径 POSTMASTER_ADDRESS：非必选，邮件服务器的管理员邮箱地址 示例： SSL_TYPE=manual SSL_CERT_PATH=/cert/jinvic.top/fullchain.pem SSL_KEY_PATH=/cert/jinvic.top/privkey.pem POSTMASTER_ADDRESS=jinvic@jinvic.top 配置完成后，使用docker-compose up -d启动服务。 容器内配置 通过docker exec -ti &lt;CONTAINER NAME&gt; /bin/sh启动容器内终端。 创建用户： setup email add jinvic@jinvic.top 之后会让你输入密码。之后就可以用这套账密登录roundcube了。 生成DKIM：setup config dkim 将括号内文本写入DNS（见 DNS配置）。 邮件客户端 Roundcube 我是直接在1Panel的应用市场装的Roundcube，不过默认配置有点问题我改了下端口，如下： Key Value IMAP 服务器 mail.jinvic.top IMAP 端口 993 SMTP 服务器 mail.jinvic.top SMTP 端口 465 IMAP登录时还需要手动指定SSL/TLS加密方式，我不清楚环境变量怎么改就直接改的配置文件./data/config/config.docker.inc.php，缺点是每次重启都会重置。 $config['imap_host'] = 'ssl://mail.jinvic.top:993'; $config['smtp_host'] = 'ssl://mail.jinvic.top:465'; $config['username_domain'] = 'jinvic.top'; username_domain是可选项，配置后如jinvic@jinvic.top登录时就可以直接用jinvic作为用户名了，比较方便。 至于SSL/TLS配置，我没有在roundcube里配，而是在反向代理至roundcube服务时加了https配置，实测没有问题。 完成如上配置后就可以登录roundcube客户端访问docker-mailserver服务器，进行收发邮件操作了。 250624更新 在1panel商店安装的roundcube只能使用1panel商店安装的mysql。就个人使用来说单独装个mysql还是太笨重了。为了切换到sqlite还是换成了自部署。参考官方示例改改就行。这里给出一个配置示例： services: roundcube: image: roundcube/roundcubemail:latest container_name: roundcube environment: ROUNDCUBEMAIL_DEFAULT_HOST: &quot;ssl://mail.jinvic.top&quot; ROUNDCUBEMAIL_DEFAULT_PORT: &quot;993&quot; ROUNDCUBEMAIL_SMTP_SERVER: &quot;ssl://mail.jinvic.top&quot; ROUNDCUBEMAIL_SMTP_PORT: &quot;465&quot; ROUNDCUBEMAIL_USERNAME_DOMAIN: &quot;jinvic.top&quot; # ROUNDCUBEMAIL_REQUEST_PATH: # ROUNDCUBEMAIL_PLUGINS: # ROUNDCUBEMAIL_INSTALL_PLUGINS: # ROUNDCUBEMAIL_SKIN: # ROUNDCUBEMAIL_UPLOAD_MAX_FILESIZE: # ROUNDCUBEMAIL_SPELLCHECK_URI: # ROUNDCUBEMAIL_ASPELL_DICTS: ROUNDCUBE_DB_TYPE: &quot;sqlite&quot; ROUNDCUBE_DB_NAME: &quot;/var/roundcube/db/roundcube.sqlite&quot; volumes: - ./www:/var/www/html - ./data/config:/var/roundcube/config - ./data/db:/var/roundcube/db ports: - &quot;12078:80&quot; restart: always ","link":"https://jinvic.github.io/post/self-deploy-mail-services-using-roundcube-and-docker-mailserver/"},{"title":"《SQL必知必会》阅读笔记","content":"《SQL必知必会》阅读笔记 《SQL必知必会》阅读笔记 第 1 课 了解SQL 1.1 数据库基础 1.2 什么是SQL 1.3 动手实践 1.4 小结 第 2 课 检索数据 2.1 SELECT 语句 2.2 检索单个列 2.3 检索多个列 2.4 检索所有列 2.5 检索不同的值 2.6 限制结果 2.7 使用注释 2.8 小结 第 3 课 排序检索数据 3.1 排序数据 3.2 按多个列排序 3.3 按列位置排序 3.4 指定排序方向 3.5 小结 第 4 课 过滤数据 4.1使用WHERE子句 4.2 WHERE子句操作符 4.3 小结 第 5 课 高级数据过滤 5.1 组合 WHERE 子句 5.2 IN 操作符 5.3 NOT 操作符 5.4 小结 第 6 课 用通配符进行过滤 6.1 LIKE操作符 6.2 使用通配符的技巧 6.3 小结 第 7 课 创建计算字段 7.1 计算字段 7.2 拼接字段 7.3 执行算数运算 7.4 小结 第 8 课 使用函数处理数据 8.1 函数 8.2 使用函数 8.3 小结 第 9 课 汇总数据 9.1 聚集函数 9.2 聚集不同值 9.3 组合聚集参数 9.4 小结 第 10 课 分组数据 10.1 数据分组 10.2 创建分组 10.3 过滤分组 10.4 分组和排序 10.5 SELECT 子句顺序 10.6 小结 第 11 课 使用子查询 11.1 子查询 11.2 利用子查询进行过滤 11.3 作为计算字段使用子查询 11.4 小结 第 12 课 联结表 12.1 联结 12.2 创建连结 12.3 小结 第 13 课 创建高级联结 13.1 使用表别名 13.2 使用不同类型的联结 13.3 使用带聚集函数的联结 13.4 使用联结和联结条件 13.5 小结 第 14 课 组合查询 14.1 组合查询 14.2 创建组合查询 14.3 小结 第 15 课 插入数据 15.1 数据插入 15.2 从一个表复制到另一个表 15.3 小结 第 16 课 更新和删除数据 16.1 更新数据 16.2 删除数据 16.3 更新和删除的指导原则 16.4 小结 第 17 课 创建和操纵表 17.1 创建表 17.2 更新表 17.3 删除表 17.4 重命名表 17.5 小结 第 18 课 使用视图 18.1 视图 18.2 创建视图 18.3 小结 第 19 课 使用存储过程 19.1 存储过程 19.2 为什么要使用存储过程 19.3 执行存储过程 19.4 创建存储过程 19.5 小结 第 20 课 管理事务处理 20.1 事务处理 20.2 控制事务处理 20.3 小结 第 21 课 使用游标 第 22 课 高级 SQL 特性 22.1 约束 22.2 索引 22.3 触发器 22.4 数据库安全 22.5 小结 总结 这次看到是第五版，20年7月出版。 MySQL的示例数据库在这里 最近都是通过orm操作sql，补习一下基础知识好了。简单记一下，别变成抄书就行。 第 1 课 了解SQL 1.1 数据库基础 介绍数据库，表，列，数据类型，行，主键这些基本概念，略。 1.2 什么是SQL SQL：Structured Query Language 结构化查询语言 用了这么久sql还真不熟悉全称是啥。 标准SQL由ANSI标准委员会管理，称为 ANSI SQL。其他DBMS 即使有自己的扩展也都支持 ANSI SQL。 1.3 动手实践 让你装一个sql。 1.4 小结 简单介绍sql及基本数据库术语。 第 2 课 检索数据 2.1 SELECT 语句 2.2 检索单个列 SELECT c_name FROM t_name; 提示：SQL不区分大小写。一种常用方法是关键词发现，列名表名等小写，这样有更好的可读性，但不是必须。 2.3 检索多个列 SELECT c_name1, c_name2 FROM t_name; 2.4 检索所有列 SELECT * FROM t_name; 注意：检索不需要的列会降低速度和性能，如非必须最好不适用通配符。 2.5 检索不同的值 SELECT DISTINCT c_name FROM t_name; 注意：不能部分使用DISTINCT。DISTINCT关键字作用于所有的列。 2.6 限制结果 SELECT DISTINCT c_name FROM t_name LIMIT 5 OFFSET 5; 2.7 使用注释 行内注释：-- text 或 # text 多行注释： /* text */ 2.8 小结 SELECT子句 LIMIT和OFFSET子句 注释 第 3 课 排序检索数据 3.1 排序数据 子句（clause）: SQL语句由子句构成，有些子句是必需的，有些则是可选的。一个子句通常由一个关键字加上所提供的数据组成。 以前从来没有注意过子句的概念，直到gorm里被教做人。 SELECT c_name FROM t_name ORDER BY c_name; 3.2 按多个列排序 SELECT c_name1, c_name2, _name3 FROM t_name ORDER BY c_name2, c_name3; 按ORDER BY子句中的列名顺序作为优先级排序。 提示：也可以使用非选择列排序。 3.3 按列位置排序 SELECT c_name1, c_name2, _name3 FROM t_name ORDER BY 2, 3; 提示：如果有必要，可以混合使用实际列名和相对列位置。 3.4 指定排序方向 SELECT c_name1, c_name2, c_name3 FROM t_name ORDER BY c_name2 DESC, c_name3 ASC; sql默认使用升序排序，你也可以使用ASC关键字显示指定。要使用降序排序，使用DESC关键字。 和DISTINCT不同，ASC和DESC只会影响对应列。 3.5 小结 子句 概念 ORDER BY子句 ASC和DESC关键字 第 4 课 过滤数据 4.1使用WHERE子句 SELECT c_name1, c_name2 FROM t_name WHERE c_name1 = 100; 注意在同时使用ORDER BY和WHERE子句时，应该让ORDER BY位于WHERE之后，否则将会产生错误。 这个我倒没注意过，用gorm时也没报过错，大概不同的DBMS或者ORM对这有优化吧。 4.2 WHERE子句操作符 不同的DBMS对操作符的支持不同，需要查看具体文档。 除了常规的大小等于，需要注意的操作符还有表区间的BETWEEN...AND...和判空的IS (NOT) NULL。 4.3 小结 WHERE子句及其操作符 第 5 课 高级数据过滤 5.1 组合 WHERE 子句 使用AND和OR逻辑操作符来组合WHERE子句。 AND的优先级大于OR，不过比起依赖默认顺序，更推荐使用括号消除歧义。 SELECT c_name1, c_name2, c_name3 FROM t_name WHERE (c_name1 &gt; 30 OR c_name2 &gt; 40) AND c_name3 &lt; 50; 5.2 IN 操作符 SELECT c_name1, c_name2, c_name3 FROM t_name WHERE c_name1 IN (3, 4, 5); 使用IN操作符的优点： 语法更清楚只管 和其他操作符组合使用时，求值顺序更易管理 一般比一组OR执行更快 可以包含其他SELECT语句，从而动态建立WHERE子句 5.3 NOT 操作符 SELECT c_name1, c_name2, c_name3 FROM t_name WHERE c_name1 NOT IN (3, 4, 5); 在复杂子句中NOT的易用性和可读性更高。 5.4 小结 AND和OR操作符 IN操作符 NOT操作符 第 6 课 用通配符进行过滤 6.1 LIKE操作符 先记一些专有名词和概念： 通配符（wildcard）：用来匹配值的一部分的特殊字符。 搜索模式（search pattern）：由字面值、通配符或两者组合构成的搜索条件。 谓词（predicate）：没讲清楚定义 ，但并不难理解。 以下是sql中的通配符。 %: 任何字符出现任意次数 直接'%'不会匹配NULL _:，任何字符匹配一个字符 []: 指定字符集指定位置匹配一个字符 部分DBMS不支持（如MySql） 最常见的关键词搜索示例如下： SELECT c_name1, c_name2 FROM t_name WHERE c_name1 LIKE '%keyword%'; 6.2 使用通配符的技巧 不要过度使用通配符 不要用在搜索模式开始处（速度慢） 注意通配符位置 6.3 小结 LIKE谓词 通配符 第 7 课 创建计算字段 7.1 计算字段 有时需要从数据库中检索出转换、计算或格式化过的数据，而不是检索出数据再在客户端应用程序重新格式化。 虽然很多操作都可以在客户端应用程序完成，但一般在数据库服务器上完成这些操作要快得多。 7.2 拼接字段 可以使用+或||拼接两个列。但MySql和MariaDB中则是特殊函数CONCAT()。 可以使用LTRIM()，RTRIM()或TRIM()函数去除左右空格。 可以使用AS关键字创建别名。这是可选的，但最佳实践推荐使用AS。 SELECT CONCAT(RTRIM(c_name1), c_name2) AS alias FROM t_name; 7.3 执行算数运算 也可以使用加减乘除等操作符对数字类型的字段进行计算。 7.4 小结 CONCAT()函数 LTRIM()，RTRIM()，TRIM函数 AS关键字 算术运算 第 8 课 使用函数处理数据 8.1 函数 注意：不同的函数在不同DBMS中的支持不同。即使是相同的功能，在不同DBMS中的函数名也很可能不同。所以SQL函数是不可移植的。 8.2 使用函数 大多是SQL实现支持以下类型的函数： 处理文本字符串的文本函数。 对数值数据进行算术操作的数值函数。 数量日期和时间值并提取特定成分的日期和时间函数。 生成美观易读的输出的格式化函数。 返回DBMS相关特殊信息的系统函数。 由于不同DBMS对函数的支持不同，在这里不展开。有需要查表。 8.3 小结 数据处理函数 第 9 课 汇总数据 9.1 聚集函数 与数据处理函数不同，聚集函数在各种主要SQL实现中支持基本一致。 聚集函数：对某些行运行的函数，计算并返回一个值。 AVG() 返回某列的平均值 COUNT() 返回某列的行数 COUNT(*)对行的数目进行计数，不管表列中包含的是空值(NULL)还是非空值。 COUNT(column)对特定列中具有值的行进行计数，忽略NULL值。 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 9.2 聚集不同值 对所有行执行计算，指定ALL参数或不指定（默认ALL） 只包含不同的值，指定DISTINCT参数 有的DBMS还支持其他参数。 SELECT AVG(DISTINCT c_name) AS avg_res FROM t_name; 9.3 组合聚集参数 在select中可以同时使用多个聚集参数。 9.4 小结 五种聚集函数 ALL和DISTINCT参数 第 10 课 分组数据 10.1 数据分组 举例需要对数据分组的需求。 10.2 创建分组 使用GROUP BY子句创建分组。一些规定： GROUP BY子句可以包含任意数目的列，因而可以对分组进行嵌套。 GROUP BY子句中嵌套了分组，数据将在最后指定的分组上汇总。 GROUP BY子句中每一列必须是检索列或有效表达式（但不能是聚集函数）。如果SELECT中使用表达式，GROUP BY中也要使用相同的表达式，不能使用别名。 大多数SQL实现不允许GROUP BY列带有长度可变的数据类型（如TEXT）。 除聚集语句外，SELECT中每一列都必须在GROUP BY中给出。 如果分组列中包含具有NULL值的行，则NULL将作为一个分组返回。如果列中有多行NULL值，它们将分为一组。 GROUP BY子句必须出现在WHERE子句之后，ORDER BY子句之前。 10.3 过滤分组 使用HAVING子句过滤分组。 HAVING支持所有WHERE操作符，唯一的差别是WHERE过滤行，而HAVING过滤分组。 另一种理解方法是，WHERE在数据分组前进行过滤，HAVING在数据分组后进行过滤。 SELECT c_name, COUNT(*) AS num FROM t_name GROUP BY c_name HAVING COUNT(*) &gt;= 2; 10.4 分组和排序 在特定DBMS中，GROUP BY分组时确实会按照子句的列排序。但还是推荐使用ORDER BY手动排序实现精细化操作和提高可读性。 10.5 SELECT 子句顺序 列出目前为止学过的子句顺序 子句 说明 是否必须使用 SELECT 要返回的列或表达式 是 FROM 从中检索数据的表 仅在从表选择数据时使用 WHERE 行级过滤 否 GROUP BY 分组说明 仅在按组计算聚集时使用 HAVING 组级过滤 否 ORDER BY 输出排序顺序 否 10.6 小结 GROUP BY子句 HAVING子句 第 11 课 使用子查询 11.1 子查询 子查询(subquery)：嵌套在其他查询中的查询。 11.2 利用子查询进行过滤 举例，没有新内容。 11.3 作为计算字段使用子查询 示例给出的写法感觉用JOIN更方便和易读，仅作了解。 11.4 小结 子查询 第 12 课 联结表 12.1 联结 简单介绍关系表概念和好处。 可伸缩性（scale）：能够适应不断增加的工作量而不失败。设计良好的数据库或应用程序 称为可伸缩性好（scale well）。 12.2 创建连结 -- 等值连结 SELECT c1, c2, c3 FROM t1, t2 WHERE t1.c0 = t2.c0 -- 内连结 SELECT c1, c2, c3 FROM t1 INNER JOIN t2 ON t1.c0 = t2.c0 上述两种方法的结果是一致的。 12.3 小结 连结概念 内连结（等值连结） 第 13 课 创建高级联结 13.1 使用表别名 缩短 SQL 语句； 允许在一条 SELECT 语句中多次使用相同的表 SELECT cust_name, cust_contact FROM Customers AS C, Orders AS O, OrderItems AS OI WHERE C.cust_id = O.cust_id AND OI.order_num = O.order_num AND prod_id = 'RGAN01'; 13.2 使用不同类型的联结 自联结（self-join） SELECT c1.cust_id, c1.cust_name, c1.cust_contact FROM Customers AS c1, Customers AS c2 WHERE c1.cust_name = c2.cust_name AND c2.cust_contact = 'Jim Jones'; 自然联结（natural join） 感觉没讲清楚。 外联结（outer join） SELECT Customers.cust_id, Orders.order_num FROM Customers LEFT OUTER JOIN Orders ON Customers.cust_id = Orders.cust_id; 外联结还包括没有关联行的行。在使用 OUTER JOIN 语法时，必须使用 RIGHT 或 LEFT 关键字指定包括其所有行的表。 13.3 使用带聚集函数的联结 SELECT Customers.cust_id, COUNT(Orders.order_num) AS num_ord FROM Customers LEFT OUTER JOIN Orders ON Customers.cust_id = Orders.cust_id GROUP BY Customers.cust_id; 13.4 使用联结和联结条件 讲了一堆没啥用的东西。 13.5 小结 别名 自联结 自然连结 外联结 第 14 课 组合查询 这章的UNION感觉没什么用，我好像都没用过，orm也用不上。 14.1 组合查询 使用情况： 在一个查询中从不同的表返回结构数据 对一个表执行多个查询，按一个查询返回数据 14.2 创建组合查询 使用UNION连接多条SELECT语句进行组合查询。 这里给的示例似乎有误，给了两个一样的sql语句。 UNION规则： UNION 必须由两条或两条以上的 SELECT 语句组成，语句之间用关键字UNION 分隔 NION 中的每个查询必须包含相同的列、表达式或聚集函数，但次序可以不同 列数据类型必须兼容：类型不必完全相同，但必须是 DBMS 可以隐含转换的类型 UNION 从查询结果集中自动去除了重复的行。如果想返回所有的匹配行，可使用 UNION ALL 而不是 UNION。 如果确实需要每个条件的匹配行全部出现（包括重复行），就必须使用 UNION ALL，而不是 WHERE。 在用 UNION 组合查询时，只能使用一条 ORDER BY 子句，它必须位于最后一条 SELECT 语句之后，排序所有结果。 14.3 小结 利用 UNION，可以把多条查询的结果作为一条组合查询返回，不管结果中有无重复。 使用 UNION可极大地简化复杂的 WHERE 子句，简化从多个表中检索数据的工作。 第 15 课 插入数据 15.1 数据插入 INSERT INTO tablename VALUES(v1,v2,v3); INSERT INTO tablename(c1,c2,c3) VALUES(v1,v2,v3); INSERT INTO tablename(c1,c2,c3) SELECT ... 若不指定列名，必须给按顺序每一个列提供值，如果没有值使用NULL。 省略的列必须允许为空或定义了默认值。 也可以使用INSERT SELECT直接插入查询结果。此时结果只看顺序无关列名。 15.2 从一个表复制到另一个表 CREATE TABLE table1 AS SELECT * FROM table2 15.3 小结 使用INSERT INTO插入数据 使用INSERT SELECT插入表 使用CREATE SELECT复制表 第 16 课 更新和删除数据 16.1 更新数据 UPDATE table1 SET key1 = value1, key2 = value2 WHERE ... 16.2 删除数据 DELETE FROM table1 WHERE ... 16.3 更新和删除的指导原则 除非确实打算更新和删除每一行，否则绝对不要使用不带 WHERE 子句的 UPDATE 或 DELETE 语句。 保证每个表都有主键，尽可能像 WHERE 子句那样使用它。 在 UPDATE 或 DELETE 语句使用 WHERE 子句前，应该先用 SELECT 进行测试，保证它过滤的是正确的记录，以防编写的 WHERE 子句不正确。 使用强制实施引用完整性的数据库，这样 DBMS 将不允许删除其数据与其他表相关联的行。 有的 DBMS 允许数据库管理员施加约束，防止执行不带 WHERE 子句的 UPDATE 或 DELETE 语句。如果所采用的 DBMS 支持这个特性，应该使用它。 16.4 小结 UPDATE语句 DELETE语句 第 17 课 创建和操纵表 17.1 创建表 CREATE TABLE table1 ( column1 TYPE NULL/NOT NULL, column2 TYPE NULL/NOT NULL, ... ) 17.2 更新表 不同DMBS对更新表的限制不一，需要具体查询对应文档。 ALTER TABLE table1 ADD column1 TYPE; ALTER TABLE table1 DROP COLUMN column2; 17.3 删除表 DROP TABLE table1 17.4 重命名表 不同DBMS对重命名表实现不同，需要具体查询对应文档。 17.5 小结 创建表 更新表 删除表 第 18 课 使用视图 到这里终于来点有用的了。 18.1 视图 重用 SQL 语句。 简化复杂的 SQL 操作。在编写查询后，可以方便地重用它而不必知道其基本查询细节。 使用表的一部分而不是整个表。 保护数据。可以授予用户访问表的特定部分的权限，而不是整个表的访问权限。 更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。 尽管视图是个很重要的特性，但在orm中似乎基本没有用到，类似的功能在应用层通过保存构建查询语句的过程作为变量实现。 18.2 创建视图 CREATE VIEW view1 AS SELECT ... 18.3 小结 视图为虚拟的表。它们包含的不是数据而是根据需要检索数据的查询。视图提供了一种封装 SELECT 语句的层次，可用来简化数据处理，重新格式化或保护基础数据。 第 19 课 使用存储过程 过程的功能在orm中也被应用层取代，数据库操作基本只剩下crud。虽然sql本身也算一门比较完备的变成语言能实现各种功能，但将这些实现放到应用层而不是sql里能更好地与业务逻辑相结合。 19.1 存储过程 简单来说，存储过程就是为以后使用而保存的一条或多条 SQL 语句。可将其视为批文件，虽然它们的作用不仅限于批处理。 19.2 为什么要使用存储过程 通过把处理封装在一个易用的单元中，可以简化复杂的操作。 由于不要求反复建立一系列处理步骤，因而保证了数据的一致性。如果所有开发人员和应用程序都使用同一存储过程，则所使用的代码都是相同的。 上一点的延伸就是防止错误。需要执行的步骤越多，出错的可能性就越大。防止错误保证了数据的一致性。 简化对变动的管理。如果表名、列名或业务逻辑（或别的内容）有变化，那么只需要更改存储过程的代码。使用它的人员甚至不需要知道这些变化。 上一点的延伸就是安全性。通过存储过程限制对基础数据的访问，减少了数据讹误（无意识的或别的原因所导致的数据讹误）的机会。 因为存储过程通常以编译过的形式存储，所以 DBMS 处理命令所需的工作量少，提高了性能。 存在一些只能用在单个请求中的 SQL 元素和特性，存储过程可以使用它们来编写功能更强更灵活的代码。 省流：简单、安全、高性能。 不同 DBMS 中的存储过程语法有所不同。事实上，编写真正的可移植存储过程几乎是不可能的。不过，存储过程的自我调用（名字以及数据如何传递）可以相对保持可移植。因此，如果需要移植到别的 DBMS，至少客户端应用代码不需要变动。 一般来说，编写存储过程比编写基本 SQL 语句复杂，需要更高的技能，更丰富的经验。因此，许多数据库管理员把限制存储过程的创建作为安全措施（主要受上一条缺陷的影响）。 19.3 执行存储过程 EXCUTE proc1( value1, value2, ... ) 19.4 创建存储过程 语法略，各DBMS实现不一，有需要查文档。 19.5 小结 执行/创建/使用存储过程 各种 DBMS 对存储过程的实现不一 第 20 课 管理事务处理 除了crud，orm中最常用的就是事务了。比起手动begin和commit，我更喜欢直接transaction开各事务块，内部基本不用考虑事务本身。 20.1 事务处理 使用事务处理（transaction processing），通过确保成批的 SQL 操作要么完全执行，要么完全不执行，来维护数据库的完整性。 事务（transaction）指一组 SQL 语句； 回退（rollback）指撤销指定 SQL 语句的过程； 提交（commit）指将未存储的 SQL 语句结果写入数据库表； 保留点（savepoint）指事务处理中设置的临时占位符（placeholder），可以对它发布回退（与回退整个事务处理不同）。 事务处理用来管理 INSERT、UPDATE 和 DELETE 语句。不能回退 SELECT语句（回退 SELECT 语句也没有必要），也不能回退 CREATE 或 DROP 操作。事务处理中可以使用这些语句，但进行回退时，这些操作也不撤销。 20.2 控制事务处理 老生常谈，不同 DBMS 用来实现事务处理的语法不同，需要参考具体文档。 ROLLBACK 命令用来回退（撤销）SQL 语句。 一般的 SQL 语句提交（写或保存）操作是自动进行的，这就是所谓的隐式提交（implicit commit）。而在在事务处理块中，提交不会隐式进行，需要手动提交使用 COMMIT 命令进行提交。 使用 SAVEPOINT 命令可以创建保留点（占位符），之后就可以通过 ROLLBACK 回退到特定保存点而非回退整个事务，从而实现精细化操作。 20.3 小结 创建事务 COMMIT ROLLBACK SAVEPOINT 第 21 课 使用游标 略，不同DBMS语法混在一起讲的比较杂，大致就是查询的结果集。这些在orm里直接遍历就行，也不是必须在sql里实现的操作。 第 22 课 高级 SQL 特性 22.1 约束 很多约束都可以通过代码而非约束实现，而且修改起来也方便。约束一般在建表时就得定义好，后续修改也麻烦。如果是使用纯数据库那约束确实有用，但如果是orm之类操作数据库其实没必要耗费心力。 主键： 任意两行的主键值都不相同。 每行都具有一个主键值（即列中不允许 NULL 值）。 包含主键值的列从不修改或更新。 主键值不能重用。如果从表中删除某一行，其主键值不分配给新行。 外键： 外键用于表示引用。虽然很常用但我其实很少在定义外键时声明其为外键约束。毕竟有时这个外键约束影响到数据库操作很烦，级联删除也可以通过代码实现替代约束。 唯一约束 唯一约束用来保证一列（或一组列）中的数据是唯一的。它们类似于主键，但存在以下重要区别。 表可包含多个唯一约束，但每个表只允许一个主键。 唯一约束列可包含 NULL 值。 唯一约束列可修改或更新。 唯一约束列的值可重复使用。 与主键不一样，唯一约束不能用来定义外键。 检查约束 检查约束用来保证一列（或一组列）中的数据满足一组指定的条件。检查约束的常见用途有以下几点。 检查最小或最大值。例如，防止 0 个物品的订单（即使 0 是合法的数）。 指定范围。例如，保证发货日期大于等于今天的日期，但不超过今天起一年后的日期。 只允许特定的值。例如，在性别字段中只允许 M 或 F。 同理，检查约束也可通过代码而非约束实现。 22.2 索引 所以倒是主要在建表时实现，代码的话差不多也是通过orm建表时创建索引。 索引改善检索操作的性能，但降低了数据插入、修改和删除的性能。在执行这些操作时，DBMS 必须动态地更新索引。 索引数据可能要占用大量的存储空间。 并非所有数据都适合做索引。取值不多的数据（如州）不如具有更多可能值的数据（如姓或名），能通过索引得到那么多的好处。 索引用于数据过滤和数据排序。如果你经常以某种特定的顺序排序数据，则该数据可能适合做索引。 可以在索引中定义多个列（例如，州加上城市）。这样的索引仅在以州加城市的顺序排序时有用。如果想按城市排序，则这种索引没有用处。 22.3 触发器 触发器也可在orm中通过钩子或者手动实现。 触发器是特殊的存储过程，它在特定的数据库活动发生时自动执行。触发器可以与特定表上的 INSERT、UPDATE 和 DELETE 操作（或组合）相关联。 保证数据一致。例如，在 INSERT 或 UPDATE 操作中将所有州名转换为大写。 基于某个表的变动在其他表上执行活动。例如，每当更新或删除一行时将审计跟踪记录写入某个日志表。 进行额外的验证并根据需要回退数据。例如，保证某个顾客的可用资金不超限定，如果已经超出，则阻塞插入。 计算计算列的值或更新时间戳。 一般来说，约束的处理比触发器快，因此在可能的时候，应该尽量使用约束。 22.4 数据库安全 需要保护的操作： 对数据库管理功能（创建表、更改或删除已存在的表等）的访问； 对特定数据库或表的访问； 访问的类型（只读、对特定列的访问等）； 仅通过视图或存储过程对表进行访问； 创建多层次的安全措施，从而允许多种基于登录的访问和控制； 限制管理用户账号的能力 22.5 小结 约束 索引 触发器 数据库安全 总结 200多页很快就读完了。虽然章节很多，但每一章内容都很少10分钟就能搞定，看完整本书也要不了几个小时。 因为很多内容不同DBMS的实现不同，所以这本书也没办法深入去讲只能提一嘴一笔带过。 除了crud和事务以外的操作，在orm中基本都不会用到。类似的逻辑可以大多可以通过代码而非sql实现，对非专业db工程师的程序员来说更友好。至于一些需要DB本身特性才能更快更好处理的需求，也可以通过rawsql实现。 确实是很适合初学者入门的书，各种基础知识点简明易懂，可以快速掌握sql基本用法。但对我就作用有限了，只有最后几章有点用。还是得找进阶一点的书来看。 ","link":"https://jinvic.github.io/post/[sql_in_10min_a_day]-reading-notes/"},{"title":"2024年终总结","content":"2024年终总结 2024年终总结 写在开头 学习 学生 社畜 生活 工作 爱好 CODE ACGN Anime Comic Game Novel 结语 写在开头 心血来潮想写个总结，是受到review-2024这个项目的启发，有一位我订阅了RSS的作者发表了他的总结顺便在文章中宣传了一下。几个月前刷到review-2023时我还是个看客，这次倒是感觉真可以尝试写点东西了。不过我这人向来没什么过去可言，转头就忘，开始有意识地记录日常也只是最近三个月的事情，更久远的事情只能凭借模糊的记忆和稀缺的文字记录简单写写了0。 学习 学生 明明才过去几个月，学生时代的事情已经十分模糊甚至带上几分朦胧且美好的“回忆滤镜”了。从毕设的记录来看1，前半年差不多都花在这件事上了。而具体学了些什么呢？其实也没多少，主要集中在前期的爬虫相关知识上，后面的LSTM相关，为了赶进度都是拿来就用，没有深入研究了，比较可惜。再往后就是无尽的写文档改文档，没什么意思也没学到什么东西。其余更多学生时代的事情，都是23年末期的事了，24年好像还真没什么好记录的。 社畜 参加工作伊始，基本是被放养的状态，给几个技术让我自己学。这段时间了解了go，啃完了gin，gorm和goredis的官方文档，主要是gorm，gin和goredis的文档倒没多少，基本靠的是第三方的教程来学。学完这些算是搭建起了基本的后端开发技术栈，即web框架+数据库驱动(ORM)2。之后的工作内容就跟着项目需求的技术栈走了。 在一个项目中接触了goframe，其对庞大完备的工程规模和模块设计叹为观止，给刚出学校没多久的学生党一点小小的软件工程震撼3。虽然之前实习时也接触过spring，但只不过是速成式完成任务式的浅尝辄止，没有去真正了解4。 另一个项目用的是kratos，这是一个微服务框架，不过我并没有深入了解微服务，还是和之前一样负责部分功能写业务代码。虽然没深入微服务，但也接触和学习了不少新东西。首先是Protobuf这个序列化技术，相当于一种通用的数据结构定义，简单学一种新的语法就行。然后是Wire这个依赖注入工具，但我只是简单了解了下依赖注入，没有实践过经验不深，以后有空肯定是要拿出来练习熟悉下的。再是swagger这个生成API文档的工具，直接通过注释生成API文档比手写方便。这个虽然我之后又自己用过一次，但还是不够熟悉，提升空间很大。最后是重量级的orm框架ent，提起这个我真的是一肚子的苦水（支持以色列，中文文档差，语法不全，主键写死...），实在是喜欢不起来5 6。 kratos这个框架文档不太全，入门时稍微摸索了下7。其他主要是各种CLI工具的安装使用搞得我有点晕，虽然给了个总的CLI工具kratos，但学习各个组件的过程还是免不了去单独安装调试使用，还好找到了just这个工具能够简化命令的管理和使用。 除了工作需求的技术栈，还慢慢啃完了《Go程序设计语言》这本书8，主要是在最开始的自由学习的那段时间，看完了前七章和第八章部分作为go语言入门，某种程度上来说基础语法还挺简单的（复杂的都封装成库了），有c++或java基础入门很快。之后工作忙放下了一段时间，再捡起来明显感到力不从心9，不过还是磕磕绊绊读完了。其实读的并不深只是大致过一下，以后有机会肯定是要重读一遍的。不过我觉得更重要的是建立相关的知识体系和扩宽知识面。用更通俗的说法来讲，就是你最起码知道了这个东西是你不会的，而不是连这个东西的存在都不知道，对知识本身的认识也是一种知识。就好像一个侃侃而谈的人，即便各个方面都很浅显也会让人觉得很厉害，毕竟他懂得多嘛。 现在主要感觉自己在SQL方面有点力有未逮，只是拿着学校学的那点三瓜两枣在糊弄，稍微遇上复杂点需求的就歇菜了。很多更高级更深入的内容，就如上面所说的，连自己不知道什么都不知道，直到查一下才恍然大悟原来还有这么个东西还能这样。所以现在迫切需要搭一个知识体系的框架出来，填不填充再说😋。 除了Mysql，另一个常用的数据库是mongoDB，这个就更惨了，连最基本的增删改查都不怎么熟，文档也没怎么看。现在用到它更多只是一些简单的数据查询，有需要现查语法就行，有空再精进一下。更常用的还是mysql，优先级更高。此外。我也不是很喜欢mongoDB这种结构不固定的数据，感觉处理起来很麻烦。存数据一时爽取数据火葬场，当然也可能是我不够了解的原因。 生活 一提到这些，又忍不住去追忆学生时代了，明明才过去几个月而已。虽然我完全没有什么所谓的“美好的青春”，基本都是窝在寝室打游戏，但偶尔也是会被朋友拉出去走走，哪怕只是下个馆子。而现在独居后，一个人占个四人桌，就算店员不说我自己都不好意思，在外面吃饭一般都在快餐店解决的。过去看来不起眼的小事，现在竟某种程度上成了一种奢求了。虽然我对社交的需求很低，工作了几个月也没和同事讲过几句话，但完全没有社交，有时也会感到烦闷。 至于现在的生活，倒也没什么不满。以前宿舍食堂教学楼三点一线，现在宿舍食堂办公室，感觉也没什么区别，甚至距离还更短了。待遇也还算满意，单人一间宿舍，虽然隔壁有个舍友但隔了扇门平日互不打扰也挺好的。食堂伙食一般，虽然可以加钱吃点好的，但评估了一下性价比后还是每餐只吃最便宜那档，实在不行回寝室煮面。对了，我还买了个电磁锅放在宿舍，最开始是想着除了烧热水还能干点别的，就在电磁锅和热水壶之间选择了前者。但买回来除了烧热水还是烧热水，而且还没热水壶方便。因为买菜储存处理什么的都不方便所以完全没做过别的菜，现在成了煮面特化。买了一套简单的砧板和刀具，偶尔吃点水果，比起削皮更喜欢切丁，虽然有点迪拜刀法。此外还买了很多东西，比如桌子（折叠的），椅子（拼装的），凳子（买桌子送的）等家具，一番布置后倒没什么所谓的“家的感觉”，只是从原来的空空荡荡变得可以住人了而已。 本来是个能几个月都不挪窝的死宅，但现在每周放假都要出去逛逛。倒不是多么想玩，主要是闷久了透透气，毕竟现在住宿舍吃食堂，一个星期都在这方圆百米内打转。一般上午九点半出门，去机厅堵门打mai。我去的那家机子还挺全，光mai有旧框日框国区三种，此外中二，sdvx，jubeat，wacca，IIDX应有尽有。就是中二机况不太好，sdvx好像是坏的，jubeat，wacca不感兴趣，IIDX偶尔搓两把。其实之前附近还有家音游窝小店以前来过，这次再去看倒闭了。这家店的部分机子应该就是从那来的。刚开始的时候会一直玩到很晚快闭店才回去，毕竟以前不喜欢出门没机会接触街机音游，多少有点乐不思蜀了。现在则是堵门趁着人少打一上午，中午吃个饭回来看一眼，人多就走人少就再玩会。本来开始的时候下午还会去牌店，也是以前没去过就去逛逛，还能锻炼下交流能力。不过后来就没去了，一是只恨财力不足实卡跟不上环境，二是入坑时间不长其实也不是很聊得来。现在下午都是去超市逛一圈看有没有什么想买的要添置的，然后回宿舍打游戏。 工作 工作有什么好总结的吗？好像都在前面聊的差不多了。现在的岗位是后端开发，选这个方向只是不想做前端，当时对各种方向不是很了解，就以为是前端做界面后端做逻辑，不想做界面选的后端，好在干的活和预期有差别但不大。现在的实际工作内容主要是crud，更复杂的业务有更资深的前辈做，我就打打杂做点简单的部分。工资水平在业内算是偏低的，不过生活条件还行开销较低，我个人完全可以接受，没啥经济压力自己够用就行，顶多对未来发展有点迷茫，不过将来的事将来再说。 话说回来，我当时一个宿舍六个人，现在除了一个保研的就我一个干的本专业的工作，可见现在就业行情真的不好。我的毕业院校是一个普通一本，上比不过985211的高学历，下比不过专科院校的低要求，属于典型的端不起架子又放不下身段了，也就是所谓“孔乙己的长衫”罢。话说回来，我大概也算所谓的“小镇做题家”了，村里的人一听一本就是这孩子不得了，可到了社会上所谓的一本学历什么也不是，这下全对上了（自嘲）。偶尔刷到一些面经贴，作者准备如何如何翔实最后成功拿到大厂offer上岸，看完后都会觉得很焦虑。觉得别人找到工作时都这么厉害，而我什么都不会随时可以被取代，虽然我在的也不是什么大厂。 爱好 想了想好像除了ACGN就没有别的爱好了，果然是阴暗的死宅。勉强把编程也加进去，虽然已经变成工作了但也还算是爱好，并且工作之外也有不少折腾还是值得记一下的。希望以后能多点别的爱好吧。 CODE 最早是八月的时候看到活动，38买了一年2h2g的华为云服务器，想着总会用上的，折腾了一下没整明白就放那了。然后10月还是11月的时候，折腾rustdesk看到可以自建，想起来自己还有台服务器就又捡了回来。顺便提醒下大家想买服务器最好乘着新人折扣第一次就买好点买就点，不然后续升级续费即麻烦还贵10。 本来用的是华为云给的镜像里自带的宝塔面板，虽然对这个产品没啥好感，懒得折腾就用着了。但它一个劲地弹窗让你买vip，忍无可忍换了1Panel。虽然也分社区版和专业版，但清爽多了至少不会主动打扰你，而且专业版的功能对我这个轻度用户而言也用不上。 列一下目前服务器上部署的项目吧： rustdesk 开源的远程桌面软件，虽然有免费服务器但速度较慢，自建就快很多了，体感延迟和蓝牙耳机差不多，完全可以接受。不过我建了这个后其实没用过几次，毕竟回了寝室谁还想工作啊，有需要报个加班就行还能赚加班费。 Gotify 一个用户用于发送和接收消息的简单服务器。我主要是配合SmsForwarder来转发验证码，这样就不用登录时掏出手机查看验证码了。 webdav 经常见到webdav这个存储方案，就了解了一下然后自建了。不过现在没怎么用这个了，都是alist+百度网盘当webdav用。 AList 一个支持多种存储的文件列表程序。如上，我主要是拿它当网盘用，支持的存储方案还挺多的只不过我用不上。 moments 极简朋友圈，可以当微博客用，我主要是看重它的小型和轻量化，毕竟我的需求很简单最低支持个Markdown就行。数据存储一个sqlite搞定不需要额外配数据库，以后如果需要迁移起来也方便。 Bitwarden 说是说bitwarden，其实用的是vaultwarden，是非官方的Bitwarden服务器实现。因为官方版本占用资源太大，而这个版本更适合个人部署使用，兼容Bitwarden客户端，只是换个服务端。 最开始部署这个是想用2fa来着，毕竟密码管理器我已经用着Google Password Manager了，没有迁移需求。但部署完了才发现2fa是另一个移动应用不归服务器管，就换2fauth了。不过这个bitwarden还是留着没删，毕竟来都来了。以后嫌占位置了再删吧。 2FAuth 和Gotify一样，需要输验证码时懒得掏手机部署的，配合扩展程序使用很方便。 EasyImages2.0 虽然在博客和微博客的选择上都尽量选择了自带图床的方案，但总是会有奇奇怪怪的地方需要贴图片，所以还是部署了一个图床。只是需求很低平时很少用而已。 mkdocs-material mkdocs是一个方便构建文档的静态站点生成器。material则是mkdocs的一个主题。感觉多级页面管理笔记之类比单篇的博客方便，也是作为gitbook的替代11 12 13。 chatgpt-web 一个简单的ChatGPT前端页面。其实类似的实现有很多，但这个最简洁干净选的这个。搭这个的起因是deepseek发了v3送了token就想试试。本来是koishi+napcat搭建的QQ群Bot，但一天不到就被腾讯拿下了14。因为腾讯开发者平台的机器人个人开发者只能频道不能群聊，干脆不做bot了。然后chatluna的猫娘预设感觉挺有意思放弃有点可惜，就找了个GPT前端转生15。 pure-ftpd 虽然ftp很常用，但最开始还真没打算装这个，少数上传需求直接在1Panel面板里解决了。但之后做Github Action的自动部署时用到FTP-Deploy-Action这个插件需要ftp就还是装了。话说回来自动部署写好脚本后真方便，有什么更改改完一推就什么也不用管了16。 mihomo 代理软件。有时git，pnpm，docker这些会抽风用不了，比起镜像站还是代理好用些。对linux生态不太了解折腾了几次配置没整好没装成功，最后用ShellCrash弄好的17。 ACGN 还好有bungumi，不然我自己肯定记不住自己都看了那些作品。总结的话就只挑一部分值得聊的说说吧，详情请移步bgm Anime 把22年整年的番，感兴趣和暂无续作计划的都补了。评价最好的是《异世界舅舅》和《孤独摇滚》，不过这两部本来就是带这高期待去看的，所以好是好但也没有《映像研》那种意料之外的惊艳。这也是延迟补番的弊端了，虽然可以很好地避雷，但也少了遇到佳作时的惊喜。 Comic 相比于AG，CN这块其实是纯凑数的，列出来为了队列整齐而已。相比动漫一季12集的短平快，漫画日轻动辄连载好几年，个人又习惯补完结而不是追连载，所以很多感兴趣的作品都是标记后等完结等忘了，就算是完结作也因为没有补漫画的习惯想着有空补就也忘了。 Game 今年的游戏主要是前半年在学校玩的，毕业参加工作后虽然攒钱换了新电脑但却没什么空玩游戏了，比较可惜。 刺客信条系列： 今年补了《叛变》《大革命》《枭雄》三作，算是把旧作全部补完了18。叛变基本就是黑旗换皮，相同的系统填充两个不同的故事。而到了大革命和枭雄这两部时，已经不需要带着那种对老游戏的宽容了，完全可以以当代玩家的视角来审视。神话三部曲好像变动较大，而且评价也在逐渐下行，不过有空还是会补。而最近《影》的节奏很大，看最后质量过得去的话应该还是会边骂边买。毕竟AC系列作为我的单机游戏入坑还是很有情怀的。育碧死不死的无所谓，只是希望别再糟蹋这个IP了。 音游： 移动端音游都退坑了，无论是arc的爬梯子还是pjsk的活动甚至签到都有种上班打卡的感觉。之前是凭着一股惯性一直玩下来的，但停下来后感觉轻松多了干脆直接退坑眼不见为净，不然总会想着某某奖励没拿到。买了个2k+的exmax+手台，高中时就想要这玩意了现在过了好几年终于入手，但玩的次数不多。bms现在还是菜逼不怎么打的动，osu!mania回坑倒是通过越级稍微推了推分，但还是马上就afk了。一方面是感觉没以前厉害有种落差感，另一方面也是怕高强度打4k给手台干坏。街机方面mai倒是几个月推到了w3，还记得入坑时打个红十就满足了，现在离曾经仰望的w4也不远了。只是现在有些浮躁满脑子都是紫谱开大歌，没什么心情红谱练底力，毕竟紫谱的谱面设计确实更有意思。IIDX因为机厅有也入坑了，刚开始不熟悉指法走了点弯路，好在刚入坑影响不大。虽然现在也还是菜，连最基本的映射都磕磕绊绊，果然7+1还是太难了。 黑神话悟空： 聊24年的游戏肯定绕不过黑神话。最开始我对这部作品的期待并不高，毕竟见过太多卖国产情怀和卖宣传片的作品。在我看来能达到《光明记忆》那种水平就行，做个demo性质的作品招人拉投资。但随着消息不断放出也渐渐打消了疑虑，还是在预购的最后几天入了豪华版。后面的故事大家都很熟悉了，出乎意料的爆火也带来了不少争议。在我看来，这游戏当然远称不上完美，糟糕的寻路，频繁的吞指令，不合理的受击硬直，不少boss招式为了演出效果导致体感很差，以及第六章堪称灾难的完成度。这些问题累积起来让我大概只能给到8分这个档次。但这游戏的出现本身就已经足够有意义了。我仍记得那些从来对游戏不感兴趣的亲戚长辈，在闲聊时居然会提起主动这款游戏，询问我有没有玩过，并让我也带着那些子侄辈去体验一下。这份认同，让我们这些从游戏机禁令以来一直被主流社会舆论排斥在外口诛笔伐的游戏玩家，第一次挺直了腰杆。也正是这份认同，让我最终还是打出了满分。 Novel 我补CN一般都是为了补A的原作，而N在这方面少之又少，今年更是一部感兴趣的都没有，基本属于是被放弃的状态。 其实比起日轻看的更多的是国内的网文，基本都是起点系的。因为习惯避开大热作品，今年看过的作品中并没有值得单独拿出来讲的，毕竟沙里淘金也不是那么容易，绝大多数都是还行，有点意思，但不够好。比起近年的新作品，我更常看的反而是初高中时随便找的老文，看新文看腻了就回去再刷一遍。也许我看的不是文，只是借此追忆那段躲在被窝里偷偷看小说的时光而已。 结语 懒得写了，就这样吧。已经比预期写的长得多了，这还是删了许多板块的情况下。又不是写作文，还要在结尾来个升华什么的...明明学生时代最讨厌的就是写作文，现在随便东拉西扯就是几千字。言归正题，今年的关键词，应该就是“迷茫”和“随波逐流”了，没有什么明确的目标和规划，把生活搞得一团糟。希望来年能做出改观吧。 2025.1.17 ","link":"https://jinvic.github.io/post/2024-year-end-summary/"},{"title":"记一次向koishi添加插件时的错误处理和修改","content":"给qq机器人绑osubot，用的@tr4nce/osu-bot插件，需要HitCircle API作后端，就用docker装这个，3个多G的镜像，还好不怎么吃内存，我现在缺的就是内存。 跑HitCircle API时报错： RuntimeError: 'cryptography' package is required for sha256_password or caching_sha2_password auth methods 因为mysql从8.0.3开始将默认的身份认证插件从mysql_native_password更改为caching_sha2_password，所以这里缺了个包。如果是手动部署直接在requirements.txt里加一行就行，但我用到是docker compose，只好在docker-compose.yml里加一行： services: api_backend: command: sh -c &quot;pip install cryptography &amp;&amp; uvicorn main:app --host 0.0.0.0 --port 8900&quot; image: tr4nce/hit-circle-api:latest ... 调试几次后又报错：Error response from daemon: No such container:，把新加的一行删了就好了。而且之后也没再报缺依赖。虽然不知道怎么回事但解决了就行吧。 关于redis，它本来是在docker-compose.yml又拉了一个redis镜像。我本来想换成宿主机的redis，但不能localhost直连，如果换公网ip因为它的镜像写死了不能用密码，我如果把本地redis改成无密码再暴露到公网风险太大，还是用的镜像。 即使是再同一个docker-compose.yml里，两个镜像也是各自独立的网络命名空间，不能localhost，得用服务名称作为主机名才行，即redis:6379。 别看搞这么麻烦，其实手动部署很简单就能解决，改下源码加个密码的配置项就行。这就是docker，部署起来确实方便，但遇到问题要改点啥也很麻烦。 然后插件本身也有点问题，因为它的命令全写的一级命令不好管理，我之后装其他bot还可能冲突，我就只好看看文档看看源码自己改一下。虽然对前端一窍不通，但和别的插件源码对照一下还是改好了，记一下怎么改： 首先再koishi安装目录下找到下载的插件，我这是/koishi/data/node_modules/@tr4nce/koishi-plugin-osu-bot/lib 在index.js里把一级指令改成二级指令，使用/或者.分隔，示例如下： // ctx.command('bind &lt;username: text&gt;', '绑定osu账号') ctx.command('osu.bind &lt;username: text&gt;', '绑定osu账号') 然后在locate/zh-CN.json改下文档。这里建议copy一份源码的yml改，改起来方便些: // 更改前 commands: bind: description: 绑定你的 osu! 账号到你的 平台 账号 ... // 更改后 commands: // 添加一级指令 osu: description: osu! 相关指令 // 其余命令都向右缩进作为二级指令 bind: description: 绑定你的 osu! 账号到你的 平台 账号 然后把yml转成json再压缩一下就行。 ","link":"https://jinvic.github.io/post/Record-error-handling-and-modification-when-once-adding-plugin-to-koishi /"},{"title":"Linux配置ClashMeta内核","content":"Linux配置ClashMeta内核 配置项没弄好，换 数据删除 解决了，感觉前面的工作都白干了。但写都写了还是发篇博客。 安装homebrew 使用homebrew安装mihomo。注意：homebrew不建议使用root用户直接安装，建议新创建一个用户再添加到sudo用户组。例如创建新用户brew: sudo useradd brew sudo passwd brew # 设置新用户的密码 sudo usermod -aG sudo brew 完成后使用新用户账号密码登录，可以使用groups命令检查用户是否属于sudo组。 使用如下命令安装homebrew： /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; 如果出现如下报错： Error: Failed to install Homebrew Portable Ruby and cannot find another Ruby 3.3! If there's no Homebrew Portable Ruby available for your processor: - install Ruby 3.3 with your system package manager (or rbenv/ruby-build) - make it first in your PATH - try again 提示说找不到适合你的处理器架构的Ruby 3.3版本，需要自已装一个ruby，安装方法不在此赘述。我是在wsl上出现这个问题的，云服务器上没有出现。 安装Homebrew成功后，需要手动将其添加到PATH路径： echo 'export PATH=&quot;/home/linuxbrew/.linuxbrew/bin:$PATH&quot;' &gt;&gt; ~/.bashrc source ~/.bashrc 然后使用brew -v验证homebrew是否能够正常使用。 安装mihomo 使用homebrew可以很方便地安装mihomo： homebrew install mihomo 安装完成后提示信息如下： You need to customize /home/linuxbrew/.linuxbrew/etc/mihomo/config.yaml. To start mihomo now and restart at login: brew services start mihomo Or, if you don't want/need a background service you can just run: /home/linuxbrew/.linuxbrew/opt/mihomo/bin/mihomo -d /home/linuxbrew/.linuxbrew/etc/mihomo 提示你配置文件创建在/home/linuxbrew/.linuxbrew/etc/mihomo/config.yaml。有需要可以参考文档进行修改。 如下是一些使用homebrew services操作mihomo的命令： brew services start mihomo # 启动服务 brew services stop mihomo # 停止服务 brew services list # 查看服务状态 brew services restart mihomo· # 重启服务 【可选】： 个人比较喜欢用just管理命令。.justfile文件如下： start: brew services start mihomo stop: brew services stop mihomo list: brew services list restart: brew services restart mihomo alias st:=start alias sp:=stop alias li:=list alias re:=restart 用户界面 完全靠参数也不方便，我们先来配置ui界面。可选的面板有yacd,metacubexd等。 数据删除 下载压缩包并解压。然后往配置文件中添加如下内容： external-controller: 0.0.0.0:9090# RESTful API 监听地址 secret: your_secret # `Authorization:Bearer ${secret}` # 设置登录面板的密码 external-ui: /home/brew/mihomo/metacubexd-gh-pages/ # 换成你压缩包解压出来的文件夹的地址 端口按需求改，地址换成你自己的，保存后重启服务。在防火墙和安全组开放相关端口后，访问http://&lt;你的服务器ip&gt;:9093/ui即可登录面板。 代理配置 见 数据删除 。 更方便的用法是使用现成的客户端，如 数据删除 ，数据删除 。 https配置 虽然注释写着要配置tls的证书路径，但实测只要反向代理时配了证书，配置项里写一下https的端口就行。 如果不进行反向代理直接通过ip和端口号访问才需要在设置里配证书路径。 # 直接通过ip访问还需要配置证书 tls: certificate: string # 证书 PEM 格式，或者 证书的路径 private-key: string # 证书对应的私钥 PEM 格式，或者私钥路径 # 反向代理只需要配置https端口 external-controller-tls: 0.0.0.0:9443 # RESTful API HTTPS 监听地址，需要配置 tls 部分配置文件 ","link":"https://jinvic.github.io/post/configure-clashmeta-kernel-for-linux/"},{"title":"Certbot申请泛域名SSL证书并自动续期","content":"Certbot申请泛域名SSL证书与自动续期 Certbot申请泛域名SSL证书与自动续期 安装 Certbot 域名验证&amp;证书生成 nginx配置证书 自动续期 参考：使用 Let’s Encrypt 免费申请泛域名 SSL 证书，并实现自动续期 本来不打算写这篇的，原教程已经很详细了。不过他使用的腾讯云，在自动续期这块有个cli工具可以用。而我用的华为云只能调api，所以还是得自己摸索下顺便记录。 安装 Certbot 虽然很想用包管理器，但官网都只用snap和pip安装，为了保险还是用到snap。 sudo snap install --classic certbot #安装Certbot sudo ln -s /snap/bin/certbot /usr/bin/certbot #创建一个符号链接，确保可以执行certbot命令（相当于快捷方式） 域名验证&amp;证书生成 Certbot需要验证你申请证书的域名是否确实属于你。具体流程就是给你个随机字符串让你解析到固定域名它再来验证。 sudo certbot certonly --manual --preferred-challenges dns -d *.example.com -d example.com 记得替换你的邮箱和域名。然后他会请求你的邮箱用于紧急更新和安全提醒。 然后是两次确认。第一次是服务条款选是，第二次是问能不能给你邮箱发广告邮件，可以选否。 接着就是给你一串字符串去解析到对应域名。例如我就是将那一串解析到_acme-challenge.jinvic.top。具体解析方法看你的DNS服务商，重点是记录类型要选TXT。 添加解析完成后稍等一会再继续。你也可以在这里验证解析是否成功。 验证成功后就会自动生成证书，并告诉你证书所在目录和过期时间。 nginx配置证书 server { listen 80; server_name example.com www.example.com; location / { return 301 https://$host$request_uri; } } server { listen 443 ssl; server_name example.com www.example.com; ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; location / { proxy_pass http://127.0.0.1:8080; } } 自动续期 内容有点多，新开了个项目：Jinvic/certbot-huaweicloud。用这个项目生成供certbot钩子运行的程序。 certbot renew --manual --preferred-challenges=dns \\ --manual-auth-hook /path/to/project/bin/certbot -use auth \\ --manual-cleanup-hook /path/to/project/bin/certbot -use cleanup \\ --deploy-hook &quot;sudo nginx -s reload&quot; /path/to/project/bin/certbot 为你编译生成的程序路径。 sudo nginx -s reload 用于重新加载配置nginx配置。 编辑生成的程序需要读取配置文件。cd到项目目录或者将配置文件.env放到程序同一目录再执行上述命令。 ","link":"https://jinvic.github.io/post/use-certbot-to-apply-for-a-pan-domain-ssl-certificate-and-automatic-renewal/"},{"title":"Linux搭建Webdav服务","content":"Linux搭建webDav服务 Linux搭建webDav服务 webdav webdav安装配置 启动&amp;重启服务 webdav justfile alist alist 安装配置登录 连接存储 alist justfile 客户端 raidrive davfs2 一直都有一个文件存储传输同步共享的需求，但苦于没有太好的解决方案。qq不安全难预览还会改你压缩包后缀名，纯强盗逻辑逼着你用他家的垃圾产品生态。百度网盘则是众所周知的限速。虽然我有会员，但感觉还是更适合长期大容量存储而非短期临时的频繁存取，自带的同步空间也不好用只能同步固定文件夹。WPS倒是可以自选同步文件夹，但本来就不是做文件管理这行的使用体验极差，遇上个几百兆的pdf就歇菜了，连基础的文档服务都做不好感觉纯噱头。现在打算在服务器上自己搭一个服务，不想再受这些鸟气。 本次搭建webdav使用hacdias/webdav，教程参考readme文件和博客使用docker搭建webdav应用。 webdav 首先准备一个专门的文件目录，用于放置配置文件和作为webdav的存储路径。这里我的路径是service/webdav。 webdav安装配置 webdav配置： 在目录下新建文件config.yml，写入如下内容： # 监听任意网卡，多网卡可指定对应ip address: 0.0.0.0 port: 6065 auth: true prefix: / modify: true rules: [] # 跨域设置 | 不是很懂 cors: enabled: true credentials: true allowed_headers: - Depth allowed_hosts: - http://localhost:6065 allowed_methods: - GET exposed_headers: - Content-Length - Content-Range # 用户信息，如果 auth 为 true 生效 users: - username: admin password: admin # 配置自己的 webdav 访问范围，此例为 /data 内所有文件 scope: /data # 配置用户权限 默认为R（只读） permissions: CRUD 其中port是docker容器内的端口，可以自行修改。cors跨域设置这块不是很懂。后面的用户信息记得改改用户名和密码，以及根据需求配置用户权限。 docker配置： 在目录下新建文件docker-compose.yml，写入如下内容： services: webdav: image: hacdias/webdav container_name: webdav restart: always ports: - 6065:6065 volumes: - ./data:/data - ./config.yml:/config.yml 其中port前部分改成你在服务器上要使用的端口，记得开放防火墙和安全组。后部分则是docker内端口，和配置文件保持一致。 volumes的路径我使用的相对路径，也可以根据需求自行修改。第一行是webdav的文件存储位置，第二行是你的配置文件位置。 启动&amp;重启服务 配置项完成后，使用sudo docker-compose up -d启动服务。 如果你修改了配置文件，如添加用户或修改密码，可以使用sudo docker-compose restart webdav重启服务。 webdav justfile just 为您提供一种保存和运行项目特有命令的便捷方式。 just地址 just文档 webdav相关命令的justfile如下： alias re := restart run: sudo docker-compose up -d restart: sudo docker-compose restart webdav del: sudo rm -r data/ alist alist: 一个支持多种存储的文件列表程序，使用 Gin 和 Solidjs。 搭了个webdav本来该到此为止的，但又发现一个alist好像挺有意思，见猎心喜搭来看看。我就说明明webdav很常用但教程相对偏少，原来都用的这个。相当于一个中间层，使用alist连接不支持webdev的文件存储方案（如百度网盘），就可以把alist当webdev连接了。 alist 安装配置登录 我是使用的docker安装，直接使用官方提供的docker-compose： services: alist: image: 'xhofe/alist:latest' container_name: alist volumes: - '/etc/alist:/opt/alist/data' ports: - '5244:5244' environment: - PUID=0 - PGID=0 - UMASK=022 restart: unless-stopped 使用sudo docker-compose up -d启动服务。然后访问&lt;服务器地址&gt;:5244登录控制台。初始账号为admin，密码随机生成，通过sudo docker logs alist查看日志： 登录后记得修改密码。 连接存储 连接存储直接看官方文档就行。 有一点需要注意，我连接自建的webdav时直接用&lt;ip&gt;:&lt;port&gt;报错：first path segment in URL cannot contain colon，需要加上http(s)://协议头。 alist justfile alist 相关命令的justfile如下： alias re := restart alias upd := update run: sudo docker-compose up -d restart: sudo docker-compose restart alist update: sudo docker-compose pull | \\ sudo docker-compose up -d log: sudo docker logs alist 客户端 raidrive 可以使用raidrive将Webdav挂载到电脑盘。配置示例如下，依次填入你的服务器地址，配置中设置的端口号，账号密码： 注意：如果你在配置中没有设置tls，不要勾选&quot;地址&quot;旁边的&quot;安全连接&quot;复选框。 davfs2 Lunux系统挂载webdav可以使用davfs2，参考这篇文章 ","link":"https://jinvic.github.io/post/build-webdav-service-on-linux/"},{"title":"碎碎念 2024-12","content":"碎碎念 已迁移： 已经迁移至自部署的微博客项目。 碎碎念 2024-12-03 2024-12-03 08:04:00 2024-12-04 2024-12-04 10:26:55 2024-12-05 2024-12-05 09:40:54 2024-12-05 10:24:13 2024-12-05 15:24:43 2024-12-06 2024-12-06 15:49:09 2024-12-09 2024-12-09 15:26:24 2024-12-09 16:40:53 2024-12-11 2024-12-11 08:15:14 2024-12-11 15:24:17 2024-12-12 2024-12-12 16:47:34 2024-12-13 2024-12-13 08:44:54 2024-12-13 11:18:42 2024-12-13 15:43:09 2024-12-03 2024-12-03 08:04:00 搭了RustDesk的自建服务器，试了一下速度挺快的，比之前的免费服务器好多了。之前卡的几乎用不了，现在虽然还有明显迟滞，但也和蓝牙耳机听歌的延迟差不多完全可以接受。 说是搭了，其实也是在宝塔的应用市场一键部署的。不是很敢折腾，这段时间已经重装系统好几次了。。。能一键装好就不自己装了，之后也打算搞点版本控制和包管理器来。 2024-12-04 2024-12-04 10:26:55 查表建树，递归，爽。 2024-12-05 2024-12-05 09:40:54 因为没问清需求导致这段时间部分工作白做了。 我倒是没什么，不过前端好像很崩溃的样子（缩头）。 2024-12-05 10:24:13 花三百多续了一年服务器，服务器好贵。 花三百多买了十年域名，域名好便宜。 把博客绑到blog.jinvic.top了，欢迎访问。 2024-12-05 15:24:43 经典踢皮球。 一些给第三方接口的参数要按照固定格式存json字符串，我懒得解析让前端拼，前端不想拼要传给我来拼。 所以这到底是前端还是后端的活？ 2024-12-06 2024-12-06 15:49:09 mongoDB真难用，半途接手的我面对一堆稀奇古怪的字段头都大了。 我很少对某项技术抱有如此大的敌意， 一般不感兴趣就过了去找替代品。但工作嘛，用什么技术栈又不是自己说了算。 上一个这么讨厌的是ent，感觉可以搞个人红黑榜了。 2024-12-09 2024-12-09 15:26:24 难得闲了下来，想把之前读了一半的书捡起来继续读。虽然留了书签，但毕竟隔了两个月，看了几段还是大脑一片空白，完全不在状态。没想到只是间隔一段时间影响会这么大，以及自己连一口气读完一本书都做不到。 2024-12-09 16:40:53 “不要通过共享内存来通信，而应该通过通信来共享内存” 在学go的竞态时看到这句话，感觉很有道理，记一下。 2024-12-11 2024-12-11 08:15:14 昨天花时间在服务器上搭了webdav和alist，感觉还不错。虽然好像不怎么用的上，但感觉总会用上的还是搭了。 感觉多少有点报复性心理存在吧。以前有需要时没那条件，现在有条件了就算没多大需求也要折腾一下。就和买东西一样，一台1060的笔记本陪我征战了五年实在卡的用不了了，干脆把两月工资砸进去换了高配电脑。不过我本来属于对画质不敏感的那类人，2K画质拉满也游戏体验也没什么质变，顶多见到的边角毛糙少了不容易出戏，最近还花了2K+把高中时就在惦记的手台买了回来。感觉再配个数位板打osu就人生圆满了w 2024-12-11 15:24:17 继续折腾服务器。还是想绑域名，就找了个主页项目用于备案。本来是拉到服务器上想试试远程开发，结果pnpm dev一跑直接给我负载和内存干炸了，重启好几次+杀进程才好。看来买的这廉价服务器不太行，还是本地跑好直接部署输出文件好了。顺便把没用的服务，mysql和mongodb这些都卸了，反正我现在又不用。 还是clone到本地跑，看文档有github集成又去跑github action的ci。不想明文存密钥又研究了一下github的环境变量。然后跑一遍ci成功了，但提示有个组件即将弃用，又更新了一下。总之就是折腾。总算把ci搞好了，以后有机会看能不能整一下cd，现在还是只能手动上传。 对了，还试着给已经部署的服务绑了下域名，ip+端口敲起来太麻烦了，让gpt写了下nginx的反代也不知道对不对，等备好案试试。 为了https连接先把证书搞下来。用的是Let’s Encrypt，参考教程为使用 Let’s Encrypt 免费申请泛域名 SSL 证书，并实现自动续期。 2024-12-12 2024-12-12 16:47:34 这个服务器怎么这么容易炸啊，随便跑点啥就炸了必须重启。我都不确定是我的问题还是服务器的问题，又或者是受到攻击了？这么个小服务器有什么好攻击的。 2024-12-13 2024-12-13 08:44:54 服务器实在用不了了，重装下系统试试。顺便把宝塔换掉，这玩意可以说是恶名鼎鼎了。就是暂时每一个好的替代品。1Panel软广有点多不是很信任。 2024-12-13 11:18:42 1Panel真香，应用市场比宝塔全多了，很多东西都可以一键配置。而且也没有宝塔那么吃相难看哪哪都要花钱。果然有选择还是开源的好。 2024-12-13 15:43:09 将微博客改成极简朋友圈项目，部署到服务器上了。 碎碎念功成身退。撒花🎉 ","link":"https://jinvic.github.io/post/micro-blog-2024-12/"},{"title":"华为云服务器配置","content":"华为云服务器配置 华为云服务器配置 MFA配置 安全组配置 重置密码 ssh登录&amp;免密 宝塔面板登录 防火墙开放端口 其他配置 mysql RustDesk Redis localtunnel gotify 最近把几个月前买的华为云服务器翻出来了，然后总是搞着搞着就把环境搞得一团糟干脆重装，反正就几分钟的事。顺便写个教程以后自己想再重装回来翻下。 MFA配置 如果你用过github，相信对2FA一定不陌生，而MFA和2FA差不多。简单来说，就是一个定时刷新的验证码。我们在进行一些敏感操作，如重设密码等需要频繁验证，这时MFA就会比收短信验证码或者邮箱验证码这类更方便些，当然MFA不是必须的，使用传统验证方式也行。 在安全设置-敏感操作中绑定MFA。管理MFA可以使用华为云的官方app。我个人是Google爱好者，使用的是google authenticator，同时管理github在内多项MFA和2FA。 安全组配置 安全组配置简单来说就是允许哪些ip访问以及开放哪些端口。这个其实刚开始不用管，用默认安全组就行。之后如果添加了某些服务再加上就行。例如你在服务器上装了个，mysql就要开放3306。细节可以参考官方文档。 要检查某个端口是否开放可以使用netstat -an | grep 80命令。 重置密码 如果你不记得你的密码，可以在【实例概览-服务器操作-更多】中重置密码，只不过会有一个验证，这时之前设的MFA就排上用场了。如果没设MFA可以用手机或邮箱验证码。 ssh登录&amp;免密 使用ssh [用户名]@[服务器公网地址]命令就可以远程登录服务器了。默认用户名是root，如果忘了密码可以重置密码。 如果觉得每次输密码太麻烦，可以配置免密登录。在本地计算机（不是服务器）上启动终端（window用cmd或powershell），cd ~来到用户目录下，一般为C:\\User\\用户名，cd .ssh进入.ssh文件夹，使用ssh-keygen -t rsa生成密钥，中途要求保存地址和密码不输直接回车也行。 查看可以发现多出了id_rsa和id_rsa_pub两个文件，分别是私钥和公钥。 此时可以使用ssh-copy-id命令再次登录服务器将会将生成的公钥复制到服务器，但会覆盖源文件。也可以记事本打开公钥文件将内容手动粘贴到/root/.ssh/authorized_keys文件中。如果不会linux的文件操作，可以使用华为云网页自带的远程登录，自带一个文件树，双击打开后粘贴就行。 或者也可以使用echo命令写入，即echo &quot;你的公钥内容&quot; &gt;&gt; ~/.ssh/authorized_keys。 如上配置完成后再使用ssh命令登录就不需要输入密码了。 宝塔面板登录 我买的Flexus L实例默认镜像是Ubuntu 22.04+宝塔面板。当然宝塔不是必要的，完全可以ssh登陆后自己敲命令装软件，不过为了方便还是先用着宝塔，以后可能会换别的管理软件。 宝塔面板的默认账密在credentials/password.txt中，可以使用cat命令查看。 登录后会要你装些软件，选默认配置就行。之后要装什么也可以在软件商店装。 防火墙开放端口 我在使用宝塔面板中安装了mysql，并在ssh登录的终端中成功登录。但是尝试使用公网ip外部登录时失败。这是因为除了安全组配置，还需要在服务器上开放防火墙对应端口。对于Ubuntu系统可以使用ufw命令管理防火墙。如下是一些常用命令。 sudo ufw enable/disable 启用/禁用ufw sudo ufw allow 80/tcp 开放特定端口，如果省略协议类型则同时允许tcp和udp sudo ufw status 查看防火墙开放的端口 加个numbered可以看序号 sudo ufw delete [rule number] 删除某条规则 sudo ufw reload 重启防火墙 如果开放端口还是无法连接，可能是mysql本身设置的问题，可以参考这里，修改访问权限。不建议直接更改root，可以新建一个用户再赋权。 其他配置 mysql 除了开放对应端口还需修改user表的host。 使用mysql -u root -p登录。 use mysql;选择mysql数据库。 select host,user from user查看user表的host。一般这里root的host是localhost，也就是不允许从外部登录。这里个人不建议直接修改root。可以新建一个用户再赋权。 CREATE USER 'newuser'@'%' IDENTIFIED BY 'mypassword';新建用户。 GRANT ALL PRIVILEGES ON *.* TO 'newuser'@'%';赋予新用户所有权限。 FLUSH PRIVILEGES;刷新权限。 完成如上操作后，就可以使用新用户远程登录mysql数据库了。 RustDesk RustDesk在宝塔的应用商店里有。先装Docker和Docker Compose，之后就可以一键安装RustDesk了。 安装RustDesk后要开放对应端口，21115:21119/tcp和21116/udp。防火墙和安全组都要配置。 服务安装后在docker-容器-hbbs-日志查看api key，ID服务器地址填自己服务器的公网地址就行。 Redis 开放端口老生常谈了，略。 在redis的配置文件中也有一行bind 127.0.0.1，限定只能本地登录。可以注释掉这行或者换成自己的ip。 因为redis默认是不设账号密码的，所以一定要设置一下密码。在配置文件/redis/redis.conf中添加一行requirepass mypassword。如果还想设置用户名，可以使用requireuser username。 如果使用的是宝塔面板，也可以直接在设置中修改。 localtunnel localtunnel可以很方便地将本地服务暴露到公网。默认会使用localtunnel官方服务器，为了隐私和效率选择自建服务器。 拉取项目：服务端的gitbub地址，使用git clone https://github.com/localtunnel/server.git命令拉取时报错如下： error: RPC failed; curl 16 Error in the HTTP2 framing layer fatal: expected flush after ref listing 在stackoverflow上看到解决方法，使用git config --global http.version HTTP/1.1强制git使用HTTP 1.1，之后可以使用git config --global http.version HTTP/2改回来。 刚打算试试，发现又好了。看来是github日常抽风，有空配下代理。 安装并启动项目：拉取后的文件夹名为server，我为了方面管理改成了localtunnel-server。cd到这个目录下，使用npm install安装依赖，然后使用node -r esm bin/server --port 1234启动项目。端口可以自定义。 使用nohup可以在后台不挂起运行程序，退出终端不影响。 gotify gotify是一个简单易部署的消息服务。 服务端：使用docker部署gotify很方便。只需要一行命令就能完成。不过我们为了可用性还是使用docker-compose。首先新建一个文件夹作为项目位置，然后新建文件docker-compose.yml： services: gotify: image: gotify/server container_name: &quot;gotify&quot; restart: always ports: - 28818:80 #可以自定义要映射的端口 environment: - GOTIFY_DEFAULTUSER_NAME=admin #默认账号 - GOTIFY_DEFAULTUSER_PASS=admin #默认密码，记得修改一下 volumes: - &quot;./gotify_data:/app/data&quot; 然后sudo docker-compose up -d就行。记得开放设置的端口和安全组，之后就可以登录&lt;ip&gt;:&lt;port&gt;查看消息了。 客户端：因为我的需求是转发验证码短信，使用的客户端为SmsForwarder-短信转发器。 在导航栏的apps标签中新建应用获取token，然后拼接服务器地址：http://&lt;ip&gt;:&lt;port&gt;/message?token=&lt;apptoken&gt;填入WebServer，测试成功。 ","link":"https://jinvic.github.io/post/huaweicloud-server-config/"},{"title":"Kratos 快速入门实践","content":"Kratos 快速入门实践 Kratos 快速入门实践 前言 项目结构 api层 ent层 data层 biz层 service层 依赖注入 总结 前言 kratos官方文档的快速入门主打一个跑起来就算成功，基本没什么内容。本文将基于官方文档快速入门，结合自己的实践，详细说明如何在kratos框架中开发一个新功能。 项目结构 如下是 Kratos 的一个典型的 Go 项目布局，也差不多是我们使用kratos new .创建新项目时的默认布局： application |____api | |____helloworld | | |____v1 | | |____errors |____cmd | |____helloworld |____configs |____internal | |____conf | |____data | |____biz | |____service | |____server |____test |____pkg |____go.mod |____go.sum |____LICENSE |____README.md 简单来说，要开发一个新功能就是api-&gt;[service-biz-data]&lt;-ent的流程。其中api层定义外部接口，service层负责与外部接口对接，biz层负责业务逻辑，data层与底层数据操作对接，ent层实现数据库定义与操作。 api层 首先在api/helloworld/v1中定义protobuf文件，并使用 kratos proto client .\\api\\helloworld\\v1\\test.proto 生成go代码。 // api/helloworld/v1/test.proto syntax = &quot;proto3&quot;; package api.helloworld.v1; import &quot;google/api/annotations.proto&quot;; option go_package = &quot;helloworld/api/helloworld/v1;v1&quot;; // The test service definition. service Test { rpc GetTest(GetTestRequest) returns (GetTestReply) { option (google.api.http) = { get: &quot;/test/{id}&quot; }; }; } message GetTestRequest { string id = 1; } message GetTestReply { string field1 = 1; string field2 = 2; } 然后可以通过kratos proto server .\\api\\helloworld\\v1\\test.proto -t internal/service在internal\\service下生成对应的service文件，这里实现了pb.TestServer接口。 // internal/service/test.go package service import ( &quot;context&quot; pb &quot;helloworld/api/helloworld/v1&quot; ) type TestService struct { pb.UnimplementedTestServer } func NewTestService() *TestService { return &amp;TestService{} } func (s *TestService) GetTest(ctx context.Context, req *pb.GetTestRequest) (*pb.GetTestReply, error) { return &amp;pb.GetTestReply{}, nil } 对外的部分就完成了，这是从外部接口到内部逻辑的步骤。 接下来，我们从最底层的数据库开始，由内向外实现到service层。 ent层 首先是ent框架的schema定义，在internal/data/ent/schema下定义ent的schema文件。 关于ent的语法，在此不再赘述。 // internal/data/ent/schema/test.go package schema import ( &quot;entgo.io/ent&quot; &quot;entgo.io/ent/dialect&quot; &quot;entgo.io/ent/schema/field&quot; ) // Test holds the schema definition for the Test entity. type Test struct { ent.Schema } // Fields of the Test. func (Test) Fields() []ent.Field { return []ent.Field{ field.Int32(&quot;id&quot;).SchemaType(map[string]string{ dialect.MySQL: &quot;int(10)UNSIGNED&quot;, // Override MySQL. }).NonNegative().Unique(), field.String(&quot;field1&quot;).SchemaType(map[string]string{ dialect.MySQL: &quot;varchar(50)&quot;, // Override MySQL. }), field.String(&quot;field2&quot;).SchemaType(map[string]string{ dialect.MySQL: &quot;varchar(50)&quot;, // Override MySQL. }), } } // Edges of the Test. func (Test) Edges() []ent.Edge { return nil } 在完成schema定义后，就可以使用ent工具生成用户操作数据库的相关代码。 ent generate ./internal/data/ent/schema 在internal/data/data.go中实现客户端并装载到Data结构体中,这样就把数据库操作和内部逻辑连接了起来。 // internal/data/data.go package data import ( ... _ &quot;github.com/go-sql-driver/mysql&quot; // mysql driver ) // Data . type Data struct { // TODO wrapped database client db *ent.Client } // NewData . func NewData(c *conf.Data, logger log.Logger) (*Data, func(), error) { cleanup := func() { log.NewHelper(logger).Info(&quot;closing the data resources&quot;) } return &amp;Data{ db: NewEntClient(c, logger), }, cleanup, nil } // NewEntClient . func NewEntClient(c *conf.Data, logger log.Logger) *ent.Client { client, err := ent.Open(c.Database.Driver, c.Database.Source) if err != nil { log.NewHelper(logger).Fatal(err) } return client } 别忘了在configs/config.yaml中修改数据库配置。 data: database: driver: mysql source: root:123456@tcp(127.0.0.1:3306)/test?parseTime=True&amp;loc=Local 完成api层和ent层后，程序内外的连接就完成了，接下来就是实现程序内部的逻辑。 data层 在internal/data/test.go中实现数据库操作，这里让testRepo实现GetTest方法，即实现biz.TestRepo接口。 // internal/data/test.go package data type testRepo struct { data *Data log *log.Helper } func (r *testRepo) GetTest(ctx context.Context, id int32) (*biz.Test, error) { test, err := r.data.db.Test.Query().Where(test.IDEQ(id)).Only(ctx) if err != nil { return nil, err } return &amp;biz.Test{ Id: test.ID, Field1: test.Field1, Field2: test.Field2, }, nil } biz层 在internal/biz/test.go中实现业务逻辑，这里因为逻辑很简单，直接调用data层方法就行。 // internal/biz/test.go package biz type Test struct { Id int32 Field1 string Field2 string } type TestRepo interface { GetTest(context.Context, int32) (*Test, error) } type TestUsecase struct { repo TestRepo log *log.Helper } // // GetTest search and return the Test. func (uc *TestUsecase) GetTest(ctx context.Context, id int32) (*Test, error) { return uc.repo.GetTest(ctx, id) } service层 最后，将TestUsecase装载到internal/service/test.go中，这样service层就完成了。 // internal/service/test.go package service type TestService struct { pb.UnimplementedTestServer uc *biz.TestUsecase } func (s *TestService) GetTest(ctx context.Context, req *pb.GetTestRequest) (*pb.GetTestReply, error) { id, err := strconv.Atoi(req.Id) if err != nil { return nil, err } test, err := s.uc.GetTest(ctx, int32(id)) if err != nil { return nil, err } return &amp;pb.GetTestReply{ Field1: test.Field1, Field2: test.Field2, }, nil } 依赖注入 最后，我们实现每一层的构造函数，并使用wire进行依赖注入。 // internal/servece/test.go package service func NewTestService( uc *biz.TestUsecase, ) *TestService { return &amp;TestService{ uc: uc, } } // internal/servece/service.go package service import &quot;github.com/google/wire&quot; // ProviderSet is service providers. var ProviderSet = wire.NewSet(NewGreeterService, NewTestService) // internal/biz/test.go package biz // NewTestUsecase new a Test usecase. func NewTestUsecase(repo TestRepo, logger log.Logger) *TestUsecase { return &amp;TestUsecase{repo: repo, log: log.NewHelper(logger)} } // internal/biz/biz.go package biz import &quot;github.com/google/wire&quot; // ProviderSet is biz providers. var ProviderSet = wire.NewSet(NewGreeterUsecase, NewTestUsecase) // internal/data/test.go package data // NewTestRepo . func NewTestRepo(data *Data, logger log.Logger) biz.TestRepo { return &amp;testRepo{ data: data, log: log.NewHelper(logger), } } // internal/data/data.go package data import ( ... &quot;github.com/google/wire&quot; ) // ProviderSet is data providers. var ProviderSet = wire.NewSet(NewData, NewGreeterRepo, NewTestRepo) // internal/server/http.go package server // NewHTTPServer new an HTTP server. func NewHTTPServer(c *conf.Server, greeter *service.GreeterService, test *service.TestService, logger log.Logger) *http.Server { var opts = []http.ServerOption{ http.Middleware( recovery.Recovery(), ), } if c.Http.Network != &quot;&quot; { opts = append(opts, http.Network(c.Http.Network)) } if c.Http.Addr != &quot;&quot; { opts = append(opts, http.Address(c.Http.Addr)) } if c.Http.Timeout != nil { opts = append(opts, http.Timeout(c.Http.Timeout.AsDuration())) } srv := http.NewServer(opts...) v1.RegisterGreeterHTTPServer(srv, greeter) v1.RegisterTestHTTPServer(srv, test) return srv } // internal/server/grpc.go package server // NewGRPCServer new a gRPC server. func NewGRPCServer(c *conf.Server, greeter *service.GreeterService, test *service.TestService, logger log.Logger) *grpc.Server { var opts = []grpc.ServerOption{ grpc.Middleware( recovery.Recovery(), ), } if c.Grpc.Network != &quot;&quot; { opts = append(opts, grpc.Network(c.Grpc.Network)) } if c.Grpc.Addr != &quot;&quot; { opts = append(opts, grpc.Address(c.Grpc.Addr)) } if c.Grpc.Timeout != nil { opts = append(opts, grpc.Timeout(c.Grpc.Timeout.AsDuration())) } srv := grpc.NewServer(opts...) v1.RegisterGreeterServer(srv, greeter) v1.RegisterTestServer(srv, test) return srv } 使用go generate ./...命令更新依赖注入代码后就可以启动服务了。 总结 通过以上步骤，我们完成了从proto文件到最终可运行的服务的整个过程，包括proto文件生成、ent层、data层、biz层、service层以及依赖注入。至于其他内容如cmd和internal/conf文件夹下的内容，在创建项目时已经生成好了不需要过多改动在此便不再赘述，有需要可以自行修改。 ","link":"https://jinvic.github.io/post/kratos-quick-start-practice/"},{"title":"ent笔记","content":"ent笔记 ent笔记 概述 快速入门 安装ent 初始化ent目录 创建实体 添加字段 添加边（Relation） 添加逆边（BackRef） 生成代码 连接数据库 创建&amp;迁移数据库模式 其他工具 SQL转entgo entimport protoc-gen-ent 概述 ent 是一个 Go 的实体框架 (ORM)。 ent 可以使用 Go 代码轻松地定义任何数据模型或图结构；schema配置由 entc (ent codegen) 验证，这种配置生成了一个地道的静态类型的 API ，使开发人员能够富有生产性和幸福感。 它支持 MySQL, MariaDB, PostgreSQL, SQLite 和 Gremlin图数据库。 简单来说，ent是Facebook团队开源的一个Go语言ORM框架，类似于Java的Hibernate，Python的SQLAlchemy，Go的GORM等。相比于gorm，ent的特点是专注于使用dsl写schema，关联和约束都写在 Go 代码，而不是结构标签，并用cli工具自动生成和验证代码，以及同样支持从schema构造迁移数据库结构，用户只需要管理好schema就行。缺点是学习成本和上手难度较高，需要理解学习它的schema概念和dls语法，以及面对复杂需求框架生成的代码可能不够灵活有时需要自定义方法。 ent官方文档里的中文和没有差不多。这里贴一个民间翻译的中文文档。 241107: 才注意到ent主页挂着支持以色列的横幅，在开源项目中宣扬政治主张实在有点恶心了。 241114: 中文支持很差，甚至文档进度都不同步，建议看英文文档。为了封装硬生生搞了个语法子集出来，很多功能都无法实现。文档既少又烂，查资料全靠issue。两个字：快跑 快速入门 ent使用需要go环境，可以安装go后设置go项目: go mod &lt;projectname&gt; 安装ent go get entgo.io/ent/cmd/ent 使用ent -h查看是否安装成功。如果提示找不到可以使用如下命令代替ent命令： go run entgo.io/ent/cmd/ent 或者使用go install添加到%GOPATH/bin目录： go install entgo.io/ent/cmd/ent 初始化ent目录 ent new 目录如下： . └── ent ├── generate.go └── schema 创建实体 ent new &lt;entityname&gt; 可以使用如上命令同时创建多个实体。它们将被创建在schema目录下。假设我们创建了一个User实体（首字母必须大写）ent new User： . └── ent ├── generate.go └── schema └── user.go 代码如下： package schema import &quot;entgo.io/ent&quot; // User holds the schema definition for the User entity. type User struct { ent.Schema } // Fields of the User. func (User) Fields() []ent.Field { return nil } // Edges of the User. func (User) Edges() []ent.Edge { return nil } 其中Fields和Edges方法分别定义了实体的字段和关联关系。 添加字段 直接修改各实体Fields方法的返回值即可。例如，我们给User实体添加age和name字段： // Fields of the User. func (User) Fields() []ent.Field { return []ent.Field{ field.Int(&quot;age&quot;). Positive(), field.String(&quot;name&quot;). Default(&quot;unknown&quot;), } } 关于字段，详情见Fields。 添加边（Relation） 直接修改各实体Edges方法的返回值即可。例如，我们给User实体添加一个一对多关系到Car： // Edges of the User. func (User) Edges() []ent.Edge { return []ent.Edge{ edge.To(&quot;cars&quot;, Car.Type), } } 这时如果我们查看数据库模式，会发现Car实体对应的cars表多了一列user_cars，作为外键约束指向User实体的id。 添加逆边（BackRef） // Edges of the Car. func (Car) Edges() []ent.Edge { return []ent.Edge{ // 创建一个名为 &quot;owner&quot; 的 `User` 反向边 // 并关联到 &quot;cars&quot; 边 (在 用户 结构中) // 并显式的使用 `Ref` 方法。 edge.From(&quot;owner&quot;, User.Type). Ref(&quot;cars&quot;). // 设置边为唯一确保每辆车都只有一个拥有者 Unique(), } } 如上代码创建了cars边的逆边owner。这时如果我们查看数据库模式，会发现并没有新增约束，因为这只是对原边的反向引用。 我们可以通过Unique方法来设置边的唯一性，从而设置一对一，一对多或多对多关系。 如果是多对多关系将建立一个新的映射表来反映关联关系。 关于边，详见Edges。 生成代码 ent generate ./ent/schema 或者： go generate ./ent 生成代码后目录如下： . └── ent ├── client.go ├── ent.go ├── enttest │ └── enttest.go ├── generate.go ├── hook │ └── hook.go ├── migrate │ ├── migrate.go │ └── schema.go ├── mutation.go ├── predicate │ └── predicate.go ├── runtime │ └── runtime.go ├── runtime.go ├── schema │ └── user.go ├── tx.go ├── user # user │ ├── user.go │ └── where.go ├── user.go # user ├── user_create.go # user ├── user_delete.go # user ├── user_query.go # user └── user_update.go # user 其中，user文件夹及user开头的文件属于User实体，其他的文件则是通用的。 在编写好schema和生成代码后，就可以使用ent的client进行数据库操作了。 连接数据库 ent支持多种数据库，包括MySQL、PostgreSQL、SQLite等。可以使用ent.Open()建立一个数据库链接并返回客户端： // func ent.Open(driverName string, dataSourceName string, options ...ent.Option) (*ent.Client, error) client, err := ent.Open(&quot;mysql&quot;, &quot;username:password@tcp(127.0.0.1:3306)/entdemo&quot;) defer client.Close() 创建&amp;迁移数据库模式 可以使用ent.Client.Schema.Create()方法创建数据库模式： // func (s *Schema) Create(ctx context.Context, opts ...schema.MigrateOption) error err := client.Schema.Create(context.Background()) 其他工具 SQL转entgo SQL转entgo 这个在线工具可以将sql直接转换成entgo的schema。 entimport blog github 这个工具可以将数据库中现有的表结构转换成entgo的schema。 protoc-gen-ent blog github 这个工具可以将protobuf文件转换成entgo的schema。 ","link":"https://jinvic.github.io/post/ent-notes/"},{"title":"ProtoBuf笔记","content":"ProtoBuf笔记 官方文档 尽量少抄文档吧。。。感觉抄文档的笔记没有一点意义，真要查些什么都直接查文档了。 概述 什么是ProtoBuf？ 定义：Protocol Buffers 是一种与语言无关、与平台无关的可扩展机制，用于序列化结构化数据。 看起来有点懵，举个例子。我们随便定义一个结构体，在不同语言中定义方法是不同的： struct Person { char name[50]; int age; }; struct Person { std::string name; int age; }; class Person: def __init__(self, name, age): self.name = name self.age = age type Person struct { Name string Age int } 而protobuf提供了一种通用的定义方式，它可以通过工具转换成任意一种语言。 message Person { string name = 1; int32 age = 2; } protobuf有什么用？ protobuf本质上是一种序列化技术。什么是序列化？这里不扯定义，简单粗暴地说，就是把数据转换成另一种更方便更通用的形式，方便进行存储和传输。你在程序里有个结构体，你可以把它当参数在这个程序里面传来传去。但如果你要把它存到磁盘，可能就得存一个txt或json，这个过程你就可以理解为序列化。你用另一个程序把这个txt或json读到程序里的结构体，然后就可以自由操作这个结构体了，这个过程就可以理解为反序列化。上面讲的是存储，而传输也是一样的道理。json就是序列化技术之一，而protobuf也是类似的。而相比json的轻量级标记，protobuf则有着更接近编程语言的语法和工具链支持。 protobuf常用于跨语言，跨项目的通信协议和数据存储，如RPC等。具体什么是RPC这里不予赘述。 protobuf-go开发 protobuf生成go代码时，需要使用 go_package 选项指定生成代码的包的导入路径。包名为最后一个路径组件。如下，包名为tutorialpb。 option go_package = &quot;github.com/protocolbuffers/protobuf/examples/go/tutorialpb&quot;; 使用protobuf生成go代码，需要额外安装插件protoc-gen-go，如果是gRPC开发还需安装protoc-gen-go-grpc： go install google.golang.org/protobuf/cmd/protoc-gen-go@latest go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest 编译器插件 protoc-gen-go 将安装在 $GOBIN 中，默认为 $GOPATH/bin。 需要将其添加到$PATH 中，以便协议编译器 protoc 能够找到它。 Linux添加PATH： export PATH=&quot;$PATH:$(go env GOPATH)/bin&quot; 编译命令中使用--go_out和--go-grpc_out指定输出目录。 protoc --go_out=proto --go-grpc_out=proto .\\proto\\test.proto ","link":"https://jinvic.github.io/post/protobuf-notes/"},{"title":"碎碎念 2024-11","content":"碎碎念 碎碎念 2024-11-01 2024-11-01 11:04:19 2024-11-02 2024-11-02 13:44:45 2024-11-02 15:32:23 2024-11-04 2024-11-04 8:23:38 2024-11-05 2024-11-05 11:50:27 2024-11-07 2024-11-07 16:13:49 2024-11-12 2024-11-12 08:13:14 2024-11-12 08:31:06 2024-11-13 2024-11-13 10:24:45 2024-11-14 2024-11-14 15:50:55 2024-11-18 2024-11-18 17:00:31 2024-11-18 19:31:05 2024-11-19 2024-11-19 01:34:59 2024-11-19 10:04:42 2024-11-20 2024-11-20 11:55:54 2024-11-20 17:23:06 2024-11-26 2024-11-26 10:31:03 2024-11-27 2024-11-27 11:07:31 2024-11-27 19:51:04 2024-11-28 2024-11-28 15:47:17 2024-11-28 17:39:06 2024-11-01 2024-11-01 11:04:19 把gredia的源文件路径迁移到百度网盘的同步空间了。本来是想着直接同步文件夹，发现不行，百度网盘只能同步它指定的文件夹，得自己移进去才行。wps倒是能实现同步不同地方的文件夹，但不是很信任wps的存储服务。在百度网盘里设置选择性同步也能勉强满足我的需求。 2024-11-02 2024-11-02 13:44:45 我的一天： 学protobuf -&gt;看官方文档 -&gt;文档看累了 -&gt;gpt总结一下 -&gt;让gpt出点题来做 -&gt;做完了编译 -&gt;手敲敲命令好麻烦，写个脚本 -&gt;看makefile -&gt;顺便看看cmake -&gt;没啥用，还是看makefile -&gt;mingw32-make好难敲，开linux吧 -&gt;wsl怎么没装make -&gt;homebrew是什么，装一下 -&gt;下载好慢，弄下代理 -&gt;怎么还要Ruby -&gt;搞个版本控制来玩玩 -&gt;装一下vfox -&gt;Windows也装一下 -&gt;powershell玩坏了 -&gt;删下配置 -&gt;scoope是什么，装一下 -&gt;用scoope装了vfox -&gt;用vfox装了Ruby -&gt;Ruby环境下装了homebrew -&gt;安装成功了怎么还是用不了 -&gt;配下path -&gt;欸我要干啥来着？ -&gt;哦跑makefile -&gt;用homebrew装了make -&gt;用homebrew装了protobuf 2024-11-02 15:32:23 🎉 恭喜！ 🎉 Jinvic学会了新技能：Protobuf！ 技能描述： 名称： Protobuf 类型： 数据序列化 威力： 80 命中率： 100% 效果： 使用高效、跨平台的数据格式，将复杂数据结构序列化为二进制文件或网络传输。提升数据交换的速度和效率，减少带宽消耗。 技能特点： 跨平台兼容： 无论是在服务器、客户端还是移动设备上，都能无缝使用。 高性能： 序列化和反序列化的速度比JSON快数倍。 强类型： 定义明确的数据结构，确保数据的一致性和可靠性。 易用性： 提供多种语言的支持，包括Go、Java、Python等，让你在不同项目中轻松应用。 使用场景： 微服务通信： 在微服务架构中，作为API接口的数据传输格式。 缓存存储： 将数据序列化后存储在缓存中，提高读取速度。 配置文件： 将复杂的配置信息序列化为文件，方便管理和读取。 恭喜你掌握了这项强大的技能，你的开发之旅将更加顺畅！ 尝试让gpt用这种语气说话，还挺有意思w 2024-11-04 2024-11-04 8:23:38 每次想着记点笔记，最后都变成了抄文档，毕竟文档已经很完善了，自己也写不出更好的。而文档不完善的？学都学不明白就更难写出什么东西了。还是肚子里没货，不能融会贯通举一反三。感觉除了流水账式的日志，做笔记状态最好的一次就是《Go程序设计语言》的阅读笔记，每每看到什么点都会想到这个在C++是怎样的在Python是怎样的，然后记一些比较和感悟。这才是正常的状态嘛。 2024-11-05 2024-11-05 11:50:27 今天读到一篇文章我为什么放弃Go语言？。看标题以为是讨论Go语言的缺点，结果内容却是非常细致地总结了盘点了Go 的常见错误帮助避坑。虽然有点标题党但怎么莫名有种刀子嘴豆腐心的傲娇感www 2024-11-07 2024-11-07 16:13:49 🎉 恭喜！ 🎉 Jinvic学会了新技能：Ent！ 技能描述： 名称： Ent 类型： ORM 威力： 90 命中率： 100% 效果： 使用Ent，你可以轻松地在Go应用程序中操作数据库。Ent提供了一种声明式的模式定义方式，让你能够以类型安全的方式处理数据模型，同时保持代码的简洁和高效。 技能特点： 声明式模式定义： 通过简单的Go代码定义数据模型，无需编写复杂的SQL语句。 类型安全： 生成的代码是类型安全的，编译时即可发现错误，减少运行时的意外。 灵活扩展： 支持自定义钩子和中间件，让你可以根据需求扩展功能。 社区支持： 活跃的社区和丰富的文档，帮助你快速解决问题。 使用场景： Web开发： 在Go的Web应用中，使用Ent管理用户、订单等数据模型。 微服务： 在微服务架构中，使用Ent处理数据持久化和查询。 API后端： 为RESTful API或GraphQL API提供强大的数据支持。 恭喜你掌握了这项强大的技能，你的开发之旅将更加高效和愉快！ 脑子都木了，好累💀 2024-11-12 2024-11-12 08:13:14 🎉 恭喜！ 🎉 Jinvic学会了新技能：Kratos！ 技能描述： 名称： Kratos 类型： 微服务框架 威力： 100 命中率： 100% 效果： 使用Kratos，你可以快速构建高性能、高可用的微服务应用。Kratos提供了丰富的功能和工具，帮助你简化开发流程，提升开发效率，同时保证系统的稳定性和可扩展性。 技能特点： 模块化设计： Kratos采用模块化设计，你可以根据需要选择和组合不同的模块，灵活构建应用。 强大的中间件支持： 提供丰富的中间件，如认证、限流、日志等，帮助你快速实现常见功能。 完善的配置管理： 支持多种配置管理方式，如文件、环境变量、配置中心等，方便管理和维护。 强大的错误处理机制： 提供统一的错误处理机制，帮助你更好地管理和记录错误。 丰富的文档和社区支持： 活跃的社区和详细的文档，帮助你快速上手和解决问题。 使用场景： 微服务架构： 快速构建和部署微服务应用，实现业务的高效解耦和独立部署。 API后端： 为前端应用提供高性能、稳定的API后端服务。 企业级应用： 构建企业级应用，满足高并发、高可用的需求。 实时数据处理： 处理实时数据流，如实时监控、在线聊天等。 恭喜你掌握了这项强大的技能，你的开发之旅将更加高效和顺畅！ 2024-11-12 08:31:06 昨晚加班两小时，啥也没干就写了篇博客，算是对这段时间所学的一个总结吧。其实看懂了很简单的东西，或许就是因为太简单了所以文档根本没写清楚，费了我好大劲才搞明白，属实怨念满满。以前看各家教程总会把一些简单的基础的东西反复讲，觉得没啥必要这不是人人都会吗？落到自己头上才明白还是讲一下好。就算是应该人人都会的东西，从不会到会也是有个过程的。不会的用户看到你这里有门槛就去别家学了，学完就顺势用别家的不一定会回来用你家的，这不是主动把人往外赶嘛，总不能说暂时水平不够的就不配用你家产品了吧。 2024-11-13 2024-11-13 10:24:45 看着同事代码里简单粗暴的循环嵌套好难受。 acm之魂蠢蠢欲动，好想给它降一下时间复杂度😖 还是算了，多一事不如少一事，能跑就行。 2024-11-14 2024-11-14 15:50:55 ent这框架语法写太死了，很多功能都无法实现。设计一套新的边系统来管理表之间关联关系，用来从无到有生成表很方便，但要匹配现有表简直就是折磨，只能在它既定的规矩里勉力腾挪。换别的框架一个join就能解决的事，在它这搞了两三天没解决，你说你惦记你那傻逼主键id干嘛。最后还是笨办法查表然后写个双指针匹配凑合用。就算你要搞强封装，开个rawsql接口也不过分吧，只有一套子集真是被气死了。 2024-11-18 2024-11-18 17:00:31 想试试能不能在命令行全局设定just变量默认值，切目录就不用写一串很长的选项了。翻半天issue好像不行。之后试了试watchexec，监视文件变化自动运行just命令。给每个命令都配了个watchexec，又觉得一个个启动太麻烦开个多线程。Start-ThreadJob这个cmdlet函数windows预装的powershell没有又装了个powershell7。因为不想跑个ps1文件开始研究怎么连接命令。管道连接符 | 和bash的 &amp;&amp; 都不行，然后才发现是分号 ; 。跑起来因为在线程里看不到输出又研究怎么输出到当前终端，没成功还是算了就这样。东搞西搞一个下午过去了，得到寥寥几行命令。 # [watchexec requeired] watch-api: watchexec -w api/meeting/{{ target }}/v1 -e proto just api # [watchexec requeired] watch-ent: watchexec -w .\\app\\meeting\\{{ target }}\\internal\\data\\ent\\schema -e go just ent # [watchexec requeired] watch-config: watchexec -w .\\app\\meeting\\{{ target }}\\internal\\conf -e proto just config # [watchexec requeired] watch-generate: watchexec -w app\\meeting\\admin\\internal\\data\\data.go \\ -w app\\meeting\\admin\\internal\\biz\\biz.go \\ -w app\\meeting\\admin\\internal\\service\\service.go \\ -w app\\meeting\\admin\\internal\\server\\http.go \\ just generate # auto-generate codes while files modified [watchexec and powershell7 required] watch-all: $jobs = @( \\ (Start-ThreadJob -ScriptBlock {just watch-api}), \\ (Start-ThreadJob -ScriptBlock {just watch-ent}), \\ (Start-ThreadJob -ScriptBlock {just watch-config}), \\ (Start-ThreadJob -ScriptBlock {just watch-generate}) \\ ); | ForEach-Object { Wait-Job $_ } alias wall := watch-all 2024-11-18 19:31:05 很多一时兴起但没有一口气完成的事，过段时间就成了梗在心头的拖累。想着做完算了却也怎么都提不起劲，放着不管又要时不时想起来刺挠你一下。 2024-11-19 2024-11-19 01:34:59 好久认真没写点东西了，今天半夜不想睡写点。 这段时间陆陆续续换手机换电脑，电子设备这块基本是重开了，勉强留下点数据也不好说全不全。说不定什么时候想找点什么却发现再也找不回来，或者已经有很重要的东西遗失了自己还没发现。即便这样，我还是想试着写点什么，算是在这个世界上留下点自己存在过的痕迹，也算是电子骨灰盒吧（笑）。 我并不信任物理上的存储介质。初高中毕业时的同学录，现在也只是放在老家的床头柜里落灰。曾经我时常拿出来翻看，回忆往昔的青葱岁月。然而这一切都被熊孩子毁了。其中有一张上面用胶带粘了一颗糖，是我曾经有些好感的女孩子给的，尽管记忆中的面容都早已模糊，我还是对其十分珍视。直到熊孩子为了一颗不知道放了几年的糖将其粗暴地扯了下来，只留下一片刺目的疤痕。而我什么都做不了，甚至连愤怒都要被拿来取笑。是啊，一边是被捧上天的小祖宗，而另一边，只是一颗放了不知道几年的糖而已。 虽然被毁坏的只有一张，但那一沓我都不愿意再拿出来翻看了。因为每次想要打开抽屉时，总会想起这件事，想起当时的气愤与无力。我又能做什么呢？恶毒地诅咒对方吃坏肚子，这已经是我能做的全部了，然而就连这点小小的报复最终也没能应验。 2024-11-19 10:04:42 🎉 恭喜！ 🎉 你获得了新道具：Just 和 Watchexec！ 道具描述： 名称： Just 类型： 任务运行器 效果： 使用Just，你可以轻松地管理和运行复杂的任务脚本。Just提供了一个简单而强大的命令行工具，帮助你定义和执行各种开发任务，如编译、测试、部署等。它不仅提高了你的开发效率，还使团队协作更加顺畅。 名称： Watchexec 类型： 文件监听器 效果： 使用Watchexec，你可以自动检测文件的变化并立即执行相应的命令。无论是保存代码文件后的自动编译，还是修改配置文件后的自动重启服务，Watchexec都能帮助你实现无缝的工作流自动化，让你的开发过程更加流畅和高效。 道具特点： Just： 任务管理： 通过简单的 justfile 配置文件，定义和管理各种开发任务。 命令别名： 为常用命令创建别名，简化命令行操作。 环境隔离： 支持环境变量和环境隔离，确保任务在不同环境下的一致性。 团队协作： 与团队成员共享 justfile，确保每个人都使用相同的任务配置。 Watchexec： 文件监听： 实时监听文件变化，自动触发指定的命令。 灵活配置： 支持多种配置选项，如过滤文件类型、排除特定目录等。 多任务支持： 可以同时监听多个文件或目录，并执行不同的命令。 集成友好： 轻松与其他开发工具和工作流集成。 使用场景： 开发工作流： 使用Just和Watchexec，你可以自动化常见的开发任务，如编译、测试、打包和部署。 实时反馈： 在开发过程中，使用Watchexec实现实时编译和测试，提高开发效率。 团队协作： 通过Just共享任务配置，确保团队成员使用一致的开发流程。 持续集成： 在CI/CD管道中使用Just和Watchexec，实现自动化构建和测试。 恭喜你获得了这两项强大的道具，你的开发之旅将更加高效和顺畅！ 2024-11-20 2024-11-20 11:55:54 这段时间每天差不多都只睡了五小时，一整天都昏昏沉沉的，坐在工位上眼皮都睁不开。 也不是全是忙，明明很困躺在床上闭上眼就是睡不着，干脆玩会手机玩累后断片似的睡一觉。 也就趁现在年轻还能再作一下了。 2024-11-20 17:23:06 今天又是啥也没干，坐在工位上忙忙碌碌不知道在忙些什么。 嘛，一周总有这么几天的，要是对此产生什么心理压力的话这鱼我不是白摸了？ 摸都摸了，大不了明天多干点。至于明天到底干不干再说🤗 回寝室打游戏咯😋 2024-11-26 2024-11-26 10:31:03 昨天下午本来打算不加班玩一下的，结果太累了睡到十一点才醒。歇一会洗个澡就又该睡觉了。在床上躺到两点还没睡着很不爽干脆硬是又熬了一个通宵。好久没有这么作了。反正最近工作少上班时间补补觉间歇眯个十几二十分钟也问题不大。就是这种作息不规律还是少整为好，唉。 2024-11-27 2024-11-27 11:07:31 这后端开发也干了两个月了，感觉和当仓管差不多。前端列个单子让后端找货，后端互相交流这个货谁管的存在哪个仓库哪个货架，找出来装车发货... 2024-11-27 19:51:04 又装上了Chocolatey，包管理器真好用。主要是有UnigetUI这个图形化界面，真让我敲命令行我肯定没那耐心，强烈推荐。 2024-11-28 2024-11-28 15:47:17 策划和开发在测试文档里隔空吵架，乐🤣 2024-11-28 17:39:06 rss这玩意用之前觉得没啥，体验后真香。 ","link":"https://jinvic.github.io/post/micro-blog-2024-11/"},{"title":"一点关于AI编程的随笔","content":"刚读了一篇文章（原文链接），说调查了很多开发者，结论是copilot并未提升编码速度balabala。文章写的稀烂数据也是一坨，典型的标题党营销号文章。但正好这个cursor也用了一段时间了有点心得体会，顺手记录一下。 最开始听到ai编程，当然是github的copilot。一方面是因为收费，另一方面就是不想，或者说不敢依赖AI，怕过于依赖ai自己的编程能力得不到提升。这当然没问题，但更深层的原因，其实是恐惧，恐惧AI的生产力，恐惧自己被淘汰。于是干脆当鸵鸟，只要我不去了解问题就不存在。 现在又用上cursor，也只是偶然见到了相关信息，又看着是免费所以干脆试试。用了一段时间，最初的惊喜过去，现在的评价应该算是比较客观的了。在我看来，现在的ai编程，依然是一个生产力工具，还没有到完全取代程序员的地步。你当然可以让它独立完成一个程序，但它很难100%达到你的要求。自然语言的表述力是有限的，即使你描述的再详尽也总会有错漏之处。而一处小小歧义造成的语境污染可能就需要你花费大量的时间和精力去纠正它。而想要去精细化地修改优化，还是需要你本身看得懂代码。如果你的需求只是够用就行，那AI确实能够满足。但商业化，企业化的那种规模庞大，结构严谨，细节丰富的工程项目，全凭AI就力所不逮了。打个比方，AI或许可以独立写个贪吃蛇写个五子棋，但不可能独立写个战神4写个大表哥2。也就是说，完全不懂编程的人，依赖AI所能实现的还是比较有限的。哪些吹嘘ai无所不能的只是营销话术，而程序员集体失业也为时尚早不必过度焦虑。 那程序员怎么用AI呢，其实也没那么高大上，还是像无良甲方那样，让AI不断拿出新的方案直到满意为止。有的人就要说了，不就是当甲方吗，我也会啊，其实还是有区别的。不懂代码提出的需求可能就是“五彩斑斓的黑”，而懂代码的画风可能就是具体到色号了。而且我个人的意见，向AI提需求时一定要尽可能的细化，不要让AI的思考代替你的思考。让AI成为你的笔尺，而不是成为你的脑子。有时一个功能刚写个函数名，他就把后面的内容全部生成好了。这时不要直接用它生成的代码，而是自己一行行写下去，哪怕每一句都有自动生成参与也比直接生成整个函数要好。这个一句句写下去的过程也是你思考和整理的过程，不要为了图方便把它舍弃。而且之后出了问题你也更好定位问题所在，有额外的需求也更容易实现。或许刚开始比较麻烦，但在理清思路后，经过你手一步步形成的代码是比在一坨直接生成的代码上缝缝补补更好维护的，而且写起来爽利的多。还是那句话，使用AI，而不是被AI使用，成为无情的tab工具。 我现在的工作内容是后端开发，写点简单的数据库交互crud。对我来说，AI编程主要是用于处理那些重复死板的工作，那些不用动脑子的工作。比如模型和接口，经常结构大查不差，AI就可以帮我补全一些字段和注释，避免我把一个单词重复敲上许多次。又或者很多功能结构类似的地方，写过一次后AI就能帮你copy过来并自动改改名字改改变量以适配需求。还有就是有些包啊变量啊字段啊方法啊一层层嵌套就会很冗长，常规ide顶多给你补一层还需要前几个字母提示，AI就能一次给你补全了。把这些内容交给AI生成就能节省自己的时间精力，不用处理这些鸡毛蒜皮的小事。至于更大的需求，我对AI的使用就很谨慎了，基本不去要求它独立实现什么功能，就连自动补全多生成几行代码我都要多看两遍检查。还是那句话，是用AI实现你的想法，而不是你用tab去实现AI的想法。要搞清主从关系，这样你才不会被AI训化，能力才能得到提升。 我想起了那个比较经典的话题，就是程序员面试能不能用IDE。嘲讽公司让程序员在白纸上手写代码，或者嘲讽现在的程序员离了ide的自动补全之类就不会写代码。现在的AI编程，确实有点IDE对白纸的降维打击那味了，但对行业的影响也没有传闻那么夸张，至少我现在也只是把AI当一个高级点的自动补全在用。时代在发展，社会在进步，至少在现在，以及未来很长一段时间内，AI都只会是一个提高生产力和工作效率的工具而已。 ","link":"https://jinvic.github.io/post/a-little-essay-on-ai-programming/"},{"title":"碎碎念 2024-10","content":"碎碎念 碎碎念 2024-10-07 2024-10-07 20:06:21 2024-10-07 20:09:39 2024-10-07 20:54:35 2024-10-07 21:01:57 2024-10-08 2024-10-08 11:46:09 2024-10-08 15:34:57 2024-10-08 17:08:15 2024-10-09 2024-10-09 17:40:38 2024-10-09 13:52:13 2024-10-09 14:15:33 2024-10-10 2024-10-10 08:39:48 2024-10-10 16:16:06 2024-10-11 2024-10-11 11:31:50 2024-10-11 11:34:15 2024-10-12 2024-10-12 10:04:49 2024-10-12 15:24:33 2024-10-14 2024-10-14 08:25:09 2024-10-14 19:58:37 2024-10-15 2024-10-15 17:19:01 2024-10-16 2024-10-16 14:44:31 2024-10-17 2024-10-17 16:32:25 2024-10-22 2024-10-22 08:58:37 2024-10-22 19:18:04 2024-10-22 20:49:47 2024-10-25 2024-10-25 21:07:39 2024-10-28 2024-10-28 19:42:59 2024-10-31 2024-10-31 14:57:06 2024-10-07 2024-10-07 20:06:21 微博客什么的，还是挺想搞一个的，写点即兴的想法或吐槽。可惜gredia不支持，就专门开个贴当微博客用吧。 2024-10-07 20:09:39 又来活了，是goframe框架的，比之前那个练手的gin项目大得多也复杂的多，读项目都不知道要都多久才能弄明白，还要学个更难的新框架。大概程序员的日常就是这样吧，一直在学东西看东西，真正敲代码的时间反而没那么多。 这次可没有给我提前学上一个月的余裕了，deadline也没个准信，不知道该从基础开始慢慢学还是先以快速开发为导向突击学比较好。个人还是喜欢慢慢来的，但职场可不是学校，拖进度的话后果会很严重吧...之前几次赶进度的学法，最后任务是完成了，脑子里什么都没留下。说到底还是根本没有时间管理，想一出是一出。 2024-10-07 20:54:35 正在看gf的demo的源码，发现一个奇怪的实现方法。 // internal/service/user.go type IUser interface { ... // 一些方法 } var localUser IUser func User() IUser { // 判空，略 return localUser } func RegisterUser(i IUser) { localUser = i } // internal/logic/user/user.go type ( sUser struct{} ) func init() { service.RegisterUser(New()) } func New() service.IUser { return &amp;sUser{} } 这样绕一圈，就让结构体sUser有了IUser的方法，即实现了该接口，初见真的被绕得晕头转向吧。看了看文档，这种写法叫做 依赖注入（DI） ，我去，控制反转，依赖注入，这不是实习时spring的内容吗？tmd，java还在追我！ 其实只是设计模式罢了，并非java专属。 2024-10-07 21:01:57 被安排工作后，反而精神了起来，待办标签页又开了一堆。前段时间上个项目的工作完成后就懒了下来，一天八小时的班感觉睡两小时摸四小时，真正有效率的只有两小时左右。强打精神开了elasticsearch的坑，亢奋一会又萎了眼睛都睁不开。现在虽然被安排完全没经验的任务，但学新东西还挺有意思的，是未曾接触过的崭新世界口牙。说白了都是三分钟热度罢了，又任务压着还能保持状态，完成了怕是又萎了。就现在，上次开的gorm和goredis还有点坑没填呢，更别说进度堪忧的gin了。 2024-10-08 2024-10-08 11:46:09 看了半天gf文档才发现项目是v1的，文档是v2的，而v1和v2差别很大。得，一天白干。 不过v2文档确实很完善，感觉当博客看都行，学到了很多项目架构方面的内容。 2024-10-08 15:34:57 想复制个本地的小项目跟着做，但gf1.16版本太老连init都跑不了，下不了资源包。这下汗流浃背了😅 2024-10-08 17:08:15 看进度表好像只有半月时间开发，加速加速。 2024-10-09 2024-10-09 17:40:38 整了个cursor试试，AI辅助确实方便。虽然之前也一直在用通义千问，但集合到IDE里光复制代码就很方便，而且模型是编程方面特化，用起来比常规大模型舒服不少。作为vscode分支插件啊快捷键啊也基本无缝迁移。 只是本来以为有免费额度，仔细一看消息过时了，现在只有两周试用。要买吗？每月20刀还是太贵了，支付可能也不是很方便。再说吧。 2024-10-09 13:52:13 每天都在写各种文档笔记备忘录，已经把脑子外挂出去了。 光靠自己什么都记不住，顶多当个索引知道去哪查。 什么赛博朋克。 2024-10-09 14:15:33 总是脑子没想清楚手就先开始动手，干了半天发现白干，纯纯浪费时间。 什么时候能改掉这个坏习惯。还是经验不足。 2024-10-10 2024-10-10 08:39:48 没有数据库和api文档好麻烦，很多东西只能脑测。 我又不好意思问。 2024-10-10 16:16:06 cursor这个代码补全真的好好用啊，全程tabtabtab就写好了。写功能和算法能力暂且不论，就我现在工作内容的crud代码绝对是一些一个准。这下不得不买了。 2024-10-11 2024-10-11 11:31:50 写完了问要不要写api文档才发地址。问我数据库在哪，我回没数据库地址才发我配置文件。是忘了吧！绝对是忘了吧！ 下次记得自己要好了... 2024-10-11 11:34:15 刚报告做完了马上来新活，随着能力提升工作也越来越忙了呢。 下次要不要拖着等问了再说呢🤔感觉会轻松点。当老油条有什么不好。 2024-10-12 2024-10-12 10:04:49 说是大小周，因为调休，这段时间基本都是小周。 今天下午下馆子+打球。明天上午出勤下午打牌，真是充实的假期。 ... 不知道该开心还是该伤心。 好困... 2024-10-12 15:24:33 摸了一整天鱼。主要是看看阮一峰的周刊，找点感兴趣的软件码一下。 感觉自己就像仓鼠一样，见到什么好东西总想着存起来，却基本不会打开第二次。 至少用起来吧。试了试确实有几个也挺好用，小而精的软件，感觉很极客。 上班上成软件测评了（ 2024-10-14 2024-10-14 08:25:09 没有工作好慌。 本来悠闲地学了一个月，被hr问了一次后就突然很想工作，现在工作做完了暂时没有新工作也淡定不下来，回不到以前悠闲学东西的状态。 我是不是被PUA了。 2024-10-14 19:58:37 一点小bug改了一整天。如果是我自己来的话顶多两三个小时就搞定了，但bug不是我发现的，和别人沟通的过程花费了大量时间。多人协作就是这样的，写代码一时爽修bug火葬场。要是写的时候细心点这时就不用这么麻烦了。但中间其实也是有个峰值在的，并不是写的越慢越好。时间长了你反而会厌烦这个项目效率暴跌，尤其是那些看了一次又一次的代码，每次重新梳理结构真的抓狂。 感觉还是要改进协作方法，提升交流能力。现在在的公司已经还不错了，我都不敢想象那些管理混乱的小公司会是什么样。此外就是开发效率的问题，把开发时间控制在效率高的区间内也是们学问，既要保证层层检查减少错漏又要保证别耽搁花费太多时间适得其反。总是还是一句话：菜就多练😒 2024-10-15 2024-10-15 17:19:01 从零写个gin项目练手，久违的充实感。 接触过gf后感觉思维都不一样了。之前对着项目无从下手，现在能看到需求直接上手开拆，分层解耦后一目了然。这就是工程化的思维吗...确实学了gf的目录结构设计后，照猫画虎也能理解这段代码大概属于什么功能应该放在哪块。虽然对小项目来说有点笨重，但随着增量开发不断加代码只会越写越爽。解耦后只需要考虑这一块的内容就行，不像以前不断翻上下文确认自己没搞错，然后想到哪写到哪代码一团糟，造出一个个庞大的单文件鼠标滚轮滚烂。前期不规划好结构后面改都没法改，也许这就是屎山吧。这么想的话我前面练手的几个项目也是屎山，至少我现在看都不想看一眼。 开始对类似的软件体系架构方面感兴趣了。上学时总把这些课当水课非睡即逃，现在倒是想找几本书来看了。果然实践出真知。大学要是多注重实践也不会天天被骂水了，连技校都不如。 2024-10-16 2024-10-16 14:44:31 折腾了一下，给个人博客加上了评论系统，用的Waline。 我这个gredia主题本身支持Valine，了解一下好像有安全风险，就换成valine改的waline，算是升级版。然后修改了一下主题的配置让其也支持waline。其实就是全局搜索把valine全部改成waline就差不多了... 2024-10-17 2024-10-17 16:32:25 好累。 写代码一时爽，改bug火葬场。今天被测试上强度了。其实还是自己先前写的不够好怪不得别人。 才过几天就有点不想看自己写的代码了，感觉有点乱。嗯，一定是解耦做的不够好，还得拆得更细（暴论） 2024-10-22 2024-10-22 08:58:37 每天做不完的琐事，无非修修补补。 再念叨当初写好点已经无济于事干脆不乏牢骚了。当时一是水平不够，二是在别人的项目上改实在畏手畏脚。现在看懂了总算稍微敢大刀阔斧地改改了，越写越怀疑自己当初到底改了啥。 2024-10-22 19:18:04 好忙好忙好忙。 开始怀念刚入职没事干的状态了。 之前是有时间没事干。 现在是有想干的事没时间。 刷旧周刊看到个感兴趣的极简朋友圈，也就是像这样的微博客，好像搞搞试试但没空。此外那个作者还有别的极简项目比如博客和论坛，都感兴趣都想搞都没时间。 不想上班啦！ 2024-10-22 20:49:47 cursor到期了。本来想换github copilot，毕竟前者20刀后者10刀便宜一半，但外币支付方式懒得整放弃了。 因为大语言问答模型一直用得阿里家的通义千问，这段时间也试了试通义灵码。不知道是我没调设置还是怎么得，体验非常糟糕，自动补全又慢又少。我主要还是用自动补全不怎么用问答功能就弃了。 找了找现在用的CodeGeeX。首先完全免费，其次支持本地部署不怕代码泄露和突然收费，再者中文支持好文档也全。用了一段时间感觉聊胜于无，只能说总比没有好。习惯了cursor的精确度感觉别家的代码补全都是半个智障。 2024-10-25 2024-10-25 21:07:39 这几天忙得脑子都木了。常规工作时间段以外的加班，反而成了难得的闲暇时光。看看博客再搞点自己的代码，因为人少所以可以光明正大地摸鱼。而且人坐在办公室，干的也算半件正事不算纯粹在玩，所以也没什么荒废时间的心理压力。还能蹭公司的夜宵和加班费，好耶。 2024-10-28 2024-10-28 19:42:59 工作越积越多，催促的声音也多了起来。已经没有空闲去慢悠悠地检查和测试了，蒙头写写完就交。虽然对不起测试但也算把一部分工作量甩出去了。 2024-10-31 2024-10-31 14:57:06 刚忙完一个项目，以为可以休息一下时下一个项目马上安排下来了。 好忙好忙好忙好忙。。。 ","link":"https://jinvic.github.io/post/micro-blog-2024-10/"},{"title":"《Go程序设计语言》阅读笔记","content":"《Go程序设计语言》阅读笔记 《Go程序设计语言》阅读笔记 第1章 入门 第2章 程序结构 2.1 名称 2.2 声明 2.3 变量 2.3.1 短变量声明 2.3.2 指针 2.3.3 new 函数 2.3.4 变量的生命周期 2.4 赋值 2.4.1 多重赋值 2.4.2 可赋值性 2.5 类型声明 2.6 包和文件 2.7 作用域 第3章 基本数据 3.1 整数 3.2 浮点数 3.3 复数 3.4 布尔值 3.5 字符串 3.5.1 字符串字面量 3.5.2 Unicode 3.5.3 UTF-8 3.5.4 字符串和字节 slice 3.5.5 字符串和数字的相互转换 3.6 常量 3.6.1 常量生成器 iota 3.6.2 无类型常量 第4章 复合数据类型 4.1 数组 4.2 slice 4.2.1 append 函数 4.2.2 slice 就地修改 4.3 map 4.4 结构体 4.4.1 结构体字面量 4.4.2 结构体比较 4.4.3 结构体嵌套和匿名成员 4.5 JSON 4.6 文本和HTML模板 第5章 函数 5.1 函数声明 5.2 递归 5.3 多返回值 5.4 错误 5.4.1 错误处理策略 5.4.2 文件结束标识 5.5 函数变量 5.6 匿名函数 5.7 变长函数 5.8 延迟函数调用 5.9 宕机 5.10 恢复 第6章 方法 6.1 方法声明 6.2 指针接收者的方法 6.3 通过接口提内嵌组成类型 6.4 方法变量与表达式 6.5 示例：位向量 6.6 封装 第7章 接口 7.1 接口即约定 7.2 接口类型 7.3 实现接口 7.4 使用 flag.Value 来解析参数 7.5 接口值 7.6 使用 sort.Interface 来排序 7.7 http.Handler 接口 7.8 error 接口 7.9 示例：表达式求值器 7.10 类型断言 7.11 使用类型断言来识别错误 7.12 通过接口类型断言来查询特性 7.13 类型分支 7.14 示例：基于标记的XML解析 7.15 一些建议 第8章 goroutine和通道 8.1 goroutine 8.2 示例：并发时钟服务器 8.3 示例：并发回声服务器 8.4 通道 8.4.1 无缓冲通道 8.4.2 管道 8.4.3 单向通道类型 8.4.4 缓冲通道 8.5 并行循环 8.6 示例：并发的Web爬虫 8.7 使用select多路复用 8.8 示例：并发目录遍历 8.9 取消 8.10 示例：聊天服务器 第9章 使用共享变量实现并发 9.1 竞态 9.2 互斥锁 sync.Mutex 9.3 读写互斥锁：sync.RWMutex 9.4 内存同步 9.5 延迟初始化：sync.Once 9.6 竞态检测器 9.7 示例：并发非阻塞缓存 9.8 goroutine 与线程 9.8.1 可增长的栈 9.8.2 goroutine 调度 9.8.3 GOMAXPROCS 9.8.4 goroutine 没有标识 第10章 包和 go 工具 10.1 引言 10.2 导入路径 10.3 包的声明 10.4 导入声明 10.5 空导入 10.6 包及其命名 10.7 go 工具 10.7.1 工作空间的组织 10.7.2 包的下载 10.7.3 包的构建 10.7.4 包的文档化 10.7.5 内部包 10.7.6 包的查询 第11章 测试 11.1 go test 工具 11.2 Test 函数 11.2.1 随机测试 11.2.2 测试命令 11.2.3 白盒测试 11.2.4 外部测试包 11.2.5 编写有效测试 11.2.6 避免脆弱的测试 11.3 覆盖率 11.4 Benchmark 函数 11.5 性能刨析 11.6 Example 函数 第12章 反射 12.1 为什么使用反射 12.2 reflect.Type 和 reflect.Value 12.3 Display: 一个递归的值显示器 12.4 示例: 编码S表达式 12.5 使用 reflect.Value 来设置值 12.6 示例：解码S表达式 12.7 访问结构体字段标签 12.8 显示类型的方法 12.9 注意事项 第13章 低级编程 13.1 unsafe.Sizeof、Alignof 和 Offsetof 13.2 unsafe.Pointer 13.3 示例：深度相等 13.4 使用cgo调用C代码 13.5 关于安全的注意事项 第1章 入门 给几个例子快速讲解go语言的结构例子，如果是对go比较熟悉的读者或许会比较方便。但我是从零开始，对我而言跳跃得有些太快了，看到1.4就跟不上了。不过也没关系，从第二章开始看更详细更系统化。 第2章 程序结构 2.1 名称 给出Go语言中的关键字和预声明的常量、类型和函数，有需要可以查表。 命名规则 一般使用驼峰式，首字母缩写使用相同大小写。 2.2 声明 没啥内容，重要的都放在后续章节详细展开。 2.3 变量 变量声明通用形式：var name = expression 类型和表达式可以省略其一。如果省略类型，将由表达式自动推断；如果省略表达式，初始值为对应类型的零值。 2.3.1 短变量声明 name := expresion 短小灵活，常用于局部变量的声明和初始化 不需要声明所有变量，对已声明变量相当于赋值 最少声明一个新变量 2.3.2 指针 基本用法和C一致，使用&amp;取地址，*解引用。 简单介绍了flag包的用法来辅助说明指针。 2.3.3 new 函数 表达式new(T)将创建一个未命名的T类型变量，初始化为该类型的零值，并返回其地址。简单来说，就是方便快捷地获取某一类型的地址，而不必先声明再取地址。 new是一个预声明的函数，不是关键字，可以被重定义。 2.3.4 变量的生命周期 生命周期的概念很多编程语言都有，不用再看一遍。 这部分还提到了垃圾回收和变量逃逸的概念，不过也是浅尝辄止，不看也行。 2.4 赋值 Go和C++类似有着形如+=这样的运算赋值和++,--这样的自增自减运算。 2.4.1 多重赋值 和Python类似，Go也可以同时为复数变量赋值，并可以将不需要的值赋给空标识符_。 2.4.2 可赋值性 没看懂在讲什么，但是不重要。 2.5 类型声明 type name underlying-type 和C++的typedef类似，Go也可以通过type关键字为某一类型设置一个别名，方便阅读理解和使用。但不同的是，Go使用type定义的命名类型，即使底层类型相同也不能使用算术表达式进行比较和合并，主要是为了避免混用。 这部分还提了下类型声明在接口中的使用方法，这将在第七章详细说明。 2.6 包和文件 可见性 声明在函数内部，是函数的本地值，类似private 声明在函数外部，是对当前包可见(包内所有.go文件都可见)的全局值，类似protect 声明在函数外部且首字母大写是所有包可见的全局值,类似public 2.7 作用域 大部分内容都不难理解。只是有一个地方需要注意一下：短变量声明依赖一个明确的作用域。错误示例： var x int = 0 if true { x, y := 1, 2 fmt.Println(x, y) } x += x fmt.Println(x) //1，2 //0 在如上代码中，x,y在内部作用域都为声明，短变量声明:=将会将x,y都声明为内部的局部变量，使外部的x声明不可见，从而未能成功变更外部x的值。这是一个很隐蔽的错误，甚至不会报错。 要避免这个错误，可以放弃使用短变量声明而是先声明再直接赋值： var x int = 0 if true { var y int x, y = 1, 2 fmt.Println(x, y) } x += x fmt.Println(x) //1，2 //2 第3章 基本数据 Go四类数据类型：基础类型（basic type），聚合类型（aggregate type），引用类型(reference type)，接口类型（interface type）。 3.1 整数 数据类型和C中的stdint.h类似，对不同位数的int进行了精确划分，这里记几个比较特殊的。 rune和int32同意，指明一个值是Unicode码点（code point）。 byte和uint8同意，强调一个值是原始数据而非量值。 uintptr大小不定，完整存放指针，用于底层编程。 这部分还介绍了算数运算符，逻辑运算符和位运算符以及他们之间的优先级，有需要可以查表。 位运算符和C稍有不同，记一下。 ^作为二元运算符表示按位“异或”(XOR)，如果需要写次方可以用math.Pow()。作为一元运算符表示取反。 &amp;^表示按位清除（AND NOT），如表达式z=x&amp;^y中，若y的某位是1,则z的对应位等于0;否则，它就等于x的对应位。 格式化输出八进制%o，十六进制%x时，前面的副词#告知是否输出相应前缀0，0x。 3.2 浮点数 格式化输出浮点数时，%g会自动保持足够的精度，%e（有指数）%f（无指数）能自定义输出宽度和数值精度。 3.3 复数 GO居然还有复数类型，但感觉我用不上就没怎么看，应该科学计算或者图形学会用的多些。 3.4 布尔值 唯一需要注意的是Go中整数不能像C那样直接当布尔值用需要显性转换。 3.5 字符串 和python类似，没啥新东西。 3.5.1 字符串字面量 介绍了一些转义符，可以查表。 字符串字面量使用双引号，可以转义。 原生的字符串字面量使用反引号，不能转义，可以展开多行。 3.5.2 Unicode 介绍Unicode来源和rune。 3.5.3 UTF-8 略，有需要再翻书。 3.5.4 字符串和字节 slice 比较了字符串和slice，因为不熟悉slice没看出什么重点，有空回头补。 3.5.5 字符串和数字的相互转换 略，有需要再翻书。该加速了，少扣点细节。 3.6 常量 同时声明一组常量时，可以省略第一项以外的表达式，这时会复用前一项的表达式及类型。 3.6.1 常量生成器 iota iota从0开始取值逐项加1。复数声明常量时由于复用表达式可以达到不同初始值的效果。具体实例见书。 3.6.2 无类型常量 略，有需要再翻书。 第4章 复合数据类型 4.1 数组 大部分都是基础知识，有一些比较新奇的定义方法： 使用...代替数组长度，数组长度将有初始化时的元素个数决定，如arr := [...]int{1,2,3}长度为3。 初始化时可以使用pos:value仅定义部分元素，未定义的元素默认为零值。如arr := [...]int{4:1}，即为{0,0,0,0,1}。 在如C等编程语言中，数组都是隐式的引用传递，而在Go中，直接传递数组当参将会和其他类型一样使用值传递，创建一个副本。此外，数组的大小也是其类型的一部分，类型 [10]int 和 [20]int 是不同的。 4.2 slice slice的大部分操作都和数组类似，主要是长度不定，概念和用法更接近c的vector和python的list。slice的零值是nil。slice也可以通过make([]T, len, cap)来声明，其中容量可省略。 slice和数组的区别首先是定义式slice不需要指定长度。然后是数组可以直接比较而slice不可以，需要手写比较函数。 4.2.1 append 函数 在讲什么没找到重点。可能是想让读者注意一下len和cap吧，但这个基本上都是隐性的用的时候真不用想真么多。 4.2.2 slice 就地修改 介绍一些slice的精细操作，还是感觉没大用。 4.3 map 记一下定义方式：ages := make(map[string]int) 可以使用{key:value,...}初始化，以及delete(key,value)删除元素。 map和slice都是引用，不能直接获取地址，可以用range遍历，将返回键值对。 map中元素迭代顺序不固定，一般认为是随机的，可以是程序在不同散列算法实现下变得健壮。如需按顺序遍历，必须显式地给键排序。 map类型的零值是nil，大多数map操作都可以在零值nil上执行，但设置元素会导致错误，必须先初始化map。 可以通过if value, ok := m[key]; !ok来判断这个元素是不存在还是零值。 map需求特殊数据类型作为键（如slice），可以定义一个帮助函数中转，将不可比较的数据类型映射到字符串。示例如下： var m make(map[string]int) func k(list []string) string { return fmt.Sprintf(&quot;%q&quot;, list) } func Add(list []string) { m[k(list)]++ } func Count(list []string) { return m[k(list)] } 4.4 结构体 定义： type struct1 struct{ field1 type1 field2 type2 struct2 // 嵌入结构体，继承所有字段 Embedded struct3 struct3 // 嵌套结构体，通过.访问子结构体字段 Nested } 结构体定义时不能定义一个相同结构体类型的成员变量（对其他聚合类型也适用），但可以定义一个指向该类型的指针，从而实现递归数据结构，比如链表和树。 结构体零值由成员零值组成。 没有成员变量的结构体为空结构体，写作struct{}。这里没有过多介绍空结构体，作者似乎也不提倡这么用。 4.4.1 结构体字面量 可以通过结构体字面量，即设置结构体成员变量来设置结构体的值。有两种格式，两种方法不能混用： 按顺序为每个成员变量赋值 可读性差，仅用于顺序明显的小结构体 指定成员变量名称和值 不需要按顺序，可以仅赋值部分成员 关于结构体指针的使用和c类似，不再赘述。 4.4.2 结构体比较 4.4.3 结构体嵌套和匿名成员 关于这部分内容我最早还是再gorm里看到的。那边把两种情况分开，分别叫嵌套（Nested）和嵌入（Embedded），这边都叫嵌套，然后匿名作为一种特殊用法。 type Point struct {X,Y int} type Circle struct {Point; Radius int} type Wheel struct {Circle; Spokes int} 这时就可以直接访问需要变量而省略中间变量，即匿名成员： var w Whell w.x = 1 // 两种用法等价 W.Circle.Point.y = 1 但是使用结构体字面量初始化并不能省略，需要遵循定义： var w1, w2 Wheel w1 = Wheel{Circle{Point{1,2},3},4} w2 = Wheel{ Circle : Circle{ Point : Point{ X : 1, y : 2, }, Radius : 3, }, Spoke : 4, } 4.5 JSON json格式略。 Go数据结构转换为JSON: json.marshal(v any) 返回一个不带任何多余空白字符的很长的字符串。 json.marshalIndent(v any,prefix string,indent string) 输出格式化结果，prefix为前缀，indent为缩进。 只有可导出的成员才能转换为json。 可以使用 成员标签定义 更改转换为json后的字段名，如json:fieldname。 JSON解析为Go数据结构： json.unmarshal(data []byte, v any) jsong字段关联到结构体成员时忽略大小写，但存在下划线的话还是要用标签定义。 流式解码器json.Decoder,使用示例： terms := []string{&quot;...&quot;} q := url.QueryEscape(string.Join(terms, &quot; &quot;)) resp, err := http.Get(URL + &quot;?q=&quot; + q) defer resp.Body.Close() json.NewDecoder(resp.body).decode(&amp;result) 4.6 文本和HTML模板 模板是一个字符串或者文件，它包含一个或者多个两边用双大括号包围的单元 {{...}}，这称为操作。 操作提供的功能： 输出值 选择结构体成员 调用函数和方法 描述控制逻辑 实例化其他模板 . 表示模板里的参数 range var end 表示循环，此时的.表示var里的元素 | 将上一个操作的结果作为下一个操作的输入，和管道类似。 通过模板输出： template.New 创建并返回一个新的模板 Func 添加函数到模板内部可以访问的函数列表 Parse 解析文本模板 temlate.Must 错误处理，详见5.9 temp1, err := template.New(&quot;name&quot;).Funcs(template.FuncMap{&quot;func1&quot;: func1}).Parse(text) temp1 = temlate.Must(temp1) html/template包使用和text/template包里面一样的API和表达式语 句，并且额外地对出现在HTML、JavaScript、CSS和URL中的字符串进行自动转义。 第5章 函数 5.1 函数声明 func name(parameter-list)(result-list){ body } 函数的基本内容略。 如果几个形参或返回值类型相同则可以简写：a int, b int-&gt;a, b int go函数支持复数返回值，并允许在返回值列表中显性声明变量，此时return的内容可省略，即裸返回。 func func1()(res int）{ ... ; return } 函数的类型称为 函数签名 。 有些函数声明没有函数体，说明这个函数使用了Go以外的语言实现。 5.2 递归 略 5.3 多返回值 如果一个函数返回一组值，想要使用这些返回值就必须显式地将其赋给变量。 如果想要忽视其中一部分可以赋给空标识符_。 一个多值调用可以当作多个参数进行传参。 5.4 错误 与许多其他语言不同，Go语言通过使用普通的值而非异常来报告错误。尽管Go语言有异常机制，这将在5.9节进行介绍，但是Go语言的异常只是针对程序bug导致的预料外的错误，而不能作为常规的错误处理方法出现在程序中。 这样做的原因是异常会陷人带有错误消息的控制流去处理它，通常会导致预期外的结果:错误会以难以理解的栈跟踪信息报告给最终用户，这些信息大都是关于程序结构方面的而不是简单明了的错误消息。 5.4.1 错误处理策略 传递错误，使子例程的错误变为主调例程错误。 使用fmt.Errorf()格式化错误信息并返回新的错误值，为原始错误信息添加额外上下文信息来建立可读的错误描述。 对操作进行重试，超出次数或时间后再报错退出。 输出错误并停止程序。 fmt.Fprintf(os.Stderr, &quot;...%v...\\n&quot;, err) log.Fatalf(&quot;...%v\\n&quot;, err) 只记下错误信息然后程序继续运行。 5.4.2 文件结束标识 io.EOF定义： package io import &quot;errors&quot; // 当没有更多输入时返回EOF var EOF =errors.New(&quot;EOF&quot;) 检测示例： in := bufio.NewReader(os.Stdin) for { r, _, err := in.ReadRune() if err == io.EOF { break //结束读取 } if err != nil{ return fmt.Errorf(&quot;read failed: %v&quot;, err) } } // ...使用r... 5.5 函数变量 函数变量的零值为nil（空值），不能调用空的函数变量。 函数变量可以和空值比较的，但它们本身不可比较。 5.6 匿名函数 命名函数只能在包级别作用域声明。但使用 函数字面量 能在任何表达式内指定函数变量。函数字面量就像函数声明，但在func关键字后面没有函数的名称。它是一个表达式，它的值称作匿名函数。 更重要的是，以这种方式定义的函数能够获取到整个词法环境，因此里层的函数可以使用外层函数中的变量。 警告：捕获迭代变量： func main() { var printNums []func() nums := []int{1,2,3,4,5,6,7,8,9,10,11} for _, num := range nums { // num := num // 解决方法 printNums = append(printNums, func() { fmt.Printf(&quot;%d &quot;, num) // NOTE: incorrect! }) } for _, f := range printNums { f() } fmt.Println() } // $ go run main.go // 11 11 11 11 11 11 11 11 11 11 11 在Go语言中，迭代变量捕获通常指的是在使用循环（如for循环）与匿名函数或闭包结合时，循环的迭代变量被闭包捕获的现象。这种情况下，如果闭包在其外部函数返回后仍然存活，并且在之后的某个时刻被调用，那么它访问的是迭代变量的最终值，而不是特定迭代中的值。 解决方法：用局部变量拷贝循环变量的值。 简单说就是闭包中存的迭代变量使用的是引用地址，而不是本身的值，所以迭代完成后存的是同一个地址。拷贝变量就为每次迭代分离出一个独立的地址。因为Go中为了方便，值和指针基本是混用的区别很少，所以可能不是很好理解。我也不确定我的理解对不对。 5.7 变长函数 在参数列表最后的类型名称前使用省略号...声明变长函数，可以传递任意数目该类型的参数。 当实参存在slice中时，在和后面放一个省略号来调用变长函数。以下两种调用等价： func sum(vals ...int) int { } values := []int{1,2,3,4} sum(1,2,3,4) sum(values...) 5.8 延迟函数调用 语法上，一个defer语句就是一个普通的函数或方法调用，在调用之前加上关键字defer。函数和参数表达式会在语句执行时求值，实际的调用推迟到包含defer语句的函数结束后才执行。defer语句没有限制使用次数;执行的时候以调用defer语句顺序的倒序进行。 5.9 宕机 宕机发生时，程序执行终止，goroutine所有延迟函数执行，程序异常退出并留下日志信息，包括宕机的值（错误消息），函数调用的栈跟踪消息，用于诊断问题原因。 5.10 恢复 8910这三部分其实都没看懂，勉强抄点书。 如果内置的recover函数在延迟函数的内部调用，而且这个包含defer 语句的函数发生宕机，recover会终止当前的宕机状态并且返回宕机的值。函数不会从之前宕机的地方继续运行而是正常返回。如果recover在其他任何情况下运行则它没有任何效果且返回nil。 func doSomethingThatPanic() { panic(&quot;something went wrong&quot;) } func main() { defer func() { if r := recover(); r != nil { log.Printf(&quot;Recovered in main: %v&quot;, r) } }() doSomethingThatPanic() fmt.Println(&quot;This line will not be reached.&quot;) } 第6章 方法 6.1 方法声明 方法声明和函数类似，但在前面多了一个参数，将方法显式地绑定在对应类型上。 Go语言中，接收者不使用如this或self的特殊名，而是自己定义。 Go和其他面向对象语言不同，可以把方法绑定到任何类型上，可以方便地为简单类型定义附加行为。 6.2 指针接收者的方法 由于主调函数会复制每一个实参变量，如果函数需要更新一个变量，或者如果一个实参太大而我们希望避免复制整个实参，因此我们必须使用指针来传递变量的地址。这也同样适用于更新接收者:我们将它绑定到指针类型，比如*Point。 习惯上遵循如果Point的任何一个方法使用指针接收者，那么所有的Point方法都应该使用指针接收者，即使有些方法并不一定需要。 关于实参接收者和形参接收者： 同一类型，比如都是T或*T，没问题 实参T形参*T，编译器会隐式取地址 实参*T形参T，编译器会隐式解引用 总之就是在调用方法时不用太在意类型，编译器基本都会隐式转换为合适的类型。这样做简洁明了，避开了指针这一个常规重难点，但有时也会引起混乱，分不清楚当前类型。 nil是一个合法的接收者： 就像一些函数允许nil指针作为实参，方法的接收者也一样，尤其是当nil是类型中有意义的零值(如map和 slice 类型)时，更是如此，例如用list *List = nil表示空链表。当定义允许nil作为接收者时应该在注释中显式标明。 6.3 通过接口提内嵌组成类型 和前面匿名成员提到的内容差不多，不再赘述。 6.4 方法变量与表达式 可以把方法赋给一个方法变量，它是一个函数，把方法绑定在一个接收者上，此时函数只需要提供实参不需要提供接收者。如func1 := t.func; func1(a,b,c) 类似的还有方法表达式，必须提供接受者并按照选择子语法调用，把原来的接收者换成函数的第一个形参，可以像函数一样调用。如func2 := T.func; func2(t,a,b,c) 6.5 示例：位向量 没啥内容 6.6 封装 Go语言只有一种方式控制命名的可见性:定义的时候，首字母大写的标识符是可以从包中导出的，而首字母没有大写的则不导出。同样的机制也同样作用于结构体内的字段和类型中的方法。结论就是，要封装一个对象，必须使用结构体。 另一个结论就是在Go语言中封装的单元是包而不是类型。无论是在函数内的代码还是方法内的代码，结构体类型内的字段对于同一个包中的所有代码都是可见的。 封装的优点： 使用方不能直接修改对象的变量，不需要更多语句检查变量的值。 隐藏实现细节防止属性改变，设计者可以更灵活地改变API实现而不破坏兼容性。 防止使用者肆意更改对象内变量。 第7章 接口 7.1 接口即约定 接口是一种抽象类型，不暴露所含数据和内部结构，只提供一些方法。简单来说相当于提供一个黑盒，不用关心内部实现只要知道能干什么就行。其实我们学编程大部分适合也是学着使用一个个黑盒而已，只不过我们不止用还负责造罢了。 7.2 接口类型 定义所含方法，嵌入其他接口，或者两者混用。这有必要单独开一节讲吗。。。 7.3 实现接口 如果一个类型实现了接口要求的所有方法，那么这个类型实现了这个接口。这时我们常说某类型是一个（is a）特定的接口类型。 给接口赋值时，只有当表达式实现了接口时才能赋值给该接口。 接口封装了对应的类型和数据，只有通过接口暴露的方法才可以调用，类型的其他方法无法通过接口调用。 interface{}被称为空接口类型。它对其实现类型没有任何要求，因此可以把任何值赋给空接口类型。 之后介绍了一下定义接口的方法，例如从类型出发，提取共性等等。 7.4 使用 flag.Value 来解析参数 没啥内容，就一示例。 7.5 接口值 接口值分为两部分：一个具体类型和该类型的一个值，分别称为接口的动态类型和动态值。 讲什么编译时动态分发，没看懂。不过不影响用接口。 一个接口值可以指向多个任意大的动态值。 这段也没看懂。 接口值的比较 接口值可以用==和!=做比较。 两个接口相等要求都是nil或动态类型和动态之都一致。 因为接口值可以比较，所以可以作为map的键或则和switch的操作数。 此外，接口值动态类型一致但动态值不可比较也很常见。 相比其他类型的可比性是确定的，接口类型的比较必须是否小心确认其可比性。 获取接口值动态类型 可以使用fmt包的%T实现。 var w io.Writer fmt.Printf(&quot;%T\\n&quot;，w)//&quot;&lt;nil&gt;&quot; w= os.Stdout fmt.Printf(&quot;%T\\n&quot;，w)//&quot;*os.File&quot; w= new(bytes.Buffer) fmt.Printf(&quot;%T\\n&quot;,w)//&quot;*bytes.Buffer&quot; 在内部实现中，fmt用反射获取接口的动态类型，这将在12章详细讨论。 注意：含有空指针的非空接口 假设由如下代码 var buf *bytes.Buffer f(buf) func f(out io.Writer){ if(out!=nil){ out.Write([]byte(&quot;done!\\n&quot;)) } } 当函数运行到out.Write时会报错，因为out的值为空，即方法的接收者为空。前面我们说过，接口值包括动态类型值和动态值。在把形参的空指针buf赋给实参out时，out的动态类型由nil变为了*bytes.Buffer。而只有动态类型和动态值都为nil的接口值才为空，所以out通过了非空检查。 正确做法是一开始就把buf类型定义为io.Writer,避免把功能不完整的值（仅有类型）赋给接口。 7.6 使用 sort.Interface 来排序 一个接口的使用示例 7.7 http.Handler 接口 接口的使用示例，介绍一个特殊的接口http.Handler，但我没看懂特殊在哪，而且对http相关也不熟悉，到底什么课会教啊，怎么感觉不管看什么都默认对它很熟悉的样子。。。 7.8 error 接口 这里还找到个错，书上“包含”写成“不含”了。投稿会不会给我钱（想peech） 后面好像全是示例，先跳一下吧。 7.9 示例：表达式求值器 7.10 类型断言 一文掌握 Golang 中的类型断言 书上原文讲的有点散，换了篇更通俗的文自己看。有时候学东西没必要死磕，看看别人怎么讲的对照一下说不定更好理解。 Golang 中的接口是一种抽象类型，可以存储任何实现了该接口方法的类型实例。然而，由于接口本身不包含类型信息，需要通过类型断言来将接口变量转换为实际类型。基本语法如下： value, ok := x.(T) x 是一个接口类型的变量，T 是希望断言的类型。value 将会是 x 转换为类型 T 后的值，ok 是一个布尔值，当类型断言成功时为 true，失败时为 false 。也可以不带ok，但如果断言失败会引发 panic。 x 必须是接口类型，非接口类型的 x 不能做类型断言。 T如果是非接口类型，检查x的动态类型是否为T，即 T 应该实现 x 的接口。 T 如果是接口，则 x 的动态类型也应该实现接口 T。 如果操作数是空接口值，则类型断言失败。 7.11 使用类型断言来识别错误 MARK 没怎么看懂，好像大概意思就是通过断言转换成特定类型，含有更多的信息。 再给给个例子说明，并提示通过fmt.Errorf等合并错误消息可能丢失结构信息，最好在失败操作发生时马上处理错误，而不是返回给调用者后。 7.12 通过接口类型断言来查询特性 咕，看不懂。接口这个东西放到实战怎么能衍生出这么多复杂东西。我还以为有个方法就算接口了，结果用起来千奇百怪，也不知道是go的特性还是其他面向对象语言都这样。 7.13 类型分支 MARK 关于联合，可识别联合，类型多态，特设多态等一大堆专有名词没看懂。 简单来说，x.(type)可以返回类型，配合switch和重用变量名可以很方便判断类型并操作： func sqlQuote(x interface{}) string { switch x := x.(type) { case nil: return &quot;NULL&quot; case int, uint: return fmt.Sprintf(&quot;%d&quot;, x) //这里x类型为interface{} case bool: if x { return &quot;TRUE&quot; } return &quot;FALSE&quot; case string: return sqlQuotestring(x) //(未显示具体代码) default: panic(fmt.Sprintf(&quot;unexpected type %T:%v&quot;, x)) } } 7.14 示例：基于标记的XML解析 看得脑子一团浆糊，先看看别的换换脑子吧。是我前置知识不够吗？在学校的时候应该多学点的。 7.15 一些建议 MARK 略 第8章 goroutine和通道 8.1 goroutine go的并发相对其他编程语言很简单，只需要在函数或方法前加上go关键字即可创建一个goroutine并发执行操作。goroutine类似于线程，但其实是一个更小的单位。 8.2 示例：并发时钟服务器 略，很简单的一个例子，顺便介绍了时间格式化。 8.3 示例：并发回声服务器 略，很简单的一个例子 8.4 通道 通道是可以让一个goroutine发送特定值到另一个goroutine的通信机制。通道的类型为chan。 ch := make(chan int) 通道是一个使用make创建的数据结构的引用。当复制或参数传递时引用同一份数据结构，零值为nil。 同种类型的通道可以比较，当引用同一通道数据时返回true，也可以和nil进行比较。 通道的两个操作：发送和接收，都使用操作符&lt;-，数据从右到左传递。在接收表达式中，结果未使用也是合法的。 ch &lt;- x // 发送语句 x = &lt;- ch // 赋值语句，接收表法式 &lt;- ch // 接收语句，丢弃结果 可以使用close(ch)来关闭通道。它设置一个标志位来指示通道关闭。关闭后发送将宕机（panic），关闭后接收将获取发送的值直到通道为空。此时接收操作完成并获取通道元素类型对应的零值。 make不带参数创建的为 无缓冲通道，也可以带一个可选参数表示通道容量来创建 缓冲通道。 8.4.1 无缓冲通道 无缓冲通道上的发送和执行操作将 堵塞 ，直到另一方执行相反操作。这将导致发送和接收goroutine 同步化 ，因此无缓冲通道也被称为 同步通道 。 当x即不比y早也不比y晚时称x和y并发，但顺序是不确定的，需要主动排序。 一点点错误处理知识，略。 强调通道本身及通讯发送时间等方面时，把消息叫做事件。当事件没有携带消息，只用于进行同步时，通过一个struct{}类型的通道来强调它done &lt;- struct{}{} 8.4.2 管道 通道可以连接goroutine，使一个的输出成为另一个的输入，即管道（pipeline）。 没有一个直接的方式判断通道是否以及关闭，但可以通过接收结果间接判断。 go func(){ for { x,ok := &lt;- ch if !ok { break // 通道关闭且读完 } // ... } } 关闭每一个通道不是必须的，只有通知接收方goroutine所有数据发送完毕才需要关闭通道。垃圾回收器将根据是否可访问来回收，而不是是否关闭。 关闭已关闭的通道和关闭空通道都会导致宕机。关闭通道也可以作为一个广播机制，详见8.9。 8.4.3 单向通道类型 为了文档化限制通道仅发送或仅接收的意图，Go提供了单向通道类型，chan&lt;-只能发送，&lt;-chan只能接收，违反这个原则会在编译时被检查出来。 close操作说明的是通道上没有数据再发送，所以只能关闭发送通道，关闭仅接收通道会在编译时报错。 赋值操作或者参数调用可以把双向通道转化为单向通道，但反过来不行。 8.4.4 缓冲通道 可以通过cap(ch)获取缓冲区容量，len(ch)获取通道内元素个数。 MARK 一点关于goroutine泄露的内容，不是很懂。 最后介绍一点缓冲和无缓冲的区别，用流水线作例子。有点似懂非懂。 8.5 并行循环 MARK 看是看懂了好像，但找不出重点。以后需要些并行循环时再回来看看吧。 8.6 示例：并发的Web爬虫 MARK 提了一下避免死锁，但没有展开，我也不知道为什么会导致死锁 之后介绍并行度不是越高越好，总有各种限制。 使用容量为n的缓冲通道建立并发原语，称为 计数信号量。每一个孔宪草表示一个令牌，保证没有接收操作时最多由n个发送。 另一种方法是通过n个长期存活的goroutine调用，保证最多只有n个并发。 8.7 使用select多路复用 select多路复用示例： select { case &lt;-ch1: // ... case x := &lt;-ch2: // ...use x... case ch3 &lt;- y: // ... default: // ... } select将保持等待直到出现通信，然后进行这次通信并执行对应语句。 如果没有对应情况将永远等待。可以设置一个&lt;-time.After(...)来实现超时退出。 如果多个情况同时满足，select将随机选择一个。 此外还介绍了计时器time.tick怎么避免goroutine泄露。 可以使用select实现非阻塞通信。select的default用于指定没有其他通信发生时立即执行的动作，这是一个非阻塞的动作，重复这个动作称为对通道轮询。 8.8 示例：并发目录遍历 进一步介绍并发的写法，引入select，time.Tick，break loop，sync.WaitGroup,计数信号量等。 8.9 取消 可以创建一个取消通道，再上面不发送任何值，关闭表示取消该goroutine。同时定义一个工具函数cancelld，被调用时检测或轮询取消状态。 var done = make(chan struct{}) func cancelled() bool { select { case &lt;-done: return true default: return false } } 创建一个goroutine，堵塞地等待触发条件，如果满足条件就通过关闭goroutine来关闭done通道来广播取消事件。 // 当检测到输入时取消遍历 go func() { os.Stdin.Read(make([]byte,1)) // 读一个字节 close(done) } 在主goroutine添加关闭通道后的处理： for{ select{ case &lt;-done: // 处理一些待完成任务，相当于退出函数 return } } 让子goroutine在开始时轮询取消状态，如果已被取消，则什么都不做立即返回。 go func ... { if cancelled(){ return } // 正常子goroutine内容 } MARK： 最后介绍一点程序退出后的清理，这部分没看懂。 8.10 示例：聊天服务器 MARK： 暂略 第9章 使用共享变量实现并发 9.1 竞态 考虑一个在串行程序中正确工作的函数，如果它在并发调用时仍能正确工作，那么这个函数是并发安全的。 程序并发安全不需要每一个类型都是并发安全的。对于绝大部分变量，如果要回避并发访问，要么限制变量只存在一个goroutine内，要么维护一个更高层的互斥不变量。 导出的包级别函数通常可以认为是并发安全的，因为包级别变量无法限制在一个gouroutine内，修改这些变量的函数必须采用互斥机制。 数据竞态：两个goroutine并发读写同一个变量且至少一个是写入。 不要修改变量。 e.g. 直接初始化全局变量且不再修改。 避免从多个goroutine访问同一个变量。 必须使用通道来发送查询请求或更新变量。 “不要通过共享内存来通信，而应该通过通信来共享内存” 即使变量不能受限于单个goroutine，也可以借助通道传递变量地址实现变量共享，即串行受限。 同一时间只有一个goroutine可以访问变量，即互斥机制。见下节。 9.2 互斥锁 sync.Mutex 可以使用容量为1的通道保证同时只有一个goroutine访问共享变量，即二进制信号量。 var( sema = make(chan struct{}, 1) v int ) func Use(){ sema &lt;- struct{}{} // 获取令牌 defer &lt;- sema // 释放令牌 // 使用变量v } sync包有一个单独的Mutex变量支持互斥锁模式。 var( mu = sync.Mutex v int ) func Use(){ mu.Lock() // 获取令牌 defer mu.Unlock() // 释放令牌 // 使用变量v } Go语言的互斥量是不可再入的（不能对已上锁互斥量再次上锁），所以嵌套申请互斥锁将导致死锁。 MARK 这里关于go互斥量不可再入的理由和解决方法没完全懂。 9.3 读写互斥锁：sync.RWMutex 多个读操作可以安全并发运行，但写操作需要独享的访问权限，这种锁称为多读单写锁，可以通过go的sync.RWMutex实现。 var mu sync.RWMutex var v int func Read() int { mu.RLock() // 读锁 defer mu.RUnlock() return v } RLock只能用于无写操作，但逻辑上只读的操作不一定没有写操作，如递增计数器或更新缓存。如果不确定是否有写操作仍以使用Lock。 因为需要更复杂的内部工作，只在竞争激烈时RWMutex才有优势，否则它比普通的互斥锁慢。 9.4 内存同步 MARK 介绍了一种由内存的本地缓存可能引发的问题，结论是尽量限制变量在单个goroutine内或使用互斥锁来避免数据竞态。 9.5 延迟初始化：sync.Once 对于那些一次性初始化以及初始化非必须的变量，如果直接用判v!=nil是并发不安全的，因为初始化时首先将v使用make构造再进行赋值操作，在这期间判得v!=nil但读不到正确值。 如果直接使用Mutex无法并发读，使用RWMutex实现并发安全较为复杂。 可以使用sync.Once实现这一并发安全，它包含一个布尔变量和一个互斥量，前者记录初始化是否完成，后者保护数据。 var once sync.Once var v map[string]int func InitV(){...} func GetV(s string)(int){ once.Do(InitV) return v[s] } 9.6 竞态检测器 go工具链有一个动态分析工具：竞态检测器（race detector），将-race参数加到go build,go run,go test命令中即可使用。 竞态检测器只能检测到运行时发生的竞态，所以需要晚完善的测试用例以获得最佳效果。 9.7 示例：并发非阻塞缓存 TODO： 看困了，以后再看。 有个singleflight包好像也能实现这个需求。 9.8 goroutine 与线程 9.8.1 可增长的栈 OS线程的栈内存是固定大小（通常为2MB）。 goroutine的栈内存是可增长的，初始通常为2KB，最大可达1GB。 9.8.2 goroutine 调度 线程由内核调度，通过硬件时钟触发，线程切换需要一个完整的上下文切换，成本高操作慢。 goroutine由Go自己的调度器调度，使用m:n调度（复用/调度m个goroutine到n个OS线程），通过特定的go语言结构触发，不需要切换到内核语境，成本低很多。 9.8.3 GOMAXPROCS Go调度器使用GOMAXPROCS参数确定使用多少个OS线程同时执行Go代码，默认值是机器CPU数量（m:n 调度中的n）。休眠或通道通信阻塞的goroutine不占用线程。I/O阻塞和其他系统调用或非Go函数的goroutine需要独立OS线程，但不计算在GOMAXPROCS内。 可以用GOMAXPROCS环境变量或runtime.GOMAXPROCS函数显式控制该参数。 9.8.4 goroutine 没有标识 在大部分支持多线程的操作系统和编程语言中，线程都有一个独特的标识（通常是一个整数或指针），本质上是一个全局map，能够轻松构建一个线程的局部储存。 goroutine在设计中没有提供这个标识，这是为了避免线程局部存储被滥用，鼓励一种更简单的编程风格。 第10章 包和 go 工具 10.1 引言 10.2 导入路径 10.3 包的声明 每个go源文件开头都需要进行包声明，作为被其他包引入时的标识符。 10.4 导入声明 导入多个包时可以使用多个import声明导入，也可以使用一个import (...)一次性导入多个包。一般后者更常见。 import ( &quot;fmt&quot; &quot;os&quot; ) 导入两个同名包时，需要指定别名避免冲突，也就是 重命名导入。 即使没有包名冲突，也可以使用重命名导入来简化包名或者避免局部变量冲突。 import ( &quot;crypto/rand&quot; mrand &quot;math/rand&quot; ) 10.5 空导入 可以通过将别名设置为_的方式实现空白导入，例如import _ &quot;image/png&quot; // 注册png解码器。多数情况下，它用来实现一个编译时的机制，开启主程序中可选的特性。 比起图片格式解码器，数据库驱动程序中用到的空白导入对我而言更为熟悉。 package main import ( &quot;database/sql&quot; _ &quot;github.com/go-sql-driver/mysql&quot; // 添加 MySQL 支持 _ &quot;github.com/lib/pq&quot; // 添加 Postgres 支持 ) db, err = sql.Open(&quot;postgres&quot;, dbname) // 0K db, err = sql.Open(&quot;mysql&quot;, dbname) // 0K db, err = sql.Open(&quot;sqlite3&quot;, dbname) //返回错误消息:unknown driver“sqlite3&quot; = 10.6 包及其命名 10.7 go 工具 10.7.1 工作空间的组织 现在都用go module不用gopath了，略。 10.7.2 包的下载 10.7.3 包的构建 10.7.4 包的文档化 go doc命令可以输出包的注释和内部声明，也可以输出包成员或方法的注释。 godoc在新版本不再内置，通过 go install golang.org/x/tools/cmd/godoc@latest安装。 运行命令godoc -http=:6060 -play -index，之后访问localhost:6060，就可以以互相链接的网页的形式查看注释文档了。官方的pkg.go.dev也是用的这种方式。 10.7.5 内部包 go build工具会特殊对待internal路径下的包，即 内部包。内部包只能被internal父目录为根的目录树下的包导入。 10.7.6 包的查询 go list 工具将给出可用包的信息。参数也可以包含...通配符，将匹配任意字串。go list用法如下： go list &lt;包名&gt; 判断包是否存在于工作空间，如果存在将输出导入路径。 go list ... 枚举工作空间中的所有包 go list &lt;路径&gt;/...一个指定子树中的所有包 go list ...&lt;关键字&gt;... 查询路径包含关键字的包 go list命令获取的是完整元数据，而不仅仅是导入路径。可以使用-json,-f等标记定制输出内容和格式。 第11章 测试 11.1 go test 工具 _test.go结尾的文件不是go build编译的目标，而是go test编译的目标。 *_test.go中有三种特殊函数： 功能测试函数： Test前缀，检测逻辑正确性，结果为PASS或FAIL 基准测试函数： Benchmark开头，测试操作性能，结果为平均执行时间 示例函数： Example开头，提供机器检查过的文档 11.2 Test 函数 功能测试函数必须以Test开头，后缀名以大写字母开头，如下是一个测试函数示例： type TestCase struct{ input interface{} want interface{} } func TestFunc(t *testing.T) { var tests = []TestCase // 初始化测试用例 for test := range tests{ if got := Func(test.input); got != test.want{ t.Errorf(&quot;Func(%v) = %v , want %v&quot;,test.input, got, test.want) } } } go test在不指定包参数时以当前目录所在包为参数。可选的命令行参数如下： -v 输出包中每个测试用例的名称和执行时间 -run = 正则表达式 只运行测试函数名称匹配给定模式的函数 11.2.1 随机测试 要确定随机输入的正确输出有两种方法： 使用低效但清晰的算法，比较结果是否一致。 构建符合模式的输入，从而知道对应输出。 使用rand.New(rand.NewSource(time.Now().UnixNano()))生成随机数种子，进而生成随机输入。在保存测试用例的输入时，比起保存整个输入数据结构，记录随机数种子更简便。 11.2.2 测试命令 go test除了测试代码也可用于测试命令。 11.2.3 白盒测试 黑盒测试：假设测试者仅了解公开API和文档，而内部逻辑不透明。 百合测试： 可以访问包的内部函数和数据结构，并且可以做一些常规用户无法做到的观察和改动。 在进行白盒测试时，可以保存全局变量或方法后更新其值，最后使用defer恢复，从而实现更精细的调试。 // develop file var globalVar := 10 func globalFunc( ) { //... } targetFunc( ) { // used globalVar // used globalFunc } // test file func testFunc(t testing.T){ // 保存原变量和方法 savedVar = globalVar savedFunc = globalFunc // 退出时恢复原值 defer func ( ) { globalVar = savedVar globalFunc = savedFunc } // 定义用于测试的变量和方法 globalVar = newVar globalFunc = newFunc // 测试targetFunc，将使用赋的新值 } 11.2.4 外部测试包 11.2.5 编写有效测试 11.2.6 避免脆弱的测试 TODO： 不是很懂 11.3 覆盖率 11.4 Benchmark 函数 11.5 性能刨析 11.6 Example 函数 OMIT： 略 需要再查 第12章 反射 12.1 为什么使用反射 有时需要写一个统一处理各种类型的函数（如Printf），但这些类型可能： 无法共享同一个接口 布局位置 在设计函数时不存在 12.2 reflect.Type 和 reflect.Value reflect.TypeOf接受interface{}参数，并将接口中动态类型以reflect.Type形式返回。 t := reflect.TypeOf(3) // reflect.Type fmt.Println(t) // int fmt.Println(t.String()) // int 注意：reflect.TypeOf总是返回具体类型，而不是接口类型。所以可以使用%T直接获取接口的具体类型： fmt.Printf(&quot;%T\\n&quot;, 3) // &lt;int Value&gt; reflect.ValueOf接受interface{}参数，并将接口中动态值以reflect.Value形式返回。 这里说返回值是具体值，但 也可以包含一个接口值。在接口部分我们了解到接口值包括动态类型和动态值，即reflect.Value也是包含动态值和动态类型的，调用Value的Type方法将类型以 reflect.Type返回。 reflect.ValueOf的逆操作是``reflect.Value.Interface方法，返回一个interface{}接口值，与reflect.Value`值相同。 var i interface{} = 3 fmt.Println(i) // 3 fmt.Printf(&quot;%v\\n&quot;, i) // 3 fmt.Printf(&quot;%T\\n&quot;, i) // int v := reflect.ValueOf(i) fmt.Println(v) // 3 fmt.Println(v.Int()) // 3 fmt.Println(v.Type()) // int fmt.Println(v.String()) // &lt;int Value&gt; x := v.Interface() fmt.Println(x) // 3 fmt.Printf(&quot;%d\\n&quot;, x.(int)) // 3 fmt.Printf(&quot;%T\\n&quot;, x.(int)) // int reflect.Value和interface{}都可以包含任意值，区别是空接口隐藏了值的信息，需要先进行类型断言否则操作有限，而reflect.Value有很多方法去分析值而不用知道类型。 可以使用reflect.Value的kind方法来区分类型: 基础类型：Bool，String，以及各种数字类型 聚合类型：Array和Struct 引用类型：Chan，Func，Prt，Slice和Map 接口类型：Interface Invalid类型：表示没有任何值，如reflect.Value的零值 12.3 Display: 一个递归的值显示器 12.4 示例: 编码S表达式 OMIT: 示例略 12.5 使用 reflect.Value 来设置值 一个变量是一个可寻址的存储区域，其中包含一个值，并且可以通过这个地址来更新。对reflect.Value也有类似区分，只有可寻址的Value才能用于更新变量。 调用reflect.ValueOf(&amp;x).Elem()来获得任意变量x的可寻址的Value值。对slice的e[i]也有reflect.ValueOf(e).Index(i)，得到的Value也是可寻址的，有一定的指针基础会更好理解。 通过reflect.Value.CanAddr()可以询问Value变量是否可寻址。 从一个可寻址的reflect.Value()获取变量有如下三步： 调用Addr()，返回一个Value，包含指向变量的指针。 调用Interface()，返回包含该指针的interface{}值。 使用类型断言将接口转换成普通指针。 然后就可以使用这个指针来更新变量了。 也可以使用reflect.Value.Set()直接从可寻址的Value来更新变量。 x := 2 d := reflect.ValueOf(&amp;x).Elem() // d refers to the variable x px := d.Addr().Interface().(*int) // px := &amp;x *px = 3 // x=3 fmt.Println(x) // 3 d.Set(reflect.ValueOf(4)) fmt.Println(x) // 4 12.6 示例：解码S表达式 OMIT: 示例略。 12.7 访问结构体字段标签 主要介绍通过反射去解析字段标签的底层实现，例如解析http请求并将参数绑定到结构体上。 大致过程是通过Field和Tag等方法解析结构体中的字段和标签，通过kind方法分类http请求中的数据类型选择合适的方法赋值。现在用的web框架都把这些底层逻辑封装好了，有需要时再翻书。 12.8 显示类型的方法 reflect.Type和reflect.Value都有Method(i)方法，前者返回reflect.method类型的实例，描述方法的名称和类型等。后者返回一个reflect.Value类型的方法值，可以通过reflect.Value.Call进行调用。 12.9 注意事项 基于反射的代码很脆弱。编译时能报错的错误，使用反射只有在执行时才会崩溃报告。 将反射的使用完整地封装在包内。 包的API中避免使用reflect.Value，而是特定类型。 每个危险操作前做额外的动态检查。 反射降低了自动重构和分析工具的安全性与准确度，因为它们无法检测到类型信息。类型也算文档的一直，而反射相关操作无法做静态类型检查。 基于反射的函数比特定类型优化的函数慢一两个数量级。 第13章 低级编程 很多实现细节无法通过Go程序访问，通过隐藏底层细节，Go程序有着更好的可读性和可移植性。但有时也可以放弃一些有益的保证去追求高性能，和其他语言交互和实现纯Go无法描述的函数。 这一章主要是读一下扩宽视野，掌握一些与操作系统底层交互的方式，普通程序用不上低级编程。 有C/C++基础看这些内容就跟回家了一样。 13.1 unsafe.Sizeof、Alignof 和 Offsetof 关于内存对齐的知识和方式。个人感觉平时编程其实不用关注内存对齐，关注那点内存提升不如提升可读性。真搞高性能要求的开发之类还是用C。 13.2 unsafe.Pointer 指针相关内容，C++的指针本质上只是一个内存地址，可以往里面写入任何数据。Go原本的指针做了个类型封装，而unsafe.Pointer相当于解除了这个限制。使用unsafe.Pointer还有很多注意事项，有需要再回来翻一下。 13.3 示例：深度相等 reflect.DeepEqual判断两个变量的值是否&quot;深度&quot;相等。对基本数据类型使用==进行比较，对组合类型逐层深入比较。 注意：对nil和空结构体将判断为不相等。如 reflect.DeepEqual(nil,[]string{})结果为false。 OMIT: 示例略。 13.4 使用cgo调用C代码 简单介绍cgo的用法，有需要再回来翻书。 13.5 关于安全的注意事项 高级语言隔离了许多底层细节，让我们可以编写安全健壮的代码并在任何操作系统上运行。 包unsafe可以穿透这层隔离去使用一些特性或实现更高性能，代价则是可移植性和安全性，需要自己评估风险。大多数时候我们都不需要用到unsafe包，如果确实需要使用，则尽可能限制在小范围内。 完结撒花🎉 2025.1.18 ","link":"https://jinvic.github.io/post/the-go-programming-anguage-reading-notes/"},{"title":"【毕设】网络代购货品分析与决策系统的设计与实现","content":"网络代购货品分析与决策系统的设计与实现 网络代购货品分析与决策系统的设计与实现 项目地址 参考 开发日志 day1 12.25 day2 12.26 day3 12.28 day4 12.29 day5 12.30 day6 12.31 配置venv环境 使用selenium输入账号密码 day7 1.2 day8 1.3 记一下cookie相关 day9 1.5 CSS选择器语法规则 获取滑块验证码图片 day10 1.6 opencv缺口识别算法 day11 1.7 鼠标轨迹模拟 返回Session和cookie day12 1.9 day13 1.11 day14 2.21 day14 2.28 day15 3.20 错误 invalid cookie domain day16 3.21 selenium登录&amp;搜索功能整合为类 搜索结果页获取商品id（京东） day17 3.22 day18 3.23 day19 3.28 从查价网站获取历史价格（gwdang.com） User-Agent反爬虫 webdriver识别 PyAutoGui day20 4.12 day21 4.24 day21 5.3 pandas数据清洗 day22 5.4 SmsForwarder转发验证码 SQLite数据库方法封装 账号池数据库 day23 5.5 建议：selenium版本回退 day24 5.9 day24 5.11 flask-login实现账号管理 day26 5.14 selenium页面滚动 selenium设置无头模式 day27 5.16 day28 5.20 考研结束，结果不论，可以开始做毕设了。老规矩边做边写点啥记录。这次想用日记一样的形式记录每日的进度。选题简单分为两部分，爬虫获得数据和时间预测模型处理数据。这个决策系统可能还要引入新的内容，先不管了，一个一个来吧。 项目地址 github 参考 书籍 Python3网络爬虫开发实战 第2版 Python3反爬虫原理与绕过实战 时间序列分析实战 基于机器学习和统计学 机器学习实战：基于Scikit-Learn、Keras和TensorFlow 原书第2版 文档 venv Requests英文文档 Requests中文文档 Selenium中文文档 Selenium英文文档 opencv pandas英文文档 pandas中文文档 SmsForwarder-短信转发器 flask中文文档 flask-login中文文档 jinja2英文文档 jinja2中文文档 博客 venv Understanding LSTM Networks 多变量时间序列的多步预测——LSTM模型 Python操作SQLite数据库（非常详细） 【Python开发】一文详解 Flask-Login 开发日志 day1 12.25 先稍微看了下崔庆才的Python3网络爬虫开发实战 第2版，之前学爬虫就看的这本。只不过当时只学了点基础，pyquery获取和解析网页。这次起码要把模拟登录和反爬虫之类的解决。检查发现我的电子书有缺页，难怪到后面书签就乱了。我还以为是书签的问题，zlibrary上的都有缺页，找了本第一版的对照看。 day2 12.26 爬虫有个scrapy挺有名，但我感觉没必要整这么复杂，增加额外的学习负担。先用书上的内容做做看吧，应该够用。 以前直接VSCode做的，因为项目都很简单。这次想用pycharm试试，一是熟悉专业的python开发工具，二是pycharm好像有虚拟环境，我本地的环境已经被我pip得乱七八糟了。就是好久没用pycharm好卡啊（汗）。 day3 12.28 看了看venv。虽然pycharm会帮你自动创建好，但之后可能会需要迁移什么的，有点担心。 关于反爬虫，之前一直没注意。这次看了看，书上主要提到三方面：验证码识别，代理和模拟登录。目前先做模拟登录，其他用到的时候再展开。 看了看好像京东关于模拟登录的教程都过期了，以前好歹有个表单项现在只有一串长字符没法解析，不会要寄了吧。 day4 12.29 试试能不能用自动化测试工具Selenium模拟登录来获取cookie。但这样可能不方便用代理池反爬。不知道爬多了会不会直接封账号。。。而且这样需要用户自己登录，会多出一些步骤。也许可以找些空账号来。 Selenium中文文档 Selenium英文文档 day5 12.30 感觉还是在反爬虫这方面力有未逮。之前用到爬虫时完全没考虑过反爬虫，因为爬的是个很简单的网页，访问频率也不高完全没必要反爬。中心都放在网页数据的获取和解析上，感觉还是得好好学习了解下反爬才行。选定了这本韦世东的Python3反爬虫原理与绕过实战当教材。 day6 12.31 pycharm太卡了，还是放弃了，换回VSCode。 配置venv环境 记录一下venv的基础用法：教程 创建虚拟环境：python -m venv /path/to/new/virtual/environment 激活虚拟环境：venv\\Scripts\\activate 退出虚拟环境：deactivate 主要用途是在虚拟环境内pip安装软件包，和全局环境分开。 装了Selenium和ChromeDriver。selenium直接pip就行。ChromeDriver则是需要自己下载。[这里]提供旧版下载，而Chrome for Testing availability才能下到最新版。下载后将chromedriver.exe放到venv的Scripts目录下就行。chrome浏览器必须版本对应比较麻烦，如果是Firefox的话可以向下兼容直接下最新版的geckodriver就行。可以通过chromedriver --version测试是否可用。 使用selenium输入账号密码 京东登录页面的链接为https://passport.jd.com/new/login.aspx。其中，账号输入框，密码输入框，登录按钮的id分别为loginname，nloginpwd，loginsubmit。 使用selenium输入账号密码： from selenium import webdriver from selenium.webdriver.common.by import By import time browser = webdriver.Chrome() browser.get('https://passport.jd.com/new/login.aspx') username='username' password='password' input_username=browser.find_element(By.ID,'loginname') input_username.send_keys(username) input_password=browser.find_element(By.ID,'nloginpwd') input_password.send_keys(password) button_login=browser.find_element(By.ID,'loginsubmit') button_login.click() time.sleep(10) browser.close() day7 1.2 在京东输入账号密码并点击登录后，会弹出滑动验证码验证。书上 (Python3网络爬虫开发实战第2版) 第八章介绍了验证码识别的相关内容。其中对于滑块验证码有OpenCV（P298）和深度学习（P304）两种方法。其中OpenCV识别正确率不高，而深度学习训练和维护模型相对复杂。此外还有一个选择就是打码平台，相当于付费把这个问题转接给更专业的商业平台，但我们这个毕设就暂时不考虑了。第八章最后还提到手机验证码的自动化处理，感觉暂时没必要了解。这个相当于在手机上做一个收发转发，但让用户收一下验证码填一下就行没必要再增加开发内容。 OpenCV和深度学习我暂时不知道两者的优劣，就先都做下试试。 day8 1.3 看了看书上 (Python3反爬虫原理与绕过实战) 第二章。主要是2.2浏览器和2.3网络协议，复习了一下HTML DOM,http协议,cookie,WebSocket等内容。我也不知道看这些有什么用，但看看也没事。 记一下cookie相关 Cookie可以理解为在HTTP协议下，服务器或其他脚本语言维护客户端信息的一种方式，是保存在客户端（比如浏览器）的文本文件，Cookie中往往包含客户端或者用户的相关信息。 简单理解，cookie就是一种保存在本地的身份信息。在用户登录后，服务器生成对应cookie保存在响应头的set-cookie字段中返回给客户端。之后客户端和服务器的通信都会在请求头的cookie字段中带上这个信息让服务器验证身份，就不用每次登录了。 day9 1.5 韦的书上 (Python3反爬虫原理与绕过实战) 介绍的滑块验证码，一种是缺口位置写在css里，直接从代码中拿到移动距离。一种是先不显示缺口，滑动时再用canvas绘制缺口。这种的解决方法是前后截图再比较像素找出缺口。京东的方法和上面都不一样，是直接放一个带缺口的图片作背景，只能想办法从图片中识别出缺口。崔的书上 (Python3网络爬虫开发实战第2版) 讲的就是这种情况。 做一下Opencv识别滑块验证码。 在用selenium拿图时发现id拿不了，又不想学XPath，就用CSS选择器好了。顺便记下CSS选择器的语法，表来自韦的书P92。 CSS选择器语法规则 获取滑块验证码图片 滑块和背景图为JDJRV-smallimg和JDJRV-bigimg类下的&lt;img&gt;元素，使用css选择器获取对象，urllib.request.urlretrieve下载图片： # 获取滑块验证码的滑块和背景图 bigimg_src = browser.find_element( By.CSS_SELECTOR, &quot;.JDJRV-bigimg img&quot;).get_attribute(&quot;src&quot;) # 背景图 smallimg_src = browser.find_element( By.CSS_SELECTOR, &quot;.JDJRV-smallimg img&quot;).get_attribute(&quot;src&quot;) # 滑块图 # 命名图片 bigimg='bigimg.png' smallimg='smallimg.png' # 下载图片 request.urlretrieve(url=bigimg_src,filename=bigimg) request.urlretrieve(url=smallimg_src,filename=smallimg) 缺口检测的大致流程如下： 高斯滤波 高斯滤波处理减少噪声干扰。 边缘检测 使用John F. Canny开发的的多级边缘检测算法canny。OpenCV实现了这个算法。 轮廓提取 使用findContours方法提取出边缘的轮廓。 外接矩形 使用boundingRect方法计算轮廓外接矩形，根据面积和周长等判断是不是目标缺口。 轮廓面积 可以使用contourAera方法计算面积。 轮廓周长 可以使用arcLength方法计算周长。 day10 1.6 opencv缺口识别算法 定义实现高斯滤波、边缘检测和轮廓提取的三个方法： import cv2 GAUSSIAN_BLUR_KERNEL_SIZE = (5, 5) # 高斯内核大小 GAUSSIAN_BLUR_SIGMA_X = 0 # 高斯内核X方向上标准偏差 CANNY_THRESHOLD1 = 200 # 最小判定临界点 CANNY_THRESHOLD2 = 450 # 最大判定临界点 # 高斯滤波 def get_gaussian_blur_image(image): return cv2.GaussianBlur(src=image, ksize=GAUSSIAN_BLUR_KERNEL_SIZE, sigmaX=GAUSSIAN_BLUR_SIGMA_X) # 边缘检测 def get_canny_image(image): return cv2.Canny(image=image, threshold1=CANNY_THRESHOLD1, threshold2=CANNY_THRESHOLD2) # 轮廓提取 def get_contours(image): contours, _ = cv2.findContours( image=image, mode=cv2.RETR_CCOMP, # 轮廓检索方式-检测所有的轮廓，只建立两个等级关系，顶层为连通域的外围边界，次层为洞的内层边界 method=cv2.CHAIN_APPROX_SIMPLE # 轮廓近似方式-仅保存轮廓的拐点信息 ) return contours image_raw = cv2.imread('bigimg.png') # 读取原始图片 image_gaussian_blur = get_gaussian_blur_image(image_raw) # 高斯滤波处理 image_canny = get_canny_image(image_gaussian_blur) # 边缘检测处理 contours = get_contours(image_canny) # 轮廓提取处理 计算轮廓和滑块的面积和周长并比较，若误差不超过允许的误差ALLOWABLE_ERROR则认定该轮廓为目标缺口。因为求了外接矩形，面积周长我就直接用长宽求了。 ALLOWABLE_ERROR = 0.1 # 允许误差范围为10% # 计算矩形大小 def get_area(height, width): area = height*width return area # 计算矩形周长 def get_length(height, width): length = (height+width)*2 return length image_slide = cv2.imread('smallimg.png') # 读取滑块图片 slide_height, slide_width, _ = image_slide.shape # 获取宽高信息 target_area = get_area(slide_height, slide_width) # 目标面积 target_length = get_length(slide_height, slide_width) # 目标周长 offset = None for contour in contours: # 遍历轮廓 x, y, w, h = cv2.boundingRect(contour) contour_area = get_area(h, w) # 轮廓面积 contour_length = get_length(h, w) # 轮廓周长 area_error = abs((contour_area-target_area)/target_area) length_error = abs((contour_length-target_length)/target_length) if area_error &lt;= ALLOWABLE_ERROR and length_error &lt;= ALLOWABLE_ERROR: cv2.rectangle(image_raw, (x, y), (x + w, y + h), (0, 0, 255), 2) offset = x return offset 兴致勃勃做完才发现成功率堪忧。在轮廓识别这一步要么就是缺口和背景色太接近识别不出来，要么就是缺口轮廓和背景图轮廓混在一起导致下一步求外接矩形时出错。前者没啥办法，后者可能可以通过调整findContours的mode和method参数解决，我也不确定。可能要换一种检测方法，或者干脆放弃OpenCV转深度学习，但感觉后者可能更容易出错。。。 放一个检测成功的示例： day11 1.7 准度不够次数来凑，加上了失败重试，不停尝试直到成功。至于判断是否成功的方法，不会写js触发器先用别的顶着，通过“拼接成功”的提示信息判断是否通过验证。 captcha_success = False while (captcha_success == False): offset = None while (offset == None): refresh_captcha(browser) # 刷新验证码 time.sleep(2) offset = get_offset(browser) # 获取滑动距离 time.sleep(2) slide_captcha(browser, offset) captcha_text = browser.find_element( By.CLASS_NAME, 'JDJRV-slide-bar-center').text if (captcha_text == '拼接成功'): captcha_success = True 发现一个问题，原图大小和渲染大小不一致，根据原图计算的移动距离需要等比换算。此外，滑动时总差一丝，怀疑是小数自动向下取整，所以加一个向上取整。 # 原图大小和渲染大小不一致，需要等比换算。 _, image_width, _ = image_raw.shape # 原图宽度 render_width = 242 # 渲染宽度 offset = math.ceil(offset*(render_width/image_width)) 鼠标轨迹模拟 如上图，明明缺口对齐了，却还是没有通过验证。而在尝试手动完成滑块验证码时成功通过了验证。也就是说并不是selenium的原因。这时，我想到了韦的书 (Python3反爬虫原理与绕过) 上提到的一点：鼠标轨迹检测（9.6 P330），于是尝试手动添加随机抖动来模拟人手移动轨迹。 import random # 滑动验证码 def slide_captcha(browser, offset): button_slide = browser.find_element( By.CLASS_NAME, 'JDJRV-slide-btn') action = webdriver.ActionChains(browser) action.click_and_hold(button_slide).perform() # 点击并按住 # action.move_by_offset(offset, 0) # 滑动距离 # 添加随机抖动 sum_x = 0 sum_y = 0 while (sum_x &lt; offset): rand_y = random.randint(-5, 5) # y轴随机抖动 while (sum_y+rand_y &gt;= 30): # 控制y轴移动不超过滑块范围 rand_y = random.randint(-5, 5) rand_x = random.randint(1, 5) # x轴随机移动 if (offset-sum_x &lt; 5): rand_x = offset-sum_x action.move_by_offset(rand_x, rand_y) sum_x = sum_x+rand_x sum_y = sum_y+rand_y # print(rand_x, rand_y, sum_x, sum_y) action.release().perform() # 松开 虽然成功率不是百分百，但也能骗过轨迹检测成功登录了。 返回Session和cookie cookies = browser.get_cookies() print(cookies) browser.close() session = requests.session() for cookie in cookies: session.cookies.set(cookie['name'], cookie['value']) return session, cookies 纠错：通过“拼接成功”的提示信息判断是否通过验证不可行，因为通过验证后很快就会自动跳转，读不到这个信息。暂时用try应付一下，因为跳转后读不到图片会报错，在except里break。感觉好草台班子啊这种做法。。。 小改动：加了一个判断缺口正方形的条件。 day12 1.9 因为淘宝京东这些电商平台要看商品详情都需要先登录，这段时间就一直在做模拟登录。做完了才发现详情页里没有历史价格，感觉这段时间白做了。其实也不算完全白做，京东的话不登录连搜索都用不了，淘宝只是看不了详情页，其他电商平台还没试过。 查了下怎么看历史价格，要么是第三方比价网站，要么是商用的查价api，没找到在京东官方页面看历史价格的方法。去爬第三方，先不说数据能不能用，反爬有是另一套手段了。登录是微信扫码，验证方法也不一样。而且爬多了感觉很容易封号，电商平台你多看看很正常，查价网站一次查一大堆就很奇怪了，账号绑定的话代理池也没用。而商用api，虽然查一次就几分几毛钱，但要做机器学习数据量几百条总得有吧，相当于一次就用掉七八块也耗不起。 迷茫了，不知道往哪个方向做，又怕做了后又发现没用全盘推倒。 day13 1.11 才发现selenium自带延时等待功能，这下不需要time.sleep()这种东西了。 对代码进行了修改优化。 day14 2.21 本来只想休息一下，结果一歇就是一个月，拖延症真可怕。 继续吧，直接爬第三方网站好了，从头做就从头做，破罐子破摔。 因为京东的搜索要登录，所以之前做的也还有点用。京东的搜索页是：https://search.jd.com/，格式为：https://search.jd.com/Search?keyword=【关键词1%20关键词2】，后面可能还有enc,wq和pvid等参数，实测删去不影响。 淘宝的搜索页为：https://s.taobao.com/。之前是的时候记得不用登录的，这次有需要了，还要再做淘宝的模拟登录。搜索格式为：https://s.taobao.com/search?q=【关键词1%20关键词2】，还有别的一堆奇奇怪怪的参数，实测删去不影响。 day14 2.28 救命，完全没状态。 这几天看了看《时间序列分析实战 基于机器学习和统计学》，还是云里雾里。找了一大堆书，但是没法有效消化内容，讲解方向也与做的方向不完全契合，难以直接套用。大概是我有些眼高手低了。 先做点别的找找手感吧，照着之前的做个淘宝的模拟登录。 淘宝登录页：https://login.taobao.com/ 淘宝的登录验证需要手机app确认或者验证码，这个就不是selenium能完成的工作了（，到现在也没想好到时候成品登录要不要用用户的账号，要的话就不用弄这么麻烦，不要的话各种验证也难搞，像这个二次验证就不是这边搞得好的。又试了试，只有无痕要二次登录，浏览器是滑块，但是自然语言理解，不是简单的对齐缺口。然后试试selenium，又是个没信息的滑块，但是手动滑都过不了验证。淘宝在这块做的太复杂了，有点想撂担子。 day15 3.20 摸鱼一时爽，一直摸鱼一直爽。要不是马上中期答辩我说不定还会继续摆下去。。。 回到正题，模拟登录因为层出不穷的反爬验证处理起来实在麻烦，为了先搭个架子出来倒是有个取巧的办法：直接让用户自己登录，我们等着拿cookie就行了。 import requests from selenium import webdriver import time def selenium(target_url): browser = webdriver.Chrome() browser.get(url=target_url) time.sleep(30) cookies = browser.get_cookies() # print(cookies, type(cookies)) # print(cookies[0], type(cookies[0])) browser.close() session = requests.session() for cookie in cookies: session.cookies.set(cookie['name'], cookie['value']) return session, cookies 顺路记一下，selenium得到的cookies的结构就是一个字典的列表，list[dict]，每一个列表项就是一个cookie。然而requests库的cookie格式只有name和value两项，所以需要转换一下： # 将 cookie 转换为 requests 库可用的格式 cookie_dict = {cookie['name']: cookie['value'] for cookie in cookies} 还顺便写了个cookie的文件格式存取以备不时之需，虽然程序内直接传参就行。 错误 invalid cookie domain 在测试selenium测试cookie是否可用时出现此错误，因为是先add_cookie再访问，就报了这个错。查了一下正确的做法是先访问需要登录的地址再设置cookie。 browser2 = webdriver.Chrome() browser2.get('https://www.jd.com') for cookie in cookies: browser2.add_cookie(cookie) browser2.get('https://search.jd.com/Search?keyword=北通%20手柄') time.sleep(10) browser2.close() day16 3.21 本来想selenium拿到cookie后用requests库进行请求的，但不知道为什么加了cookie还是未登录状态。正好之前selenium使用cookie正常，这些测试转正了。用selenium完成搜索，再把内容交由pyquery解析...好像也没必要，selenium自己又不是不能解析。算了先这样吧。 selenium登录&amp;搜索功能整合为类 整合了登录和搜索功能，这下直接把selenium整成一个类得了。上文提到了搜索的格式，直接把关键字放到url里用空格分割就行，带上cookies信息就能正常搜索了。 from selenium import webdriver import time class Selenium: login_url = '' index_url = '' search_url = '' cookies = list[dict] def __init__(self, login_url, index_url, search_url) -&gt; None: self.login_url = login_url self.index_url = index_url self.search_url = search_url self.cookies = list[dict] def selenium_login(self): login_url = self.login_url browser = webdriver.Chrome() browser.get(url=login_url) time.sleep(30) cookies = browser.get_cookies() browser.close() # return cookies self.cookies = cookies def selenium_search(self, keywords): index_url = self.index_url search_url = self.search_url for keyword in keywords: search_url = search_url+keyword+'%20' # 空格分割关键字 browser = webdriver.Chrome() browser.get(index_url) for cookie in self.cookies: browser.add_cookie(cookie) browser.get(search_url) time.sleep(5) with open(&quot;search_result.html&quot;, mode=&quot;w&quot;, encoding='utf-8', newline='') as f: f.write(browser.page_source) browser.close() if __name__ == '__main__': selenium_jd = Selenium(login_url='https://passport.jd.com/new/login.aspx', index_url='https://www.jd.com', search_url='https://search.jd.com/Search?keyword=') selenium_jd.selenium_login() selenium_jd.selenium_search(['北通', '手柄']) 解析还是先别放类里了，不同电商平台页面结构不同解析方法也各异。 再记一些TODO List： 登录定时更改，手动登录完成后主动结束等待，可能需要多进程/线程 异常处理 搜索时启用无界面模式 搜索结果页获取商品id（京东） 从结果页中解析出商品id待用。标识度很高的是J_goodsList这个类，检索这个类下的li元素就行，商品id是data-sku这个参数。 import requests from pyquery import PyQuery as pq from selenium_class import Selenium # index_url_jd = 'https://www.jd.com' # session, _ = selenium_login.selenium() # response = session.get(index_url_jd) # print(response.status_code) # print(response.url) # with open(&quot;index_jd.html&quot;, mode=&quot;w&quot;, encoding='utf-8', newline='') as f: # f.write(response.text) def get_goods_id_jd(keywords): login_url_jd = 'https://passport.jd.com/new/login.aspx' index_url_jd = 'https://www.jd.com' search_url_jd = 'https://search.jd.com/Search?keyword=' selenium_jd = Selenium(login_url_jd, index_url_jd, search_url_jd) selenium_jd.selenium_login() selenium_jd.selenium_search(keywords) # 解析网页数据 with open('search_result.html', 'r', encoding='utf-8') as f: html = f.read() doc = pq(html) goodslist = doc('#J_goodsList li') id_list = list() for goods in goodslist.items(): id_list.append(goods.attr('data-sku')) for id in id_list: print(id) day17 3.22 昨天上午和导师聊了聊，找到了不少改进方向，记一下。首先是登录部分，我现在是取巧，弹个框让用户自己登录。就算之前的自动化登录，也是需要一个账号密码来登录的。这就牵扯到一个数据安全的问题，用户怎么会愿意把自己的账号密码输入到一个非官方的软件里呢？我也想过内置一个账号，但在陌生环境登录一般都会要求手机号收验证码，而做这个功能既麻烦又需要服务器，会有额外开销。我初始的设想是做纯客户端不做服务器的，但聊了后服务器这个还是要有，验证码这个功能也得做。现在图方便最后答辩也过不了的，所以还是得做。第二就是后面的时间序列预测，我之前想当然的觉得，把不同时间的价格数据丢到模型里跑，得到一个未来的价格就行。但导师要求更严格，还要加入销量等影响因素，用于支持题目中的“决策”二字，这就有点触及我的知识盲区了，看来得先多看看书。目前看的那本，讲了半天还是没到重点，在犹豫要不要换一本。此外，时间序列销量这个数据也不好拿，电商平台上都只有当前的销量价格，价格上第三方网站上还能找到，销量这数据就是真没人关心了。 电商网站上都只有当前价格，历史价格这个数据藏起来的（不要影响鼠鼠赚钱）。找了下可以在第三方的网站上找到。也有一些商用api。api好用是好用，就是要钱，测试用用没关系，放毕设里正式用肯定被毙。查价网站只需要商品页链接就行，但有点担心大量爬触发反爬，又要增加工作量，先走一步看一步吧。 先列出一些可用的第三方查价网站： https://tool.manmanbuy.com/HistoryLowest.aspx这个是一个叫慢慢买的app的查价页，该app也是致力于比价省钱的，还要专门的比价api合作业务，比较专业。 https://www.lsjgcx.com/这个就是一个常见的查价网站，但传播较广，也做了自己的app，看了看挺草率的，没上一个专业。 http://www.hisprice.cn/从个犄角格拉翻出来的，过客网的过客比价。也做了个公众号只不过是跳转网页罢了。 day18 3.23 接上。 先用http://www.hisprice.cn/这个链接做下试试。虽然可以输链接再submit，但看了看直接加在url后面当参就行了，即：http://www.hisprice.cn/his.php?hisurl=【商品链接】。 寄。 本来以为数据现成的很好爬，f12看看发现是canvas现画的图，价格放在id=containertooltip的div里，随着鼠标位置实时更新，落在拐点上才显示价格。现在有两条路，一条图像识别折线图+selenium模拟鼠标落点再爬html里的数据，一条直接想办法从js代码里把数据拿出来。后者折腾半天还是毫无头绪，实在不懂前端，大概只能选前者了。 day19 3.28 又找了找，换了一家叫购物党（gwdang.com）的查价网站，这家就很实诚了。虽然还是画图+鼠标位置检测+动态变更内容，但那也只是方便用户，具体数据在侧边栏写的明明白白，就爬这家好了。 从查价网站获取历史价格（gwdang.com） 这家的搜索页是https://www.gwdang.com/v2/trend?from=search，可以往input里填数据再post，也可以直接通过链接访问，格式为https://www.gwdang.com/v2/trend/【商品id】-【平台代码】.html，例如京东的平台代码为3，上面有一件商品id为4979408，对应链接就是https://www.gwdang.com/v2/trend/4979408-3.html。 访问了一下试试，失败了，返回状态码403，尝试添加用户代理（user-agent）。关于这部分内容，详见韦的《Python3反爬虫原理与绕过实战》第4章 信息校验型反爬虫 4.1 User-Agent反爬虫。 User-Agent反爬虫 def get_history_price(goods_id, platform_code): target_url = 'https://www.gwdang.com/v2/trend/'+goods_id+'-'+platform_code+'.html' user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36' headers = {'User-Agent': user_agent} response = requests.get(target_url, headers=headers) print(response.status_code) 成功访问，但会直接通过链接访问会弹出验证消息，懒得做验证的话通过搜索页输入商品链接就不会弹验证了。还是回到了selenium上（。 搜索框是&lt;input id=&quot;url&quot;&gt;，按钮是&lt;button id=&quot;search-button&quot;&gt;用selenium填写后点击按钮。 browser = webdriver.Chrome() browser.get('https://www.gwdang.com/v2/trend?from=search') input = browser.find_element(By.CSS_SELECTOR, '#url') input.send_keys('https://item.jd.com/4979408.html') button = browser.find_element(By.CSS_SELECTOR, '#search-button') button.click() # 等待页面加载完成 WebDriverWait(browser, 10).until( EC.presence_of_element_located((By.CLASS_NAME, 'promotion-list'))) print(browser.page_source) 还是弹出了验证，猜测是检测到了使用自动化工具，尝试绕过webdriver检测。关于这部分内容，详见韦的《Python3反爬虫原理与绕过实战》第7章 特征识别反爬虫 7.1 webdriver识别。 webdriver识别 Object.defineProperty(navigator, &quot;webdriver&quot;, { get: () =&gt; false, }); browser = webdriver.Chrome() browser.get('https://www.gwdang.com/v2/trend?from=search') # 绕过webdriver验证 script = 'Object.defineProperty(navigator, &quot;webdriver&quot;, { get: () =&gt; false, });' browser.execute_script(script=script) input = browser.find_element(By.CSS_SELECTOR, '#url') input.send_keys('https://item.jd.com/4979408.html') button = browser.find_element(By.CSS_SELECTOR, '#search-button') button.click() # 等待页面加载完成 WebDriverWait(browser, 10).until( EC.presence_of_element_located((By.CLASS_NAME, 'promotion-list'))) print(browser.page_source) PyAutoGui 还是不行。尝试引入pyautogui，做了一部分突然想起来最后还是要做无界面的（headless）到时候pyautogui就没用了。所以可能还是要做验证。留一个残骸，这个也还有个问题，就是它的相对坐标是从页面起点算的，上边的各种栏位都没算进去，但也没必要改了。 import pyautogui browser = webdriver.Chrome() browser.get('https://www.gwdang.com/v2/trend?from=search') input = browser.find_element(By.CSS_SELECTOR, '#url') # input.send_keys('https://item.jd.com/4979408.html') button = browser.find_element(By.CSS_SELECTOR, '#search-button') # button.click() # 获取相对坐标 location_input = input.location location_button = button.location print(location_button) # 转换为绝对坐标 window_position = browser.get_window_position() print(window_position) abs_location_input = {'x': window_position['x']+location_input['x'], 'y': window_position['y']+location_input['y']} abs_location_button = {'x': window_position['x']+location_button['x'], 'y': window_position['y']+location_button['y']} print(abs_location_button) # pyautogui操作 pyautogui.moveTo(abs_location_input['x'], abs_location_input['y'], duration=0.5) pyautogui.click() pyautogui.typewrite('https://item.jd.com/4979408.html') pyautogui.moveTo(abs_location_button['x'], abs_location_button['y'], duration=0.5) pyautogui.click() 如果手动点的话是不会弹验证的，selenium点就会，键盘上enter一下也不行。大概是鼠标轨迹检测吧，之前的技术积累用上了。 # 设定动作链 action = webdriver.ActionChains(browser) x_offset = 40 action.move_to_element_with_offset(input, -x_offset, 0) sumx = 0 while (sumx &lt; x_offset): if (sumx &lt; x_offset): action.move_by_offset(2, 0) sumx += 2 action.perform() action.click() action.perform() 没点到。。。看不到鼠标也不知道哪里出问题，换个方法。 手动测试发现虽然直接tab enter不行，但tab绕一圈回来再enter就可以。这样就绕过了麻烦的爬虫检测了。 input.send_keys(goods_url) # 设定动作链 action = webdriver.ActionChains(browser) # 跳过第一次 action.send_keys(Keys.TAB).perform() time.sleep(0.2) action.send_keys(Keys.TAB).perform() time.sleep(0.2) # 循环一次 while (button != browser.switch_to.active_element): action.send_keys(Keys.TAB).perform() time.sleep(0.2) action.send_keys(Keys.ENTER).perform() 开始爬价格数据。直接定位&lt;ul class=&quot;promotion-list&quot;&gt;，查找子元素&lt;li class=&quot;promotion-item&quot;&gt;，每一项记为一天的数据，日期为&lt;div class=&quot;head&quot;&gt;&lt;span class=&quot;date&quot;&gt;，价格为&lt;p class=&quot;ymj&quot;&gt;&lt;span&gt;。 import requests from pyquery import PyQuery as pq from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC import selenium.common.exceptions as SE target_url = 'https://www.gwdang.com/v2/trend/4979408-3.html' search_url = 'https://www.gwdang.com/v2/trend?from=search' index_url = 'https://www.gwdang.com/' # user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36' # headers = {'User-Agent': user_agent} # response = requests.get(search_url, headers=headers) # print(response.status_code) browser = webdriver.Chrome() browser.get('https://www.gwdang.com/v2/trend?from=search') # 绕过webdriver验证 script = 'Object.defineProperty(navigator, &quot;webdriver&quot;, { get: () =&gt; false, });' browser.execute_script(script=script) # 等待页面加载完成 WebDriverWait(browser, 10).until( EC.presence_of_element_located((By.ID, 'url'))) input = browser.find_element(By.CSS_SELECTOR, '#url') input.send_keys('https://item.jd.com/4979408.html') button = browser.find_element(By.CSS_SELECTOR, '#search-button') # button.click() # 等待页面加载完成 WebDriverWait(browser, 15).until( EC.presence_of_element_located((By.CLASS_NAME, 'promotion-item'))) # with open(&quot;price_result.html&quot;, mode=&quot;w&quot;, encoding='utf-8', newline='') as f: # f.write(browser.page_source) # with open('price_result.html', 'r', encoding='utf-8') as f: # html = f.read() # doc = pq(html) doc = pq(browser.page_source) datalist = doc('.promotion-list .promotion-item') datalist = datalist.items() id_list = list(dict()) d = dict() for data in datalist: d['date'] = data.find('.date').text() # 日期 d['price'] = data.find('.ymj span').text()[1:] # 价格 id_list.append(d) print(d['date']+'\\t'+d['price']) day20 4.12 好想把日期删掉（捂脸），摸鱼也得有个限度吧。 做下数据库，本来想做无服务端，就选了SQLite这个内置的轻量数据库。但好像又得做服务端了，懒得改先就这样吧。 稍微康了康，发现自己sql忘的差不多了，边做边复习吧。 老样子先建个类，各种方法都封装进去，主程序只需要传参就行。 day21 4.24 deadline来临，大踏步进入时序预测模型。从头学应该来不及，先读点代码吧。 装装环境库，pandas，sklearn，tensorflow都整上。需要注意的是，sklearn的包名现在是scikit-learn，pip sklearn会报错。因为这几个包都挺大的，建议使用镜像站：-i https://pypi.tuna.tsinghua.edu.cn/simple。 了解到informer做长序列比较好，可以考虑加入进来。还有就是之前一直考虑的价格单标签，应该至少加上销量做成多标签。 day21 5.3 感觉数据太将就了，用pandas搞下数据清洗吧。 pandas数据清洗 首先原始数据的日期没有年份，手动给它加上去： from datetime import datetime year = datetime.now().year # 获取当前年份 pre = 13 for i in range(df.shape[0]): mouth, _ = df.loc[i, 'Date'].split('-') if (int(mouth) &gt; pre): year -= 1 pre = int(mouth) df.loc[i, 'Date'] = pd.to_datetime( df.loc[i, 'Date']+'-'+str(year), format='%m-%d-%Y') df['Date'] = pd.to_datetime(df['Date']) df['Date'] = df['Date'].dt.date 这样就从03-27变成了2024-03-27，避免排序时搞乱了。 再是去重，很简单一句话： df.drop_duplicates(inplace=True) 然后就是填补缺失值，这一步有点难理解，最好看看文档里的例子来理解各函数的作用。首先创建一个连续的日期索引date_range,然后set_index('Date')把日期当索引，reindex(date_range)重设索引，这样没有的日期也有一行了，数据是NA，.fillna(method='ffill')前向填充数据，空的日期就用前一天的价格填上了，最后.reset_index()把索引改回去。这里Date列名变成index了，用rename改回去。 # 用前一天的数据填补空缺日期 df.sort_values('Date', inplace=True) # 排序 df.reset_index(drop=True, inplace=True) # 重置索引 # 创建一个连续日期的索引 date_range = pd.date_range(start=df['Date'].min(), end=df['Date'].max()) # 用date列当索引 | 用date_range重设索引 | 前向填充空数据 | 重设索引 df = df.set_index('Date').reindex( date_range).fillna(method='ffill').reset_index() df = df.rename(columns={'index': 'Date'}) # 将新增的列名'index'改回'Date' print(df.head) 最后存下来，训练模型时再读取。 path = './data/processed_data/' df.to_csv(path+filename, index=False) day22 5.4 验证码转发什么的，还是搞下试试吧。 SmsForwarder转发验证码 在手机上用SmsForwarder的webhook转发验证码信息，就不造轮子了。 给出一个简单的配置示例： 【此处应有图】 服务器用flask简单搭一下。因为是测试，直接用的内网ip，双方连同一个局域网。也可以用 ngork这样的工具内网穿透，这里就不用了。 from flask import Flask, request, jsonify app = Flask(__name__) # 测试用，实际使用需要更改主机与端口号 host = '172.17.148.62' port = '8000' @app.route('/') def index(): return 'Hello, World!' if __name__ == '__main__': app.run(port=port, host=host, debug=True) 加一个接收验证码的路由，从里面解析出接收验证码的手机号和验证码，存到账号池数据库中。爬虫从数据库里拿收到的验证码，感觉有点多此一举，如果用RabbitMQ、Kafka等消息队列直接通信或许更方便，可惜我不会，而且账号池数据库也算有需要吧。 # 获取SmsForwarder转发的验证码 @app.route('/receive_sms', methods=['POST']) def receive_sms(): # 获取并解析请求中的数据 data = request.get_json() print(data) message = data.get('msg') if message: # 处理短信内容,通过正则匹配6位数字验证码 pattern = r&quot;【京东】(\\d{6})&quot; match = re.search(pattern, message) verification_code = match.group(1) # 正则匹配接收信息的号码 pattern = r&quot;\\+86(\\d{11})&quot; match = re.search(pattern, message) mobile_number = match.group(1) print(mobile_number, verification_code) db = sql_class.SQLiteTool('accounts.db') update_sql = &quot;UPDATE accounts SET verification_code = ? WHERE mobile_number = ?&quot; db.update_data( update_sql, (verification_code, mobile_number)) return jsonify({&quot;status&quot;: &quot;success&quot;, &quot;message&quot;: &quot;SMS received&quot;}), 200 else: return jsonify({&quot;status&quot;: &quot;error&quot;, &quot;message&quot;: &quot;No message found in the request&quot;}), 400 SQLite数据库方法封装 数据库使用SQLite，写个轮子先，封装好各个交互方法： import sqlite3 class SQLiteTool: def __init__(self, db_name): &quot;&quot;&quot; 初始化数据库连接 :param db_name: 数据库文件名 &quot;&quot;&quot; self.conn = sqlite3.connect(db_name) self.cursor = self.conn.cursor() def create_table(self, table_sql): &quot;&quot;&quot; 创建表 :param table_sql: 创建表的SQL语句 :return: None &quot;&quot;&quot; try: self.cursor.execute(table_sql) self.conn.commit() print(&quot;Table created successfully.&quot;) except Exception as e: print(f&quot;Error creating table: {e}&quot;) def insert_data(self, insert_sql, data_tuple): &quot;&quot;&quot; 插入数据 :param insert_sql: 插入数据的SQL语句模板 :param data_tuple: 插入数据的元组 :return: None &quot;&quot;&quot; try: self.cursor.execute(insert_sql, data_tuple) self.conn.commit() print(&quot;Data inserted successfully.&quot;) except Exception as e: print(f&quot;Error inserting data: {e}&quot;) def query_data(self, query_sql): &quot;&quot;&quot; 查询数据 :param query_sql: 查询数据的SQL语句 :return: 查询结果 &quot;&quot;&quot; try: self.cursor.execute(query_sql) rows = self.cursor.fetchall() return rows except Exception as e: print(f&quot;Error querying data: {e}&quot;) return None def update_data(self, update_sql, data_tuple): &quot;&quot;&quot; 更新数据 :param update_sql: 更新数据的SQL语句模板 :param data_tuple: 更新数据的元组 :return: None &quot;&quot;&quot; try: self.cursor.execute(update_sql, data_tuple) self.conn.commit() print(&quot;Data updated successfully.&quot;) except Exception as e: print(f&quot;Error updating data: {e}&quot;) def delete_data(self, delete_sql, data_tuple=None): &quot;&quot;&quot; 删除数据 :param delete_sql: 删除数据的SQL语句模板 :param data_tuple: 可选的元组，用于填充SQL中的占位符 :return: None &quot;&quot;&quot; try: if data_tuple: self.cursor.execute(delete_sql, data_tuple) else: self.cursor.execute(delete_sql) self.conn.commit() print(&quot;Data deleted successfully.&quot;) except Exception as e: print(f&quot;Error deleting data: {e}&quot;) def close_connection(self): &quot;&quot;&quot; 关闭数据库连接 :return: None &quot;&quot;&quot; if self.conn: self.conn.close() print(&quot;Connection closed.&quot;) 账号池数据库 建一个账号池数据库，包含手机号（mobile_number，主键），验证码（verification_code）和占用状态（occupied）三列。爬虫和接收转发的验证码的服务器就通过数据库交互。爬虫首先从账号池中筛出空闲的账号，用这个账号请求验证码并标记占用，服务器接收到转发的验证码后存入验证码。爬虫检测到验证码变化后取出验证码并解除占用。 # 账号池数据库初始化 def accounts_db_init(): # 账号池 account_list = [ '', '' ] # 创建数据库 db = SQLiteTool(&quot;accounts.db&quot;) create_table_sql = ''' CREATE TABLE IF NOT EXISTS accounts ( mobile_number TEXT PRIMARY KEY, verification_code TEXT NOT NULL, occupied BOOLEAN NOT NULL ); ''' db.cursor.execute(&quot;DROP TABLE IF EXISTS accounts&quot;) db.create_table(create_table_sql) # 存入账号 insert_sql = &quot;INSERT INTO accounts VALUES (?, ?, ?)&quot; for account in account_list: db.insert_data(insert_sql, (account, '000000', False)) # 关闭连接 db.close_connection() 然后就是爬虫中，和短信验证码相关的部分。用这部分替换掉原来的账号密码登录。 # SQL：从账号池中找出一个可用账号 db = SQLiteTool('accounts.db') query_sql = &quot;SELECT * FROM accounts WHERE occupied = False&quot; accounts = db.query_data(query_sql) if (len(accounts)): print('忙碌中，请稍候再试') return False update_sql = &quot;UPDATE accounts SET occupied = ? WHERE mobile_number = ?&quot; db.update_data(update_sql, (True, accounts[0][0])) # 标记该账号使用中 div_sms_login = browser.find_element(By.ID, 'sms-login') div_sms_login.click() # 切换到短信验证码登录 input_mobile_number = browser.find_element(By.ID, 'mobile-number') input_mobile_number.send_keys(accounts[0][0]) button_send_code = browser.find_element(By.ID, 'send-sms-code-btn') button_send_code.click() # 发送验证码 # 每0.5秒检查一次是否收到验证码，等待5秒 cnt = 10 verification_code = '' while (cnt): time.sleep(0.5) cnt -= 1 query_sql = &quot;SELECT * FROM accounts WHERE mobile_number = accounts[0][0]&quot; verification_code = db.query_data(query_sql)[1] if (verification_code != accounts[0][1]): break update_sql = &quot;UPDATE accounts SET occupied = ? WHERE mobile_number = ?&quot; db.update_data(update_sql, (False, accounts[0][0])) # 标记该账号空闲 db.close_connection() if (verification_code == accounts[0][1]): print('请求验证码超时') return False input_sms_code = browser.find_element(By.ID, 'sms-code') input_sms_code.send_keys(verification_code) # 输入验证码 button_login = browser.find_element(By.ID, &quot;sms-login-submit&quot;) button_login.click() # 等待登录 day23 5.5 建议：selenium版本回退 发现一个bug，selenium启动chromedriver时，总是会先访问一个网址，等到超时报错再正常启动浏览器。而这个网址是github.io域名没挂梯一般都访问不了，所以每次启动都要等半天等它超时了才能正常启动浏览器，而且这个访问对正常使用完全没影响，大概是检查更新之类的吧。想禁用这个访问有不知道怎么做，查了查回退版本到4.5.0就不会有这个问题了。 完整报错信息如下： Exception managing chrome: error sending request for url (https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json) day24 5.9 没空写日志，忙的头掉。写文档好麻烦，都没空敲代码。 day24 5.11 简单记一下这段时间完成的工作吧，没空详细写了。其实也没做啥，写文档去了。现在的主要任务也是改文档。其实我代码都没写完。。。 果然还是写代码好玩，抽个空写写，明天又要交文档。 前端改了改，用jinja2的模板继承功能简化了一下。 为了实现登录引入flask-login,方便操作数据库又引入Flask-SQLAlchemy，层层加码，变得越来越臃肿了。 Flask-SQLAlchemy不知道为什么就是不能正确连接到数据库，弃用了。正常写sql命令就行。 flask-login实现账号管理 写一下用户数据库初始化，在初始化时就插入一个管理员账号: def users_db_init(): # 创建数据库 db = SQLiteTool(&quot;users.db&quot;) create_table_sql = ''' CREATE TABLE IF NOT EXISTS users ( uid INTEGER PRIMARY KEY, username TEXT NOT NULL UNIQUE, password TEXT NOT NULL, email NOT NULL UNIQUE ); ''' db.create_table(create_table_sql) insert_sql = &quot;INSERT INTO users VALUES (?, ?, ?,?)&quot; db.insert_data(insert_sql, (0, 'admin', 'admin', 'admin')) # 关闭连接 db.close_connection() 配置一下flask-login，用这个库去管理登录状态。 login_manager = LoginManager() login_manager.init_app(app) login_manager.login_view = 'login' login_manager.login_message = '请先登录以访问此页面。' login_manager.login_message_category = 'Access denied.' app.config['SECRET_KEY'] = os.urandom(16).hex() 定义用户类： # 用户模型 class User(UserMixin): db_path='users.db' def __init__(self, uid, username, password, email): self.uid = uid self.username = username self.password = password self.email = email @classmethod def get_by_id(cls, uid): db = sql_class.SQLiteTool(cls.db_path) query_sql = &quot;SELECT * FROM users WHERE uid = &quot; + str(uid) user_data = db.query_data(query_sql) db.close_connection() if user_data: return cls(*user_data[0]) return None @classmethod def get_by_username(cls, username): db = sql_class.SQLiteTool(cls.db_path) query_sql = &quot;SELECT * FROM users WHERE username = &quot; + \\ f'\\'{str(username)}\\'' user_data = db.query_data(query_sql) db.close_connection() if user_data: return cls(*user_data[0]) return None @classmethod def get_by_email(cls, email): db = sql_class.SQLiteTool(cls.db_path) query_sql = &quot;SELECT * FROM users WHERE email = &quot; + \\ f'\\'{str(email)}\\'' user_data = db.query_data(query_sql) db.close_connection() if user_data: return cls(*user_data[0]) return None @classmethod def create_user(cls, username, password, email): db = sql_class.SQLiteTool(cls.db_path) query_sql = &quot;SELECT MAX(uid) FROM users&quot; max_uid = db.query_data(query_sql)[0][0] uid = max_uid+1 insert_sql = &quot;INSERT INTO users VALUES (?, ?, ?, ?)&quot; db.insert_data(insert_sql, (uid, username, password, email)) db.close_connection() return cls(uid, username, password, email) def get_id(self): return str(self.uid) # 用户加载回调 @login_manager.user_loader def load_user(uid): return User.get_by_id(uid) 登录功能实现： # 登录 @app.route('/login', methods=['POST']) def login(): username = request.form['username'] password = request.form['password'] user = User.get_by_username(username=username) if user and user.password == password: login_user(user) return redirect(url_for('index')) # 登录成功后重定向 else: session['error_msg'] = '用户名或密码错误' return redirect(url_for('error')) 注册功能实现： # 注册 @app.route('/register', methods=['POST']) def register(): username = request.form['username'] email = request.form['email'] password = request.form['password'] confirm_password = request.form['confirm_password'] if password != confirm_password: session['error_msg'] = '两次密码不匹配' return redirect(url_for('error')) user1 = User.get_by_username(username=username) user2 = User.get_by_email(email=email) if user1 or user2: session['error_msg'] = '用户名或邮箱已被使用' return redirect(url_for('error')) # 创建新用户 new_user = User.create_user(username, password, email) # 注册完成直接登录 login_user(new_user) return redirect(url_for('index')) day26 5.14 今天代码截止，但还没写完，寄。主要把之前的后端和最近做的前端匹配起来。 selenium页面滚动 京东搜索页有些商品信息需要滚动到下面才会正常加载，所以加个页面滚动。 # 模仿用户缓慢滚动到页面底部 last_height = 0 while True: # 滚动200px browser.execute_script(&quot;window.scrollBy(0,300);&quot;) # 等待页面加载新内容 time.sleep(0.5) # 计算新的文档高度，如果不再变化，则跳出循环 height = browser.execute_script( &quot;return document.documentElement.scrollTop || window.pageYOffset || document.body.scrollTop;&quot;) if height == last_height: break last_height = height print(height) time.sleep(1) selenium设置无头模式 from selenium.webdriver.chrome.options import Options opt.add_argument(&quot;--headless&quot;) # 无头 self.driver = webdriver.Chrome(options=opt) #使用无头模式打开 self.driver.get(url) 今天测试时突然发现我爬数据的购物党要登录了，离交代码只剩几小时，紧急改，最后做了一个很糙的补丁交上去了，也不知道后面还能不能改。。。还有好多功能没实现。。。 day27 5.16 在保存预测结果到SQLite数据库是发现predict_price被存为了BLOB二进制格式而不是REAL浮点数格式，而actual_price一切正常。在一番排查后终于确定是因为predict_price的格式为numpy.float32而actual_price的格式为numpy.float64，SQLite只能正确处理64位的浮点数，所以要把32位的predict_price转为64位。 predict_price = predict_price.astype(np.float64) day28 5.20 应该算是结束了。随后改了点啥，没空记也记不清了，总之就是些边边角角的修改。总结一下，只有前期慢悠悠的做爬虫的部分算是真正学了东西，后面的LSTM，Flask以及前端等都是赶鸭子上架，能跑就行。做出来的东西，因为缺少规划，也是东一榔头西一棒槌，没有一个清晰明了的结构。最开始本来是想做好封装和模块化的，写着写着就驾驭不住了。还是缺少项目开发和管理的经验，下次加油吧。 （完） ","link":"https://jinvic.github.io/post/[Graduation-Design]-Design-and-Implementation-of-an-Analysis-and-Decision-System-for-Online-Purchasing-of-Goods/"},{"title":"记中山青软实训经历","content":"记中山青软实训经历 day0 2023.7.3 *7.6补 今天才到中山，平时都没怎么出门，更别说这次出省。拉了个同学一起走才没走丢Orz。 说是实习，却并没有去企业，来了个技校住校上课，快进到进厂打螺丝。 虽然是八人寝，空间也还算大。只有块床板被褥得自己买。周边只有两家小超市，食堂也不太行。 总体生活水平也不算特别差吧，但绝对算不上好。 之前宣讲时说是java技术栈，spring框架，有点难受。C++、java、Python三大头中，唯独Java我是最忽视的。ACM经验+课设做的算法，偏基础，纯计算的的东西我一般都用C++。而最近想做点快速开发就在学在用Python，可以说这两这都算是有点基础的。唯独java，不仅上课一直轱辘话我直接睡过去了，之后的几个课设，awt啊，jsp啊基本都是github见，没有深入研究的使用的经验。 day1 2023.7.4 *7.6补 上来开个会，欢迎这个感谢那个，老生常谈。 终于开始上课，本来布置了一个小作业摸底，结果谁也不会。老师就问你们会什么，问什么都是不会，把老师给问无语了。本科生是这样的，实践能力还真不如技校。我也疑惑大学这几年都学了些啥，这个话题有空聊。 最后老师没办法，就带着我们做一个简单的小项目，springboot+mybitasplus+mysql。纯后端，通过postman进行http请求传参。感觉就一直在@来@去，什么面向注释编程。 day2 2023.7.5 *7.6补 今天的任务是写一天文档，文档这种东西就和PPT一样完成任务必备，这个技能大家都点的挺高的，更何况现在有了GPT，水文档更是没压力。不过枯燥也是真的枯燥，还是写了一天，大部分时间都是写吐了歇着回血。这样干巴巴的写真的对项目能力有提升吗？即没人监督又没人指导，大家都是完成任务。而且很多东西感觉就不是这个阶段写的只能编，像详细设计的模块构成和数据库设计等，只能开编。 稍微抽空复习了一下昨天写的。做了两个小功能。 day3 2023.7.6 之前只是说做过云盘，没具体讲。加上第一天讲的springboot+mybitasplus，我也就学了做了。结果今天说换框架，用SSM，这下真白学了。不用你讲什么啊（掀桌） 又是带着做个注册功能当示例。但早就想说了，QQ的群课堂真不好用，画面等比缩一圈代码更难看清了。那老师也只顾着自己讲，稍微掉一点就再也跟不上了。尤其是代码还没敲完他就切屏讲下一个真的恼火。 讲了一大堆，但说实话配置啊前端啊我都完全没搞懂，就后端的Java稍微懂了些。虽然最后还是做出来了，但感觉还是没消化，知其然不知其所以然。毕竟这讲课的方式我也觉得有点问题，是那种快速做成果的方式而不是学知识的方式。就我而言，要掌握某一门技术我一般都是先从整体入手，大概了解整体框架后再去钻研具体细节。这样初期进度很慢，但入门后学起来就很快。但他讲课的方式就是需要什么讲什么，提一下这个有什么用那个有什么用，最后得到的都是零散的知识点，而且专项特化你也很难做迁移，用这些知识做过别的什么。就完成任务，做完过段时间就忘了。怎么说呢，就感觉这种方式虽然快但也太功利了，不是很适合长线学习。如果你之后肯花时间去补完这个框架整合到自己的知识体系那还好，但大部分人只会解脱一般立刻将其丢进垃圾堆吧。培训机构嘛，短期出成绩数据好看就行，结课后你爱咋咋地关我啥事。 另外，idea做这种项目开发真好用啊，之前JetBrains家的产品，Pycharm、WebStorm啥的都只是浅尝辄止，平时还是喜欢用VSCode一个编辑器打天下。不过做这种高度结构化的项目果然还是专门的IDE比较好用。其实Eclipse也还行，但在我这样的新生代看来总透着一股旧时代的臃肿与笨拙感。就是JetBrains全家桶订阅太贵了啊，也就学生身份现在还能嫖一下，这些不得不考研了（雾）。 其实一整天除了上课讲的什么都没做，一方面是怕他明天还讲现在做白做，另一方面就是一直再帮同学弄华为云和Git，毕竟之前有点Github的经验上手还是比较快的，这时就显出平时多学多了解的用处了。虽然了解不深但到真要用时学起来还是比0基础快很多的。所以。。。该学学编译器，Cmake和Linux了。以前该多学学的，现在想学才觉出没时间了。 前几天也是，帮着配mysql，以及项目debug。没办法，能力越大责任越大（你就吹吧），帮点忙收获下感谢还是挺有成就感的，就是自己的项目进度停滞不前有时还是感觉有点急（你先别急）。 day4 2023.7.7 感觉没什么自己写的必要了，教程里都贴着代码，读懂就行，还有老师带着讲。转换下思路，不是来锻炼你独立开发项目的能力，而是锻炼你阅读项目代码学习架构的能力，这时就感觉诶一下子轻松了。 day5 2023.7.8 今天队友基本都上手了，可以独立开发。终于git的push和merge记录不是我孤零零一个人了。可以说我教的比老师还多，建议给我发工资（ 他们做的还蛮快的，一天下来基本都做完了，就我还剩个小BUG改下sql就行。下课了今天又没晚自习 ，不改了回寝室玩。 day6 2023.7.9 星期天休息，润去市里玩。 day 7 2023.7.10 又是被DEBUG折磨的一天。很多功能他们做完了看着没问题就算了。现在全做完后一用就全是洞，还是要我来debug。很多错误看到最后都是很简单的错误，但问题就是这个看到最后，我得把他们负责的部分都看一遍才知道这个部分是做什么的怎么做的，然后才能找到错误。但问题是我都看一遍了，与其在现有的代码上找bug不如我自己写... 试了试在内网上其他设备访问，已有账号倒没问题，注册时会提示不安全不让注册，应该是http协议的问题。折腾一会搞出自签搞出https，虽然还是提示证书不安全但能注册了，赢。 day8 2023.7.11 做了回收站单文件删除功能，这个功能示例里只有前端没有后端，不知道怎么回事。主要是有前端，不然我又不会写前端，后端反正其他几个功能的代码拼接一下就行。 折腾tomcat，部署到本地还好说，maven package一下导出war包放倒webapp目录下就行。云服务器再看看吧，搞不了算了。然后startup.bat的控制台乱码，chcp 95001也没用，最后还是改系统编码为utf-8才解决。 day9 2023.7.12 累。 修了前端不能播放视频的bug。他用的flash停用了，看了一下好像是把视频变成swf再用ckplayer播放。那个函数接口我也看不懂找不到文档，干脆全部推翻，用它最新的cklayer写了下，其实就用了示例，前端算是搞好了。测试的时候，浏览器不准访问本地文件放不了视频。就在tomcat的webapp下建一个FileServer文件夹当文件服务器，然后每次预览视频就拷贝到这里再让前段访问，终于行了。然后为了这个要专门前端写个post后端写个@RequestMapping，再在写几个FileService写几个方法来实现功能。其实并不复杂，就是不了解不熟练。搞个文件服务器也就是建个文件夹很简单吧，没学过你上哪知道，我查半天试了一堆方法想解除浏览器限制都没用。 要做的差不多都做完了，然后就写写文档。晚上的时候是真没事干了，整个晚自习都在打游戏。 day10 2023.7.13 闲。 象征性的写点实习日志和总结，还是GPT写的。白天老师就坐在上面也不好打游戏。 看点书吧。 我是傻逼。 视频预览那个功能根本不用写这么复杂。这功能不是我做的所以我直接在前端上开始改了，前端直接访问文件才出的问题。但他后端其实有个方法返回视频流，把这个填到路径里就行了。 我是傻逼。 反转了，视频流播放视频调不了进度条。改回去了。 ","link":"https://jinvic.github.io/post/Notes-on-Zhongshan-QST-Training-Experience/"},{"title":"Gridea主题concise如何添加和修改live2d模型","content":"前言 软件自带的主题感觉不是很好用，早就想换，但这个开源项目好像已经不再维护，主题页面https://gridea.dev/themes已经失效了，就暂且搁置了下来。 之后想起这回事又找了找，虽然官网的主题页面用不了了，但github上还是能找到不少为gridea做的主题的，挑挑拣拣一番，我相中了这个concise主题，项目地址。 之后尝试改live2d，原项目的教程就几句话： 参考了：gridea-theme-fog 模型下载地址: 下载地址 模型样式预览: 预览地址 主题-自定义配置中目前可选2中模型：黑猫和白猫 修改：可直接覆盖live2d/assets直接修改， 添加：按照目前结构继续添加（要修改下载下来的目录文件结构，及对应的model.json里相关path） 感觉讲的比较简略，想弄好还是要摸索一番的，我就详细写一下记在这里避免忘记，如果以后自己要再改live2d模型就来看看。 模型的预览和下载 这个原readme里面写了地址： 模型下载地址: 下载地址 模型样式预览: 预览地址 我们先到预览里挑一个喜欢的模型，这里以miku为例： 然后下载模型并解压，找到对应文件夹，进入asserts子文件夹，这就是我们的模型了： 将模型添加到gridea 首先我们要找到gridea的源文件路径，这个可以在客户端左下角找到： 进到themes/concise/assets/media/live2d/assets目录下，我们需要将模型移到这个目录。不过不能简单拖过来，它们的目录结构有点不一样。 两个json文件和moc子文件夹下的文件可以直接移动： 在gridea这边的mtn目录下新建文件夹，以模型名字命名，再将下载的mtn文件夹内文件移到新建的文件夹内： 至此，我们就成功将模型添加到gridea了。 配置文件修改 由于添加模型时更改了目录结构，我们首先修改模型的配置文件。打开assets下的miku.model.json。这里可能是压缩成一行的代码，可以使用VScode的格式化方便查看，将motion项中的mtn/路径都修改为mtn/miku/就行。 之后我们要修改concise主题的配置文件，将新模型添加到选项中。在themes/concise目录下找到config.json，搜索“看板娘”，在这个项下按格式添加就行： 重启gridea客户端，查看是否添加成功： 进入网页查看，头脚被截断了一部分： 在目录themes/concise/templates/includes下找到live2d.ejs，修改画布大小： &lt;canvas id=&quot;live2d&quot; width=&quot;240&quot; height=&quot;250&quot; class=&quot;live2d&quot;&gt;&lt;/canvas&gt; 修改为width=&quot;200&quot; height=&quot;300&quot;，现在能正常显示了： （完🙃） ","link":"https://jinvic.github.io/post/Gridea-theme-concise-how-to-add-and-change-live2d-model/"},{"title":"【学习笔记】C++ Primer Plus（第6版）【基础篇】","content":"【学习笔记】C++ Primer Plus（第6版）【基础篇】 目录 【学习笔记】C++ Primer Plus（第6版）【基础篇】 目录 前言 第1章 预备知识 第2章 开始学习C++ 2.1 进入C++ 头文件命名 命名空间 2.2 C++语句 2.3 其他C++语句 2.4 函数 函数原型 第3章 处理数据 3.1 简单变量 变量命名规则 运算符sizeof 头文件climits C++进制表示法 wchar_t,wcin和wcout char16_t和char32_t 3.2 const限定符 3.3 浮点数 cfloat或float.h头文件 浮点常量后缀 3.4 C++算术运算符 运算符优先级 类型转换 第4章 复合类型 4.1 数组 数组初始化 4.2 字符串 读取一行字符串 空行和溢出问题 4.3 string类简介 字符串的复制与拼接 string类读入一行 原始字符串 4.4 结构简介 匿名结构体 结构中的位字段 4.5 共用体 共用体的大小 匿名共用体 4.6 枚举 定义与赋值 取值范围 4.7 指针和自由存储空间 内存的分配和释放 静态联编和动态联编 4.8 指针、数组和指针算 数组的地址和指针类型 字符串指针 自动存储、静态存储和动态存储 4.9 类型组合 复杂数据类型的识别 4.10 数组的替代品 模板类vector和array 第5章 循环和关系表达式 5.1 for循环 ios:: boolalpha 前缀格式和后缀格式 5.2 while循环 5.3 do while循环 ctime头文件 5.4 基于范围的for循环 5.5 循环和文本输入 文件尾EOF 5.6 嵌套循环和二维数组 指针数组初始化为字符串常量 第6章 分支语句和逻辑运算 6.1 if语句 6.2 逻辑表达式 6.3 字符函数库cctype 6.4 ？：运算符 6.5 switch语句 6.6 break和continue语句 6.7 读取数组的循环 6.8 简单文件输入输出 简单文件读写 文本文件结尾 文件打开失败时确定原因 第7章 函数——C++的编程模块 7.1 复习函数的基本知识 7.2 函数参数和按值传递 形参和实参 7.3 函数和数组 数组作函数参数 指针和const 指向常量的指针和常量指针 7.4 函数和二维数组 二维（多维）数组的指针 7.5 函数和C-风格字符串 7.6 函数和结构 7.7 函数和string对象 7.8 函数和array对象 7.9 递归 7.10 函数指针 前言 这本书可以说是久仰大名了，但一直没有深入学习。一方面是没有时间，另一方面则是从学生时代的课堂学习转到看书自学中间还是需要个过渡的。这段时间刚度过考试周能喘口气，又为实习就业等未来感到焦虑，就看看书提升下自我吧。 本来我学习是没有做笔记的习惯的，会就是会不会就是不会。但大学读了几年，愈发感到力不从心。要学的知识太多太杂，很多东西你学完当时掌握得很好，转过头回来就忘了个七七八八。这种感觉很痛苦，就像是游戏回坑结果新手村都出不去。最后还是妥协了，做点笔记吧，忘了什么查查笔记总比翻一本几百页的大部头方便。 第一次边学边作笔记，我也不知道怎么弄比较好，摸索着来吧。这次我打算按目录分章分类，记下相对陌生的知识点方便日后查阅，更多是一种自用的功能性的索引的感觉。 第1章 预备知识 这一章更多是一个科普的内容，感觉有空看看也还行。学干货这章就先跳过吧。 第2章 开始学习C++ 2.1 进入C++ 这部分就是hello world，大部分内容都会。 头文件命名 头文件命名约定可以看看，了解一下c和c++头文件的区别。 命名空间 命名空间主要是用来区分不同的版本。例如A和B都写了一个函数func()，就可以用A::func()，B::func()来区别。 using namespace std;是一种偷懒的做法，现在我已经改掉了这个习惯，直接使用std::cin等。另一种可行的方法是using std::cin，这样也可以直接使用cin，相对using整个命名空间要安全些。此外，还可以将using语句放在特定的函数或结构体定义内来限制范围。 2.2 C++语句 2.3 其他C++语句 这一部分没什么重要的内容。主要是面向初学者的专业名词解释。 2.4 函数 函数原型 注意：C++程序应当为程序中使用的每个函数提供原型。 我之前一直将原型称为声明，因为原型的作用就和声明一样，告诉编译器有这么个东西。不过我一般不写原型，而是直接在用到函数之前把函数的定义写好在前面。这或许并不是一个好的编码习惯，需要改正。 再复习下原型和定义的区别： 第3章 处理数据 3.1 简单变量 变量命名规则 运算符sizeof 可对类型名或变量名使用sizeof运算符。对类型名(如 int)使用sizeof运算符时，应将名称放在括号中;但对变量名(如n_short)使用该运算符，括号是可选的: cout &lt;&lt; &quot;int is &quot; &lt;&lt; sizeof (int) &lt;&lt; &quot; bytes .\\n&quot; ; cout &lt;&lt; &quot;short is &quot; &lt;&lt; sizeof n_short &lt;&lt; &quot; bytes.\\n&quot; ; 头文件climits 头文件climits定义了符号常量来表示类型的限制。 C++进制表示法 C++使用前一（两）位来标识数字常量的基数。 如果第一位为1~9，则基数为10（十进制);因此93是以10为基数的。 如果第一位是0，第二位为1~7，则基数为8(八进制);因此042的基数是8，它相当于十进制数34。 如果前两位为0x或0X，则基数为16(十六进制); 头文件iostream提供了控制符dec、hex和 oct,分别用于指示cout以十进制、十六进制和八进制格式显示整数。 wchar_t,wcin和wcout 一种实现可以同时支持一个小型基本字符集和一个较大的扩展字符集。8位char可以表示基本字符集，另一种类型wchar_t (宽字符类型)可以表示扩展字符集。wchar_t类型是一种整数类型，它有足够的空间，可以表示系统使用的最大扩展字符集。这种类型与另一种整型（底层(underlying）类型）的长度和符号属性相同。对底层类型的选择取决于实现，因此在一个系统中，它可能是unsigned short，而在另一个系统中，则可能是int。 cin和 cout将输入和输出看作是char流，因此不适于用来处理wchar_t类型。iostream头文件的最新版本提供了作用相似的工具——wcin和wcout，可用于处理wchar_t流。另外，可以通过加上前缀L来指示宽字符常量和宽字符串。下面的代码将字母Р的wchar_t版本存储到变量bob中,并显示单词tall 的wchar_t版本: wchar_t bob = L'P'; l/ a wide-character constant wcout &lt;&lt; L&quot;tall&quot; &lt;&lt; endl; ll/ outputting a wide-character string 在支持两字节 wchar_t 的系统中，上述代码将把每个字符存储在一个两个字节的内存单元中。 char16_t和char32_t C++11新增了类型char16_t和char32_t，其中前者是无符号的，长16位，而后者也是无符号的，但长32位。C++11使用前缀u表示char16_t字符常量和字符串常量,如uC'和u&quot;be good&quot;;并使用前缀U表示char32_t常量,如U'R'和U&quot;dirtyrat”。 char16_t ch1 = u'q' ; l / basic character in 16-bit form char32_t ch2 = U'\\U0000222B'; // universal character name in 32-bit form 与wchar_t一样，char16_t和char32_t也都有底层类型——一种内置的整型，但底层类型可能随系统而已。 3.2 const限定符 const相比于#define的优点： 首先，它能够明确指定类型。 其次，可以使用C++的作用域规则将定义限制在特定的函数或文件中。 第三，可以将const用于更复杂的类型，如第4章将介绍的数组和结构。 此外，在C++（而不是C)中可以用const值来声明数组长度。 3.3 浮点数 cfloat或float.h头文件 可以从cfloat或float.h头文件中关于有效位数和指数范围等的限制。 浮点常量后缀 在默认情况下，像8.24和2.4E8这样的浮点常量都属于double类型。 如果希望常量为float类型，请使用f或F后缀。 对于long double类型，可使用l或L后缀（由于l看起来像数字1，因此L是更好的选择)。 下面是一些示例: 1.234f // a float constant 2.45E20F // a float constant 2.345324E28 // a double constant 2.2L // a long double constant 3.4 C++算术运算符 运算符优先级 书里只简单讲了讲优先级和结合性的概念。这里放一张微软文档里的表，这张表的内容很全，方便查表。 顺便吐槽，这表里有机翻啊，除法翻译成部门，赋值翻译成转让。。。我用md的表格语法贴上来，改掉上述翻译错误。 运算符说明 运算符 替代方法 第 1 组优先级，无关联性 范围解析 :: 第 2 组优先级，从左到右关联 成员选择（对象或指针） 或 -&gt; 数组下标 [] 函数调用 () 后缀递增 ++ 后缀递减 -- 类型名称 typeid 常量类型转换 const_cast 动态类型转换 dynamic_cast 重新解释的类型转换 reinterpret_cast 静态类型转换 static_cast 第 3 组优先级，从右到左关联 对象或类型的大小 sizeof 前缀递增 ++ 前缀递减 -- 二进制反码 ~ compl 逻辑“非” ! not 一元求反 - 一元加 + Address-of &amp; 间接寻址 * 创建对象 new 销毁对象 delete 强制转换 () 第 4 组优先级，从左到右关联 指向成员的指针（对象或指针） 或 -&gt;* 第 5 组优先级，从左到右关联 乘法 * 除法 / 取模 % 第 6 组优先级，从左到右关联 加法 + 减法 - 第 7 组优先级，从左到右关联 左移 &lt;&lt; 右移 &gt;&gt; 第 8 组优先级，从左到右关联 小于 &lt; 大于 &gt; 小于或等于 &lt;= 大于或等于 &gt;= 第 9 组优先级，从左到右关联 相等 == 不相等 != not_eq 第 10 组优先级，从左到右关联 位与 &amp; bitand 第 11 组优先级，从左到右关联 位异或 ^ xor 第 12 组优先级，从左到右关联 位或 | bitor 第 13 组优先级，从左到右关联 逻辑与 &amp;&amp; and 第 14 组优先级，从左到右关联 逻辑或 || or 第 15 组优先级，从右到左关联 条件逻辑 ? : 赋值 = 乘法赋值 *= 除法赋值 /= 取模赋值 %= 加法赋值 += 减法赋值 -= 左移赋值 &lt;&lt;= 右移赋值 &gt;&gt;= 按位“与”赋值 &amp;= and_eq 按位“与或”赋值 |= or_eq 按位“异或”赋值 ^= xor_eq 引发表达式 throw 第 16 组优先级，从左到右关联 逗号 , 类型转换 在进行列表初始化（list-initiallization），即使用{}进行初始化（C++11）时，不允许缩窄（narrowing），即变量的类型可能无法表示赋给它的值。 const int code = 66; int x = 66; char c1{31325}; // narrowing, not allowed char c2 = {66}; // allowed because char can hold 66 char c3{code}; // ditto char c4 = {x}; // not allowed,x is not constant x = 31325; char c5 = x; // allowed by this form of initialization 第4章 复合类型 4.1 数组 数组初始化 需要注意的一些规则： 只有在定义的时候才能初始化 如果只对数组一部分初始化，则编译器把其他元素设置为0 如果初始化数组是方括号[]内为空，则C++编译器将计算元素个数。 一般不推荐这样做。不过，在初始化const char[]时可以这么做，不用去数字符串长度。 以下是C++11新增的一些特性： 初始化数组时可省略等号 可不在大括号内包含任何东西，这将把所有元素设置为零 列表初始化禁止缩窄转换，详见3.4 C++算术运算符-类型转换 4.2 字符串 读取一行字符串 cin.getline()：该函数读取整行，使用回车键输入的换行符确定输入结尾。 第一个参数：存储输入行的数组的名称 第二个参数：读取的字符数。注意： 有一个多余空间用于存储'\\0'，如下实际能存储的字符数为19 cin.getline(name,20); cin.get()：该函数在读入一行时参数和用法大致与getline()相同，区别是getline()读取并丢弃换行符，而get()将其留在输入队列中。 另一种用法是使用不带参数的cin.get()，它将读取下一个字符，因此可以用于处理换行符。 在混合输入数字和字符串时，就可以用这个方法处理掉多余的换行符。如： (cin&gt;&gt;age).get()&gt;&gt;name; 空行和溢出问题 这个问题我挺在意，但书上表示在之后章节再详细介绍，先mark一下 4.3 string类简介 字符串的复制与拼接 c中的char数组需要使用strcpy()进行复制，strcat()进行拼接。而c++的string类可以通过赋值进行复制，+运算符进行拼接。例如，将字符串1和2拼接后复制给3： //C风格 strcpy(charr3, charr1); strcat(charr3, charr2); //C++风格 str3 = str1 + str2; 相比于c的数组操作，c++的类操作还不用担心长度溢出等问题。 string类读入一行 cin.getline(charr, 20); //char数组读入一行 getline (cin , str) ; // string类读入一行 这里没有使用句点表示法，这表明这个getline()不是类方法。它将cin 作为参数，指出到哪里去查找输入。另外，也没有指出字符串长度的参数，因为string对象将根据字符串的长度自动调整自己的大小。 istream类因为引入在string类之前，所以没有考虑string类型。cin&gt;&gt;x在读入其他类型时，使用的是istream类的成员函数，而cin&gt;&gt;str使用的是string类的友元函数。关于友元函数将在11章详细介绍。 原始字符串 原始字符串将&quot;(和)&quot;用作定界符，并使用前缀R来标识原始字符串: cout &lt;&lt; R&quot;(Jim &quot;King&quot; Tutt uses &quot;\\n&quot; instead of endl. )&quot; &lt;&lt; ' \\n '; 输入原始字符串时，按回车键不仅会移到下一行，还将在原始字符串中添加回车字符。 自定义定界符时，在默认定界符之间添加任意数量的基本字符，但空格、左括号、右括号、斜杠和控制字符（如制表符和换行符）除外。 可将前缀R与其他字符串前缀结合使用，以标识wchar_t等类型的原始字符串。R放在前后都可以。 4.4 结构简介 没什么需要注意的知识点。记一下匿名结构体吧。 匿名结构体 可以省略名称，定义一种结构类型和这种类型的变量。 struct { int x; int y; }position; 这种结构体类型没有名称，因此无法创建这种类型的变量，只能在定义的同时声明变量。 结构中的位字段 类型：整形或枚举。定义方式：冒号+位数。 struct torgle_register { unsigned int sN : 4; // 4 bits for sN value unsigned int : 4; // 4 bits unused bool goodIn : 1; // valid input (1 bit) bool goodTorgle : 1; // successful torgling }; 书上提到位字段常用于低级编程，也就是更接近硬件和底层，所以了解一下就行，可以使用位运算替代。 4.5 共用体 共用体（union） 是一种数据格式，它能够存储不同的数据类型，但只能同时存储其中的一种类型。 共用体的大小 这部分书上没提，稍微查了下，共用体的大小要大于最大的成员，并且对齐所有的成员。以下面这个共用体为例： union U { char s[9]; int n; double d; }; 用运算符sizeof测试其大小为16。这是因为这里存在字节对齐的问题，9既不能被4整除，也不能被8整除。因此补充字节到16，这样就符合所有成员的自身对齐了。 匿名共用体 匿名共用体和上面讲的匿名结构体差不多。它的一种用法是作为结构体的成员变量，共用体的成员将成为相同地址处的结构体的变量。 struct widget { char brand[20]; int type; union // anonymous union { long id_num; // type 1 widgets char id_char[20]; // other widgets }; }; widget prize; if (prize.type == 1) cin &gt;&gt; prize.id_num; else cin &gt;&gt; prize.id_char; 如上，可以直接使用prize.id_num访问共用体内成员，不需要命名和定义共同体在通过共用体访问内部成员。 4.6 枚举 定义与赋值 定义格式：enum 类型名 {枚举量[,枚举量]};，以下是一个示例： enum spectrum {red , orange, yellow, green, blue, violet, indigo, ultraviolet}; 默认情况下枚举量的值从0开始类推。 也可以通过赋值显式设置枚举量的值。 指定的值必须是整数。 如果只显式定义了部分枚举量的值，未被初始化的枚举量的值将比前一个大1。 也可以创建多个值相同的枚举量。 取值范围 每个枚举都有取值范围（range），通过强制类型转换，可以将取值范围内的任何整数值赋值给枚举变量，即使这个值不是枚举值。 取值范围的确定如下： 上限： 大于最大值的最小的2的幂减1。 下限：若最小值为0，则下限为0；否则，为上限相同方式加负号。 C++11增加了域内枚举（scoped enumeration），这将在第十章介绍。 4.7 指针和自由存储空间 两个基本运算符：取地址&amp;，解引用* 内存的分配和释放 在c中，可以使用malloc()和calloc()分配内存。 void *malloc( size_t size ); void *calloc( size_t num, size_t size ); calloc()内部其实就是用malloc实现的。 可以使用free()释放内存。 void free( void *ptr ); 在C++中，使用new申请内存空间，delete释放内存空间。 pointer = new type; pointer = new type( initializer ); pointer = new type[size]; delete p; delete[] pArray; 书中在这里还提到了静态联编和动态联编的区别。 静态联编和动态联编 静态联编: 使用数组声明来创建数组时，将采用静态联编，即数组的长度在编译时设置。 动态联编: 使用new[]运算符创建数组时，将采用动态联编（动态数组)，即将在运行时为数组分配空间，其长度也将在运行时设置。使用完这种数组后，应使用delete[]释放其占用的内存。 4.8 指针、数组和指针算 数组的地址和指针类型 这一部分看起来或许很抽象，但在应用时很容易出错。 数组名被解释为其第一个元素的地址，而对数组名应用地址运算符时，得到的是整个数组的地址。 short tell[10]; // tell an array of 20 bytes cout &lt;&lt; tell &lt;&lt; endl; // displays &amp;tell[0] cout &lt;&lt; &amp;tell &lt;&lt; endl; // displays address of whole array 从数字上说，这两个地址相同;但从概念上说，&amp;tell[0](即tell )是一个2字节内存块的地址，而&amp;tell是一个20字节内存块的地址。因此，表达式tell+1将地址值加2，而表达式&amp;tell+2将地址加20。换句话说, tell是一个 short指针(*short )，而&amp;tell是一个这样的指针，即指向包含20个元素的short 数组(short * )。 让我们看看这个short数组的指针类型：short (*)[20]，乍一看似乎并不好理解。这是一个长为20的short数组的指针？还是一个short指针的数组，长为20？让我们接着看下去。 我们可以这样声明和初始化这种指针： short (*pas)[20] = &amp;tell; //pas points to array of 20 shorts 如果省略括号,优先级规则将使得pas先与[20]结合，导致pas是一个short 指针数组,它包含20个元素,因此括号是必不可少的。其次，如果要描述变量的类型，可将声明中的变量名删除。因此, pas的类型为short(*)[20]。另外，由于pas被设置为&amp;tell，因此*pas与tell等价，所以(*pas)[0]为tell数组的第一个元素。 这里通过优先级的区别回答了上述问题。我提供另一种理解思路，不一定对： 如果没有括号，short与*结合，认为是short指针，再通过后面的[20]判定为指针数组。 有括号时，先是short和[20]结合判定为short数组，再通过*判定为数组指针。 我再讲讲关于使用方括号[] 进行数组索引的问题。这个方括号其实就相当于解引用，比如a[5]就相当于\\*(a+5)。理解了这个，一些直接使用指针的数组操作就更好理解了。 字符串指针 字符串指针和其他类型有所不同，它就是char *，而不是char (*)[20]，因为字符串的长度是由后续地址中'\\0'的位置决定的，而不是一开始被声明的。此外，在尝试输出字符串地址时，将会输出字符串的值：cout&lt;&lt;str;。如果需要输出字符串的地址，需要强制转换成其他类型的指针：cout&lt;&lt;(int*)str;。 自动存储、静态存储和动态存储 这部分其实看看书就好，我简单总结一下： 自动存储就是在函数内部定义的变量，即局部变量，只在其所在的代码块内有效，离开代码块后内存被释放。 静态存储的方式有两种，一种是在函数外定义，即全局变量；另一种是使用static关键字。静态存储的变量存在程序的整个生命周期，在程序结束后释放内存。 动态存储就是使用new和delete申请和释放内存，管理了一个内存池。这种方式更自由，但也导致了更复杂的内存管理。 进一步总结一下分配位置和生命周期： 自动存储分配在栈上，生命周期与所属函数的生命周期相同。 静态存储是分配在数据段中的，其生命周期从程序开始执行到结束都存在。 动态存储分配在自由存储区和堆上，需要手动分配和释放内存，其生命周期由程序员控制。 4.9 类型组合 没什么内容，看看指向指针数组的指针这种一堆*号嵌套怎么辨别吧。 复杂数据类型的识别 int a; // int类型 int *b[3] = {&amp;a, &amp;a, &amp;a}; // int指针数组 int **c = b; // 指向int指针数组的指针 一种方式就是之前提到的，*和[]的转换。比如b，你把后面的[3]看成一个*，于是b的类型就为int**。从int**到int* []也是一样的，可以看出int**是一个int指针的数组。 书上还提到用auto自动获取类型：auto c=b，就不用纠结怎么写c的类型了。但这样编译是过了，还是不知道c到底是什么类型。另一种可行的方法是typeid(b).name()，我们只要输出一下，编译器就会告诉我们数据类型了。 4.10 数组的替代品 模板类vector和array 简单介绍了模板类vector和array，讲的比较浅。贴两个声明方式吧： vector&lt;typeName&gt; vt (n_elem) ; arrayetypeName, n_elem&gt; arr; 它们的区别在于：vector长度可变，array长度固定。这是因为vector内部就是用new和delete来管理内存的，它的内存空间位于自由存储区和堆，而array的内存空间和常规数组一样位于栈或数据段中。 此外，vector和array和常规数组一样不检查下标越界的问题。为了安全可以使用at()成员函数，它将在运行期间捕获非法索引，同时程序默认中断。 第5章 循环和关系表达式 5.1 for循环 都是基础，记点杂项。 ios:: boolalpha 通常，cout在显示 bool值之前将它们转换为int，但cout.setf (ios:: boolalpha）函数调用设置了一个标记，该标记命令cout显示 true和 false，而不是1和0。 前缀格式和后缀格式 对于内置类型，采用哪种格式不会有差别; 但对于用户定义的类型，如果有用户定义的递增和递减运算符，则前缀格式的效率更高。 5.2 while循环 5.3 do while循环 都是基础，记点杂项。 ctime头文件 头文件ctime(较早的实现中为time.h）首先定义了一个符号常量——CLOCKS_PER_SEC，该常量等于每秒钟包含的系统时间单位数。因此，将系统时间除以这个值，可以得到秒数。或者将秒数乘以CLOCK_PER_SEC，可以得到以系统时间单位为单位的时间。其次，ctime将clock_t作为clock()返回类型的别名（参见本章后面的注释“类型别名”)，这意味着可以将变量声明为clock_t类型，编译器将把它转换为long、unsigned int或适合系统的其他类型。 5.4 基于范围的for循环 for(auto x:array)：对数组（或容器类）的每个元素执行相同的操作。 for(auto &amp;x:array)：&amp;表示x为引用变量，使可以修改数组内容。 5.5 循环和文本输入 文件尾EOF 看看书吧。这里记一下通过键盘来模拟文件尾条件。Unix：Crtl+D，Windows：Crtl+Z和Enter。 检测到EOF后，cin将两位（eofbit和failbit）都设置为1。可以通过成员函数eof( )来查看eofbit是否被设置;如果检测到EOF，则cin.eof()将返回 bool值 true，否则返回 false。同样，如果eofbit或failbit被设置为1，则 fail()成员函数返回 true，否则返回false。注意，eof()和fail()方法报告最近读取的结果;也就是说，它们在事后报告，而不是预先报告。因此应将cin.eof( )或cin.fail()测试放在读取后，程序清单5.18中的设计体现了这一点。它使用的是 fail()，而不是eof( )，因为前者可用于更多的实现中。 事实上，关于EOF的检测还有很多细碎的知识点，我就不一一列举了，掌握常用的方法就行。这部分内容更多是扩展一下视野让你知道为什么会这样，以及简单提及对象、原型和重载这些概念，对我作用不大。 5.6 嵌套循环和二维数组 指针数组初始化为字符串常量 这对我是一种很新鲜的写法，因为我一般直接用std::string数组或者二维char数组。这种方法仔细想想也确实可行。 const char *cities[5] = // array of pointers { // to 5 strings &quot;Gribble city&quot;, &quot;Gribbletown &quot;, &quot;New Gribble&quot;, &quot;san Gribble&quot;, &quot;Gribble vista&quot;}; 第6章 分支语句和逻辑运算 6.1 if语句 都是基础，略 6.2 逻辑表达式 有一点书上只提了一下，但我认为需要注意单独拿出来（看到后面才发现书上还是讲了这点，只不过举的除零的例子）。就是或运算符||和与运算符&amp;&amp;的判断是有顺序的，后续表达式对结果没有影响时会提前结束。这使得我们可以写出一些看上去有问题的逻辑表达式，因为逻辑运算符的本质就是写了个会提前返回的if-else表达式嵌套。例如我们判断可变数组里某个值是否为1（当然，这只是一个简单的例子，实际应用会比这复杂得多）： if(v[i] == 1) // exist risk if(v.size() &gt;= i &amp;&amp; v[i] == 1) // more safe /* equal to below if(v.size() &gt;= i) { if(v[i] == 1) return true; else return false; } else return false; */ 这种写法会先判断数组长度避免越界，再访问对应下标的值。如果下标越界，v.size() &gt;= i的值为false，后面无论是true还是false都对结果没有影响，于是判断提前结束。即使下标越界，v[i] == 1语句并不会被执行，所以运行时不会出问题。 此外，C++中也可以用and，or、not作为逻辑运算符。c中要想这样做需要包含iso646.h头文件，不过我个人觉得没必要。 6.3 字符函数库cctype 6.4 ？：运算符 这个最好只用于简单条件判断，复杂的嵌套什么的可以写但没必要，不差那几行代码对吧，可读性比较重要。 6.5 switch语句 注意：switch语句中的break不是必须的，你可以通过将多个case并在一起来提高代码复用。 书上提到使用枚举型变量，这是因为枚举型变量本质上就是给0,1,2这样的具体值起了个别名，这点我们在之前提到过。 6.6 break和continue语句 break和continue很基础就不说了。 goto书上提了一句， 大多数情况甚至任何情况都尽量避免使用goto。我也见过goto存在即合理就是给你用的这样的观点。我的看法是如果使用前叙述的结构化语句很复杂麻烦，而goto能很好地提升代码可读性的话用用也未尝不可，没必要当洪水猛兽。 6.7 读取数组的循环 提到了一点错误处理，在本应输入数字是输入字符，可以先用cin.clear()重置cin，再while(cin.get()!='\\n') 来读掉错误输入，最后要求用户重新输入。 我觉得这个看看就行不用认真记。后面肯定有专门的错误处理方法。这种就初学者为了用户交互用用。 6.8 简单文件输入输出 简单文件读写 一些简单的文件读写，详细的要看后面。临时简单用用还行。 写入文本文件： 1．包含头文件 fstream。 2．创建一个ofstream对象。 3．将该ofstream对象同一个文件关联起来（ofstream.open(filename)）。 4．就像使用cout那样使用该ofstream对象。 在使用ofstream.open()是，如果文件不存在将被创建；如果文件已存在默认将丢弃原有内容重新写入。 使用完文件后记得用ofstream.close()将其关闭。 读取文本文件大致相似。可以使用ifstream.is_open()检测文件是否成功打开。 if(!fin.is_open()) exit(EXIT_FAILURE); 如果文件被成功地打开，方法 is_open()将返回 true;因此如果文件没有被打开，表达式!inFile.isopen()将为true。函数 exit()的原型是在头文件cstdib 中定义的，在该头文件中，还定义了一个用于同操作系统通信的参数值EXIT_FAILURE。函数exit()终止程序。 文本文件结尾 \\n\\r什么的书上也提了下，感觉算那种暂时可以不了解但不能不知道的小知识，大部分时候都不用管但不知道什么时候就会因为这个出问题。这东西Windows和Linux还不一样，每次看到这类东西都想着要是能统一一下就好了，但也没啥可能，积重难返。 警告:Windows文本文件的每行都以回车字符和换行符结尾;通常情况下，C++在读取文件时将这两个字符转换为换行符，并在写入文件时执行相反的转换。有些文本编辑器(如Metrowerks CodeWarrior IDE编辑器)，不会自动在最后一行末尾加上换行符。因此，如果读者使用的是这种编辑器，请在输入最后的文本后按下回车键，然后再保存文件。 文件打开失败时确定原因 在检测文件是否成功打开时，一种简单的方法是使用good()，该方法将在没有发生任何错误时返回true，也可以使用eof()（读到eof）,fail()（读到eof、类型不匹配）,bad()（文件受损、硬件故障等）来尝试确定具体原因。 第7章 函数——C++的编程模块 7.1 复习函数的基本知识 主要还是讲函数原型，讲的太细反而看不出有什么重点。。。 函数和返回值类型不匹配时会自动转换什么的用过一两次就知道了。 7.2 函数参数和按值传递 形参和实参 了解一下形参（parameter）和实参（argument）的概念。形参是实参的副本，修改形参并不会影响实参。但如果你需要修改实参，则可以传递地址或者取引用，后面会讲。 7.3 函数和数组 数组作函数参数 主要就是第4章的数组的地址和指针类型里讲过的，数组名相当于第一个元素的地址。当然，他和真正的地址有一点区别，因为程序是将它标记成数组的，所以sizeof运算符和&amp;地址运算符都返回的是整个数组的长度or地址。而进行函数传参时，它就失去了作为数组名的特性，仅仅是首元素地址了，所以我们通常需要额外的参数来说明数组长度。 指针和const 在只有一级间接关系时还好理解，到了二级就有点似懂非懂，看了蛮久才勉强明白。所以说指针这东西就是麻烦。这里直接贴结论，详细还是看书多思考一下： 注意:如果数据类型本身并不是指针，则可以将const 数据或非const 数据的地址赋给指向const 的指针，但只能将非const 数据的地址赋给非const指针。 指向常量的指针和常量指针 当const写在指针类型前时，它表示指向常量的指针，指针指向对象的值不能改变，但指针的对象可以改变。 当const写在指针类型后时，它表示常量指针，指针指向对象的值可以改变，但指针的对象不能改变。 当然，也可以写两个const，使指针指向的对象和指向对象的值都不能改变。 7.4 函数和二维数组 二维（多维）数组的指针 做函数参数的二维数组长啥样？答案是int (*)[]，这是类型名。例如一个3*4的二维数组arr，就是int (*arr)[4]。当然可以写int arr[][4]，后者可读性更好但前者更利于你了解指针。又来了，C/C++的噩梦——指针。这个地方多一个括号少一个括号意思完全不一样，难怪不少人谈指针色变。 带括号时，int (*arr)[4]，它表示指向长为4的int数组的指针；而不带括号的int *arr[4]，它表示长为4的指向int类型指针的数组。是不是有点晕了（笑）。我们这样来看，带括号时，先是int与[4]结合，表示长为4的int数组，再看*号，就是指向这个数组的指针。而不带括号时，首先是int与*结合，表示指向int类型的指针，再看后面的[4]，表示长为4的数组，这样就行了。 我之前想当然的移位一维数组是int *，二维数组就应该是int **，这是不对的，实际上后者表示的是指向int指针的指针，或者说可以作为int指针的数组。这是你可能就疑问了，每个一维数组是一个int指针，int指针的数组不就是二维数组了吗？这你就忽略了最重要的一个因素：长度。你没有指定一维数组的长度，这种定义就相当于连续的一维数组指针放在一起而没有对应的数组空间，你只能动态给它分配内存，和我们平常说的拥有连续内存空间的二维数组并不一样。举个例子： // 静态分配内存 int arr[3][4]; // 动态分配内存 int **arr2; arr2 = new int *[3]; for (int i = 0; i &lt; 3; i++) arr2[i] = new int[4]; // 使用方法近似 for (int i = 0; i &lt; 3; i++) for (int j = 0; j &lt; 4; j++) arr[i][j] = arr2[i][j] = i &amp; 4 + j; 它们虽然用起来差不多，但在函数传参时，如果不能正确地指定类型名是不行的。所以还是要搞懂它们的区别。 7.5 函数和C-风格字符串 略，就是强调传值直接传指针。字符串因为有\\0不用再传长度。 7.6 函数和结构 7.7 函数和string对象 7.8 函数和array对象 一路看下来没什么重要的内容。感觉一直在强调可以用指针但后面会讲更好用的引用这样。 7.9 递归 略。 7.10 函数指针 函数指针乍一看很高大上，其实声明和用法什么的是共通的。就像基本类型一样，你在函数声明的变量前加个*就是函数声明了。但因为函数有参数列表，所以要用括号括起来避免优先级的问题。如下： double (*pf)(int); //指向返回值为double的函数的指针 double *pf(int); //返回值为指向double的指针的函数 此外，使用指针调用函数时，既可以使用(*pf)，也可以直接使用pf当函数名。虽然两者逻辑上是冲突的，但支持两种做法的人都有，所以C++进行了折中，两种做法都是正确的。 在进行函数指针声明时，也可直接用auto+初始化的方式： double func(int)； auto pf=func; 要查看实际的函数地址，则需要解引用，如*pf或者*(*pf)。 再上点强度，指向函数的指针的数组怎么写？ const double * (*pf[3]) (const double *, int); 如上是指向返回类型为const double *的函数的指针的数组。正如我们之前所说，pf先与[3]结合表示是数组，*表示数组内存的是指针，其他表示这是一个函数指针。如果括起来，理论上就是指向函数数组的指针了。尝试了一下，编译器将报错不允许使用函数数组。 再套一层，指向这个数组的指针怎么写？ const double * (*(*ppf)[3]) (const double *, int); 从里往外看，首先(*ppf)表示这是一个指针，把它摘出去，剩下的const double * (*[3]) (const double *, int);其实就是上面那个数组的类型了，合起来看就是指向这个类型的指针，怎么样，晕了吧。没关系，我也晕。 最后，记得用auto和typedef简化编码。例如上述的指向函数的指针的数组的指针，就可以如下定义： const double * (*pf[3]) (const double *, int); auto ppf=&amp;pf; 以及使用typedef为复杂的类型起一个别名。 typedef const double * (*p_func) (const double *, int); p_func pf=func; ","link":"https://jinvic.github.io/post/[study-notes]-cpp-primer-plus-6th-edition-[basic]/"},{"title":"基于python爬虫的arcptt计算器【备份留档】","content":" 备份留档 注意： 以下内容为早期边学边做的记录，已过时，仅作备份留档用。 项目最新进度可以查看 GUI项目地址 前言 arcaea在一次更新后删减了api的返回数据，所以各种查分bot都用不了，查分被做成了付费功能。。，约14RMB一个月。玩家直接倒退回excel时代手算ptt。虽然excel写好函数后也还算方便了，没必要写个计算器套壳。但我想学习了解一下python爬虫和Qtpy这些，就从这个点入手了。做自己感兴趣的题材学起来也没那么枯燥。 CLI项目地址（不再维护） GUI项目地址 爬取网页 因为没打算深入学习，只想快点搞个成品出来，所以各项原理只是简单过了遍，没有深入学习，像是查字典一样去找自己需要的部分。 参考书籍为：Python3网络爬虫开发实战 第二版 先是用的urllib.request.urlopen，返回一个response，print时没什么问题，存文件就会报错：UnicodeEncodeError，python的编码问题不是很懂，先略过。 往后翻了翻，使用requests.get，这次报错requests.exceptions.SSLError。查一下，加个verify=False来避免ssl认证。再跑，报错requests.exceptions.ProxyError，再查，代理的问题。因为我随时上谷歌和github page，代理是一直挂着的。关了代理，verify=False也删掉，再跑，终于好了： import requests # 获取网页 url = 'https://wiki.arcaea.cn/%E5%AE%9A%E6%95%B0%E8%AF%A6%E8%A1%A8' # 定数详表页面 response = requests.get(url) with open('website.html', mode='wb') as html_file: html_file.write(response.text) emm其实爬虫的部分可以到此为止了，接下来就是数据的提取和处理。不过这样未免过于虎头蛇尾，再往后看看有什么用得上的。 解析提取数据 书上提供了XPath，Beautiful Soup、pyquery等几种库，看得我眼花缭乱。最后选择了pyquery库，它用的选择器和CSS是一样的。之前做移动终端编程也了解过一点jquery。想到这个我就有满满的槽要吐，这个有空再聊。 想从之前保存的网页中读，又报错了：UnicodeDecodeError。还是字符问题，有空再把python的字符整明白。这里url比较简单，不需要加什么参数，就不用request库直接用pyquery访问了： from pyquery import PyQuery as pq target_url = 'https://wiki.arcaea.cn/%E5%AE%9A%E6%95%B0%E8%AF%A6%E8%A1%A8' # 定数详表页面 doc = pq(url=target_url) chart_constant_table = doc('tbody') # 定数表 print(chart_constant_table('th').text()) for item in chart_constant_table('tr').items(): print(item('td').text()) 定数表拿到了，接下来的问题就是用什么样的数据结构存这张表。 定数表存储 比较让人恼火的一点是，这些曲目似乎并没有一个统一的编号。arcaea中文维基只是简单粗暴的用曲名作为表示符。这样增删改查感觉都不怎么方便。我也懒得折腾就这样吧。 使用csv库来存储定数表，又报错了：UnicodeEncodeError。看看存了一半的csv，原来是Löschen中的ö是德文字符，默认gbk字符集写入没有这个字符。之前的报错应该也都是这个原因。加个encoding='utf-8'，问题解决。 from pyquery import PyQuery as pq import csv target_url = 'https://wiki.arcaea.cn/%E5%AE%9A%E6%95%B0%E8%AF%A6%E8%A1%A8' # 定数详表页面 doc = pq(url=target_url) chart_constant_table = doc('tbody') # 定数表 # print(list(chart_constant_table('th').text().split(' '))) with open('chart_constant_table.csv', 'w', encoding='utf-8', newline='') as csvfile: writer = csv.writer(csvfile) for item in chart_constant_table('tr').items(): print(item.text().split('\\n')) writer.writerow(item.text().split('\\n')) 定数表查询 正常写个遍历查询。考虑了一下要不要用pandas库，因为csv表很小就三百来行，也不需要什么高级的数据分析处理就算了。 本来是{head[i]}:{row[i]}这样输出，感觉看起来不是很方便就改成类似表格的格式输出了。求取曲名列最大长度后用ljust对齐。 import csv def CCT_search(st): # 读取csv并查询 with open('chart_constant_table.csv', 'r', encoding='utf-8') as csvfile: reader = csv.reader(csvfile) head = next(reader) res = [] for row in reader: if(row[0].upper().find(st.upper()) != -1): res.append(row) # 寻找曲名的最大宽度 max_width = max([len(str(row[0])) for row in res]) max_widths = [5, max_width, 5, 5, 5, 5] # 编号和定数列宽度固定 # print(max_widths) if(len(res) == 0): print('未查找到结果，请重新查找') else: # 输出表头 head = ['编号']+head formatted_row = '' for i in range(len(head)): if(i &lt; 2): # 前两列为中文，宽度短一点不然对不齐 formatted_row += str(head[i]).ljust(max_widths[i]) else: formatted_row += str(head[i]).ljust(max_widths[i] + 2) print(formatted_row) # 输出定数表 idx = 0 for row in res: # print(f'', end=' ') row = [idx]+row formatted_row = '' for i in range(len(row)): # print(f'{head[i]}:{row[i]}', end=' ') formatted_row += str(row[i]).ljust(max_widths[i] + 2) print(formatted_row) idx += 1 return res 这只是查曲名用的，大小写不敏感。给查询结果编号输出，用户通过编号选择对应曲目。以查询red为例，输出如下： 编号 曲目 PST PRS FTR BYD 0 Redolent Shape 4.5 7.5 10.2 1 Hybris (The one who shattered) 4.5 7.5 9.8 2 Red and Blue 4.0 7.5 9.4 10.0 3 Redraw the Colorless World 4.0 6.5 9.2 玩家成绩存储和更新 我打算另建一张用户数据表来存储玩家玩了哪些曲目，以及对应的成绩和潜力值。 最开始用户数据表是空的。玩家每次玩了新歌，录入成绩时需要从定数表中拿曲名和定数出来，再结合成绩计算潜力值存入用户数据表，表头为曲名 难度 定数 成绩 潜力值。之后推了更高的分，就直接在用户数据表里面更新。添加成绩代码如下： import csv from CCT_search import CCT_search from ptt_culculation import ptt_cul # 从定数表添加新行 def UDT_add(): print('请输入关键词以查找曲目') st = input() res = CCT_search(st) if(len(res) == 0): return input_check = False while input_check == False: print(&quot;选择添加的曲目，输入编号&quot;) idx = int(input()) if(idx &gt;= len(res) or idx &lt; 0): print(&quot;编号不合法&quot;) else: input_check = True input_check = False while input_check == False: print(&quot;选择难度[pst|prs|ftr|byd]&quot;) difficults = ['PST', 'PRS', 'FTR', 'BYD'] difficult = input() dif_id = -1 for i in range(4): if(difficults[i].upper() == difficult.upper()): dif_id = i break if(dif_id == -1): print('难度输入错误') else: input_check = True print(&quot;输入成绩&quot;) score = int(input()) # 曲名 难度 定数 成绩 潜力值 new_row = [res[idx][0], difficults[dif_id], res[idx][dif_id+1], score, ptt_cul(float(res[idx][dif_id+1]), score)] print(new_row) # 写入用户数据表 with open('user_data_table.csv', 'a', encoding='utf-8', newline='') as csvfile: writer = csv.writer(csvfile) writer.writerow(new_row) UDT_sort() 更新成绩代码如下，查找部分和之前CCT_search()差不多，感觉一直打表和查找代码重复度太高了，有空再优化吧。 def UDT_update(): print('请输入关键词以查找曲目') st = input() # 在用户数据表搜索 with open('user_data_table.csv', 'r', encoding='utf-8') as csvfile: reader = csv.reader(csvfile) rows = [row for row in reader] res = [] dic = {} # 存查找结果到原表行数的映射 row_no = 0 # 原表行数 idx = 0 # 结果编号 for row in rows: if(row[0].upper().find(st.upper()) != -1): res.append([idx]+row) dic[idx] = row_no idx += 1 row_no += 1 if(len(res) == 0): print('未查找到结果，请重新查找') return # 寻找曲名的最大宽度 max_width = max([len(str(row[1])) for row in res]) max_widths = [5, max_width, 5, 5, 10, 10] head = ['编号', '曲名', '难度', '定数', '成绩', '潜力值'] head_widths = [3, max_width, 3, 3, 8, 7] # 输出表头 formatted_row = '' for i in range(len(head)): formatted_row += str(head[i]).ljust(head_widths[i] + 2) print(formatted_row) # 输出用户数据表 for row in res: formatted_row = '' for i in range(len(row)): formatted_row += str(row[i]).ljust(max_widths[i] + 2) print(formatted_row) input_check = False while input_check == False: print(&quot;选择修改的曲目，输入编号&quot;) idx = int(input()) if(idx &gt;= len(res) or idx &lt; 0): print(&quot;编号不合法&quot;) else: input_check = True print('输入更新后的成绩') score = int(input()) rows[dic[idx]][3] = score rows[dic[idx]][4] = ptt_cul( float(rows[dic[idx]][2]), rows[dic[idx]][3]) with open('user_data_table.csv', 'w', encoding='utf-8', newline='') as new_csvfile: writer = csv.writer(new_csvfile) writer.writerows(rows) UDT_sort() 写个排序函数,每次更改用户数据表后排序。 def UDT_sort(): with open('user_data_table.csv', 'r', encoding='utf-8', newline='') as csvfile: reader = csv.reader(csvfile) rows = [row for row in reader] sorted_rows = sorted(rows, key=lambda x: float(x[4]), reverse=True) with open('user_data_table.csv', 'w', newline='') as csvfile: writer = csv.writer(csvfile) writer.writerows(sorted_rows) b30和r10计算 每次计算b30前使用UDT_sort()排序。如果成绩大于30项，只取前30项。 单曲ptt和r10都有公式算。 一起的代码如下： import csv def ptt_cul(cc, score): if(score &gt; 10000000): return cc+2 elif(score &gt;= 9800000): return cc+1+(score-9800000)/200000 else: return max(cc+(score-9500000)/300000, 0) def b30_cul(): with open('user_data_table.csv', 'r', encoding='utf-8', newline='') as csvfile: reader = csv.reader(csvfile) cnt = 0 sum = 0 for row in reader: sum += float(row[4]) cnt += 1 if(cnt == 30): break return sum/30 def r10_cul(b30, ptt): return (ptt*40-b30*30)/10 命令行界面和打包 做个简单的命令行界面看能不能用。 from spider import CCT_update from user_data_edit import UDT_add, UDT_list, UDT_update from ptt_culculation import b30_cul, r10_cul def main(): print('选择你要进行的操作：') print('1. 更新定数表') print('2. 列出用户成绩') print('3. 添加新成绩') print('4. 更新现有成绩') print('5. 计算b30') print('6. 计算r10') input_check = False while input_check == False: idx = int(input()) if(idx &gt; 6 or idx &lt;= 0): print(&quot;编号不合法&quot;) else: input_check = True if(idx == 1): CCT_update() elif(idx == 2): UDT_list() elif(idx == 3): UDT_add() elif(idx == 4): UDT_update() elif(idx == 5): print(b30_cul()) else: print('输入你现在的ptt') ptt = input() print(r10_cul(b30_cul(), float(ptt))) if __name__ == '__main__': while(True): print() main() 安装PyInstaller，使用Pyinstaller -F main.py命令进行单文件打包。 初次使用需要先生成两个表格。启动程序，先使用1. 更新定数表命令生成定数表。再使用3. 添加新成绩命令生成用户数据表。也可以自己导入用户数据，方法见上。 Qtpy图形化界面 诶，还没做呢。CLI能用懒得做GUI了，有生之年系列。 开始做了。懒得贴代码了，去github看吧。这里记一下进度。 项目地址 23-06-12 0:17 GUI使用Pyside6开发，先搭一个架子。 整合了CCT查询和UDT查询。表格显示使用TableView空间，不再手动格式化。 给UDT加了个表头，使CCT和UDT的搜索通用。 23-06-13 3:16 把各个文件整合为单文件。 添加了爬取定数表失败的异常处理。 使用QInputDialog进行参数输入。控件自带的输入限制省去了手写异常处理的工作量。 完成了GUI的开发。 （居然两天就做完了，还以为会拖很久） ","link":"https://jinvic.github.io/post/python-spider-based-arc-ptt-culculation/"},{"title":"BMP图片格式和读取【C++/Python】","content":" 前言 这篇文章的标题本来是《人工智能实验-基于三层BP神经网络的人脸识别》这样看起来就高大上的标题的，结果做了一半，室友告诉我这个实验允许用python，而且C++求梯度时有求导什么的不好写balabala。。。（其实只是公式推导，最后推出来的要用的公式并不复杂）加上期末考试将近确实确实缺时间，只好转python化身调包侠交差。至于做了一半的C程序和文章，还是有点舍不得，只好从里面拆一块勉强成形的部分出来，变成了现在这个小肚鸡肠的标题，残念。 如果你按下F12，还能从注释里找到点原文章的残骸 我刚开始做的时候用的C++，然后理所当然去拿rgb值了。之后做python看到用PIL包一句话的事，羡慕嫉妒恨。C++其实也有很多第三方库，但安装啊文档啊用法啊这些都是问题，有什么疑惑也没地问。社区环境不如java和python这些，大佬不屑于用萌新用不明白，于是大家都自己造轮子，轮子越造越多却没几个能传播到大家都用的地步。闲话到此为止，先讲讲如何用C++读取图片rgb值，python放最后面。 BMP图像文件格式 了解BMP的格式我主要参考了这篇文章BMP图片的文件结构。这篇介绍得相对独立，不需要什么前置知识。此外，为了更完善的代码支持，我引入了wingdi.h这个头文件。这是 Windows 平台上的一个头文件，其中定义了一些图形设备接口（GDI）相关的结构体、常量和函数。同时定义好了一些可用于处理BMP的结构体和函数，这样就不用自己写一遍了。但我发现使用这个头文件里的定义时我的IDE的自动补全和错误检查之类都变得很慢，不知道是不是引入这个头文件引起的，之后可能把相关代码修改一下单独拿出来。 言归正传，wingdi.h头文件是有着官方文档可用的。仅用于处理BMP格式的话，看这几个就够了： wingdi.h 标头：相当于目录，主要在#structures下找定义好的结构体。 BITMAP 结构 (wingdi.h)：BMP结构体，如果觉得他定义的这个不好用也可以自己写一个。我就有点想换了，void*每次用都要强转。。。 BITMAPFILEHEADER structure (wingdi.h)：文件头结构体，不知道为什么这个页面没中文，不过也没几个字无所谓。 BITMAPINFOHEADER 结构 (wingdi.h)：信息头结构体，重要的信息都在这里。 RGBQUAD 结构 (wingdi.h)颜色表结构体。 参考资料列完，就来简单讲讲BMP的文件格式吧。大致可分为4个部分：位图文件头（Bitmap File Header）、位图信息头（Bitmap Info Header）、颜色表（Color Map）和位图数据（即图像数据，Data Bits或Data Body）。 文件头和信息头的结构就不具体介绍了，看上面的文档就行。颜色表是一个可选项，不一定有。主要取决于信息头中一个叫biBitCount的参数，它指定每个像素的位数 (bpp) ，取值有1、4、8、24、32几种。首先我们要知道，像素的颜色通常有r、g、b三个值确定，每个值的长度都是8位，加起来就是24位。于是，如果biBitCount为24的话，它直接就能存下rgb值了，也就不需要颜色表。至于32位，个人猜测是加了一个alpha值，也就是透明度，之前做滑块验证码时Java的bufferimage就是这样的。不过BMP是不是也这样我也不确定，没查资料。 回到正题，24位是没有颜色表的。那么颜色表是干什么的呢？就是当biBitCount小于24时，每个像素的位数存不下rgb值，这时就需要一个额外的表来保存可选的rgb值，而位图数据存的是这张表的索引。举个例子，假设一张BMP图的biBitCount值为8，那么在文件头和信息头后就是一个大小为2^8=256的颜色表。之后再是位图数据。对于这张图的每个像素，他首先在位图数据中得到一个8位的值，然后以这个值作为索引到颜色表里去找对应的颜色。同理，biBitCount值为1颜色表就只有2种颜色，值为4就是16种颜色。 BMP图像RGB值读入和处理 写一个读入函数，定义如下 bool readBMP(const char *filename, BITMAP *bmp) filename我准备外部用std::string类型，方便修改，传入时就用std::string.c_str()；BITMAP是wingdi.h中定义的结构体，主要注意成员bmBits，这是指向位图位值位置的指针。 首先用ifstream打开文件后，读掉文件头和信息头： // 二进制读方式打开指定的图像文件 std::ifstream file(filename, std::ios::binary); // 位图文件头结构变量 BITMAPFILEHEADER file_head; file.read((char *)&amp;file_head, sizeof(BITMAPFILEHEADER)); // 位图信息头结构变量 BITMAPINFOHEADER info_head; file.read((char *)&amp;info_head, sizeof(BITMAPINFOHEADER)); 根据文件头和信息头的内容，进行标识符校验和部分成员赋值： // 检查文件标识符 if (file_head.bfType != 0x4d42) { std::cerr &lt;&lt; &quot;Invalid BMP file: &quot; &lt;&lt; filename &lt;&lt; std::endl; return false; } // 处理固定值 bmp-&gt;bmType = 0; bmp-&gt;bmPlanes = 1; // 获取图像宽度和高度 bmp-&gt;bmWidth = info_head.biWidth; bmp-&gt;bmHeight = info_head.biHeight; 到了处理位图数据的部分，数据集的图片都是8位256色的图，但做神经网络时存三个rgb值对我们没有意义，还需要额外空间去存颜色表。所以我们这里直接转成32位bpp，用wingdi.h中的RGB(r,g,b)宏把三个值合成一个。其实就是按位拼起来，自己写一个也行。不过有现成的我也懒得写了。 同时为了兼容性，还是要判断一下原图的bpp是否为8的，然后决定是否读掉颜色表以及转32位操作。这里我想删掉的，毕竟要做兼容性其实应该把1,4,32全做一下，暂时就这样吧。 // 每个像素的位数，转换成32位的颜色值 bmp-&gt;bmBitsPixel = 32; // 灰度图像有颜色表，且颜色表表项为256 RGBQUAD *color_table; if (info_head.biBitCount == 8) { // 申请颜色表所需要的空间，读颜色表进内存 color_table = new RGBQUAD[256]; file.read((char *)color_table, sizeof(RGBQUAD) * 256); } // 计算每个扫描行中的字节数 bmp-&gt;bmWidthBytes = info_head.biWidth * info_head.biBitCount / 8 + 3 / 4 * 4; DWORD biSizeImage = bmp-&gt;bmWidthBytes * bmp-&gt;bmHeight; // 申请位图数据所需要的空间 char *bmBits = new char[biSizeImage]; // 读取图像数据 file.read((char *)bmBits, biSizeImage); // 将数据存入结构体BITMAP中 if (info_head.biBitCount == 8) { bmp-&gt;bmBits = new COLORREF[biSizeImage]; for (int i = 0; i &lt; biSizeImage; i++) ((COLORREF *)(bmp-&gt;bmBits))[i] = RGB(color_table[bmBits[i]].rgbRed, color_table[bmBits[i]].rgbGreen, color_table[bmBits[i]].rgbBlue); delete[] color_table; } else bmp-&gt;bmBits = bmBits; 完整代码 // 读入BMP图像 bool readBMP(const char *filename, BITMAP *bmp) { // 二进制读方式打开指定的图像文件 std::ifstream file(filename, std::ios::binary); if (!file) { std::cerr &lt;&lt; &quot;Failed to open BMP file: &quot; &lt;&lt; filename &lt;&lt; std::endl; return false; } // 位图文件头结构变量 BITMAPFILEHEADER file_head; file.read((char *)&amp;file_head, sizeof(BITMAPFILEHEADER)); // 位图信息头结构变量 BITMAPINFOHEADER info_head; file.read((char *)&amp;info_head, sizeof(BITMAPINFOHEADER)); // 检查文件标识符 if (file_head.bfType != 0x4d42) { std::cerr &lt;&lt; &quot;Invalid BMP file: &quot; &lt;&lt; filename &lt;&lt; std::endl; return false; } // 处理固定值 bmp-&gt;bmType = 0; bmp-&gt;bmPlanes = 1; // 获取图像宽度和高度 bmp-&gt;bmWidth = info_head.biWidth; bmp-&gt;bmHeight = info_head.biHeight; // 每个像素的位数，转换成32位的颜色值 bmp-&gt;bmBitsPixel = 32; // 灰度图像有颜色表，且颜色表表项为256 RGBQUAD *color_table; if (info_head.biBitCount == 8) { // 申请颜色表所需要的空间，读颜色表进内存 color_table = new RGBQUAD[256]; file.read((char *)color_table, sizeof(RGBQUAD) * 256); } // 计算每个扫描行中的字节数 bmp-&gt;bmWidthBytes = (info_head.biWidth * info_head.biBitCount / 8 + 3) / 4 * 4; DWORD biSizeImage = bmp-&gt;bmWidthBytes * bmp-&gt;bmHeight; // 申请位图数据所需要的空间 char *bmBits = new char[biSizeImage]; // 读取图像数据 file.read((char *)bmBits, biSizeImage); // 将数据存入结构体BITMAP中 if (info_head.biBitCount == 8) { bmp-&gt;bmBits = new COLORREF[biSizeImage]; for (int i = 0; i &lt; biSizeImage; i++) ((COLORREF *)(bmp-&gt;bmBits))[i] = RGB(color_table[bmBits[i]].rgbRed, color_table[bmBits[i]].rgbGreen, color_table[bmBits[i]].rgbBlue); delete[] color_table; } else bmp-&gt;bmBits = bmBits; if (!file) { std::cerr &lt;&lt; &quot;Error reading BMP file: &quot; &lt;&lt; filename &lt;&lt; std::endl; return false; } return true; } 顺手放个测试函数： void readBMP_test(void) { BITMAP bmp; std::string filename = &quot;1.BMP&quot;; readBMP(filename.c_str(), &amp;bmp); std::cout &lt;&lt; bmp.bmWidth &lt;&lt; &quot; &quot; &lt;&lt; bmp.bmHeight &lt;&lt; '\\n'; // std::cout &lt;&lt; ((COLORREF *)(bmp.bmBits))[0] &lt;&lt; &quot; &quot; &lt;&lt; ((COLORREF *)(bmp.bmBits))[bmp.bmWidth * bmp.bmHeight - 1] &lt;&lt; '\\n'; for (int i = 0; i &lt; bmp.bmWidth * bmp.bmHeight; i++) { std::cout &lt;&lt; ((COLORREF *)(bmp.bmBits))[i] &lt;&lt; '\\n'; } } Python python也可以像上文那样一个个读字节把头文件什么的全读掉，但我没有深入了解和尝试实现。 放个博客在这：BMP文件分析及用python读取 另一种方法就是使用Python中的Pillow（PIL）库。Pillow库是Python Imaging Library（PIL）的分支，它支持多种图像文件格式。 示例代码如下： from PIL import Image # 打开 BMP 图像文件 with Image.open('image.bmp') as img: # 获取图像的 RGB 像素数据 rgb_img = img.convert('RGB') width, height = rgb_img.size # 遍历图像的每一个像素点，并获取其 RGB 值 for y in range(height): for x in range(width): r, g, b = rgb_img.getpixel((x, y)) print(f&quot;Pixel({x}, {y}) - R: {r}, G: {g}, B: {b}&quot;) 顺便一提，也可以不把rgb值拿出来直接用np.array()转为数组用来训练。因为我的数据集是8位灰度图像，还需要用image.convert(L)将图像转换为灰度模式。最后用flatten()方法降维一维。 关于image.convert()函数，可以看这篇博客。 示例代码如下： from PIL import Image import numpy as np # 读入BMP图像并转换为灰度模式 img = Image.open('image.bmp').convert('L') # 转换为NumPy数组 img_data = np.array(img) # 将图像数据展平并添加到列表中 X.append(img_data.flatten()) ","link":"https://jinvic.github.io/post/BMP_image_format_and_read_[C++_Python]/"},{"title":"关于中文字符编码的二三事","content":"从学习编程以来，基本都一直避免着用到中文。因为中文容易乱码嘛，英文用起来没那么多事。但一直没有深究其中的原因。前段时间做信息安全的实验，各种加密解密。然而助教提了一个要求：要能够处理中文。得，不能再当鸵鸟了，只得好好叨唠叨唠处理中文的问题。其实这玩意，会者不难难者不会。要深究一番也还是有点深度，这里就简单介绍下。 什么是编码？ 简单来说，编码对字符来说就像是身份证一样，计算机通过一个编号来唯一确定一种字符。你在敲代码，或者阅读文本时，所看到的字符，其实计算机是不认的。计算机中存储的是其对应的编码，要用的时候先查询这个编码对应的字符，再将字符呈现给你看。 为什么英文不用考虑编码问题？ 首先，为什么我们在使用英文时从来没有考虑过编码问题？其实英文字母是有编码的，就是c里面的‘a’=97这样，其中的97就是它的编号。这套编码我们称之为ASCII码，只有0-127。别的编码方式，基本都是兼容ASCII码的，或者说是在ASCII上进行扩展，添加新的字符以及对应的编码。所以，不管你这台设备，或者说这个文件，这个终端用的是什么编码，使用ASCII码的英文一般都能够正常显示，所以不用考虑编码问题。 为什么有时中文会乱码？ 上文提到，编码是计算机将编号和字符唯一对应的方式。也就是说，同样的一个编号，在不同编码方式下可能会是完全不同的两个字符。这就是为什么我们有时会遇到中文乱码了。举个很常见的例子，你在VScode写个个小程序，输出中文，F5，一切正常。 #include &lt;bits/stdc++.h&gt; using namespace std; signed main(void) { cout &lt;&lt; &quot;中文&quot; &lt;&lt; endl; system(&quot;pause&quot;); return 0; } 但直接运行编译生成的可执行文件就会乱码： 原因就是我们上面讲的，双方使用的编码不一样。我们通过chcp命令来查看两个终端分别用到什么编码： 这里输出的是代码页(Code Page)，这里我们不做展开。只要知道936对应GBK编码，而65001对应UTF-8编码就行。双方使用的编码不一样，结果也就不一样。 那为什么UTF-8编码的输出才是正确的呢？也许你没有注意到，在使用VScode编辑器时，右下角会有个小小的UTF-8字样： 这是说我们正在以UTF-8编码浏览文件，同样也会以这个编码保存文件。点击这个按钮你还可以切换用其他编码打开或保存文件。 那么原因找到了，我们使用UTF-8的编码保存了文件。编译器编译生成exe文件，里面的“中文”字符串也是UTF-8编码的。而外部终端使用GBK编码打开，于是乱码。 如何解决乱码问题 要解决这个问题，就要让文件和终端的编码一致。我们可以选择用GBK编码保存文件，或者设置终端编码为UTF-8来解决问题。 设置终端编码方式为：SetConsoleOutputCP(65001);（需要windows.h），或者system(&quot;chcp 65001&quot;);（不需要windows.h）。 关于Qt的中文编码 因为最近Qt用的比较多，就在这里稍微提一下。我是先写好c程序，再用Qt做图形化界面，中途需要在QString和std::string以及char*之间转换。如果转换不当就很容易出问题。 Qt的QString用的是unicode编码，在使用.toStdString()转化成std::string后就变成了UTF-8编码。Qt转换成char*虽然有多种方式，但我还是推荐先转成std::string再用.c_str()转成char*，这样路径明晰，兼容性也会好些。这时的char*也是UTF-8编码。 需要转回Qt时，std::string用QString::fromStdString()，char*用QString::fromUtf8()就行。 ","link":"https://jinvic.github.io/post/something_about_Chinese_character_encoding/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://jinvic.github.io/post/hello-gridea/"}]}